[
  {
    "objectID": "lectures/00_intro_to_python.html#lecture-agenda",
    "href": "lectures/00_intro_to_python.html#lecture-agenda",
    "title": "Lecture 1 - Intro to Python and Environmental Data Science",
    "section": "Lecture Agenda",
    "text": "Lecture Agenda\n\nüêç What Python?\n‚ùì Why Python?\nüíª How Python?\n\n\n‚ÄúPython is powerful‚Ä¶ and fast; plays well with others; runs everywhere; is friendly & easy to learn; is Open.‚Äù"
  },
  {
    "objectID": "lectures/00_intro_to_python.html#what-is-python",
    "href": "lectures/00_intro_to_python.html#what-is-python",
    "title": "Lecture 1 - Intro to Python and Environmental Data Science",
    "section": "What is Python?",
    "text": "What is Python?\nPython is a general-purpose, object-oriented programming language that emphasizes code readability through its generous use of white space. Released in 1989, Python is easy to learn and a favorite of programmers and developers.\n\nHigh-level languages\n(Python, C, C++, Java, Javascript, R, Pascal) - Take less time to write - Shorter and easier to read - Portable, meaning that they can run on different kinds of computers with few or no modifications.\nThe engine that translates and runs Python is called the Python Interpreter\n\n\nCode\n\"\"\" \nEntering code into this notebook cell \nand pressing [SHIFT-ENTER] will cause the \npython interpreter to execute the code\n\"\"\"\nprint(\"Hello world!\")\nprint(\"[from this notebook cell]\")\n\n\nHello world!\n[from this notebook cell]\n\n\n\n\nCode\n\"\"\"\nAlternatively, you can run a \nany python script file (.py file)\nso long as it contains valid\npython code.\n\"\"\"\n!python hello_world.py\n\n\nHello world!\n[from hello_world.py]\n\n\n\n\nNatural vs.¬†Formal Languages\nNatural languages are the languages that people speak. They are not designed (although they are subjected to various degrees of ‚Äúorder‚Äù) and evolve naturally.\nFormal languages are languages that are designed by people for specific applications. - Mathematical Notation E=mc^2 - Chemical Notation: \\text{H}_2\\text{O}\nProgramming languages are formal languages that have been designed to express computations.\nParsing: The process of figuring out what the structure of a sentence or statement is (in a natural language you do this subconsciously).\nFormal Languages have strict syntax for tokens and structure:\n\nMathematical syntax error: E=\\$mü¶Ü_2 (bad tokens & bad structure)\nChemical syntax error: \\text{G}_3\\text{Z} (bad tokens, but structure is okay)\n\n\n\nDifferences between Natural and Formal languages\n\nAmbiguity: Natural languages are full of ambiguity, which people parse using contextual clues. Formal languages are nearly or completely unambiguous; any statement has exactly one meaning, regardless of context.\nRedundancy: In order to make up for ambiguity, natural languages employ lots of redundancy. Formal languages are less redundant and more concise.\nLiteralness: Formal languages mean exactly what they say. Natural languages employ idioms and metaphors.\n\nThe inherent differences between familiar natural languages and unfamiliar formal languages creates one of the greatest challenges in learning to code.\n\n\nA continuum of formalism\n\npoetry: Words are used for sound and meaning. Ambiguity is common and often deliberate.\nprose: The literal meaning of words is important, and the structure contributes meaning. Amenable to analysis but still often ambiguous.\nprogram: Meaning is unambiguous and literal, and can be understood entirely by analysis of the tokens and structure.\n\n\nStrategies for parsing formal languages:\n\nFormal languages are very dense, so it takes longer to read them.\nStructure is very important, so it is usually not a good idea to read from top to bottom, left to right. Instead, learn to parse the program in your head, identifying the tokens and interpreting the structure.\nDetails matter. Little things like spelling errors and bad punctuation, which you can get away with in natural languages, will make a big difference in a formal language."
  },
  {
    "objectID": "lectures/00_intro_to_python.html#why-python",
    "href": "lectures/00_intro_to_python.html#why-python",
    "title": "Lecture 1 - Intro to Python and Environmental Data Science",
    "section": "Why Python?",
    "text": "Why Python?\nIBM: R vs.¬†Python\nPython is a multi-purpose language with a readable syntax that‚Äôs easy to learn. Programmers use Python to delve into data analysis or use machine learning in scalable production environments.\nR is built by statisticians and leans heavily into statistical models and specialized analytics. Data scientists use R for deep statistical analysis, supported by just a few lines of code and beautiful data visualizations.\nIn general, R is better for initial exploratory analyses, statistical analyses, and data visualization.\nIn general, Python is better for working with APIs, writing maintainable, production-ready code, working with a diverse array of data, and building machine learning or AI workflows.\nBoth languages can do anything. Most data science teams use both languages. (and others too.. Matlab, Javascript, Go, Fortran, etc‚Ä¶)\n\n\nCode\nfrom IPython.lib.display import YouTubeVideo\nYouTubeVideo('MkNnAwkvvP8')\n\n\n\n        \n        \n\n\n\nLanguage Usage by Data Scientists\nAnaconda State of Data Science\nData from 2021:"
  },
  {
    "objectID": "lectures/00_intro_to_python.html#what-about-2022-data",
    "href": "lectures/00_intro_to_python.html#what-about-2022-data",
    "title": "Lecture 1 - Intro to Python and Environmental Data Science",
    "section": "What about 2022 data?",
    "text": "What about 2022 data?\nThe data are available here‚Ä¶\nLet‚Äôs do some python data science!\n\n\nCode\n# First, we need to gather our tools\nimport pandas as pd  # This is the most common data science package used in python!\nimport matplotlib.pyplot as plt # This is the most widely-used plotting package.\n\nimport requests # This package helps us make https requests \nimport io # This package is good at handling input/output streams\n\n\n\n\nCode\n# Here's the url for the 2022 data that we just looked at:\nurl = \"https://static.anaconda.cloud/content/Anaconda_2022_State_of_Data_Science_+Raw_Data.csv\"\n\n# Try to access the file using the requests library\nresponse = requests.get(url)\nresponse.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n\n# A 200 response code means our request was successful:\nprint(response)\n\n\n&lt;Response [200]&gt;\n\n\n\n\nCode\n# Read the response into a dataframe, using the io.StringIO function to feed the response.txt.\n# Also, skip the first three rows\ndf = pd.read_csv(io.StringIO(response.text), skiprows=3)\n\n# Our very first dataframe!\ndf.head()\n\n# Jupyter notebook cells only output the last value requested...\n\n\n\n\n\n\n\n\n\nIn which country is your primary residence?\nWhich of the following age groups best describes you?\nWhat is the highest level of education you've achieved?\nGender: How do you identify? - Selected Choice\nThe organization I work for is best classified as a:\nWhat is your primary role? - Selected Choice\nFor how many years have you been in your current role?\nWhat position did you hold prior to this? - Selected Choice\nHow would you rate your job satisfaction in your current role?\nWhat would cause you to leave your current employer for a new job? Please select the top option besides pay/benefits. - Selected Choice\n...\nWhat should an AutoML tool do for data scientists? Please drag answers to rank from most important to least important. (1=most important) - Help choose the best model types to solve specific problems\nWhat should an AutoML tool do for data scientists? Please drag answers to rank from most important to least important. (1=most important) - Speed up the ML pipeline by automating certain workflows (data cleaning, etc.)\nWhat should an AutoML tool do for data scientists? Please drag answers to rank from most important to least important. (1=most important) - Tune the model once performance (such as accuracy, etc.) starts to degrade\nWhat should an AutoML tool do for data scientists? Please drag answers to rank from most important to least important. (1=most important) - Other (please indicate)\nWhat do you think is the biggest problem in the data science/AI/ML space today? - Selected Choice\nWhat tools and resources do you feel are lacking for data scientists who want to learn and develop their skills? (Select all that apply). - Selected Choice\nHow do you typically learn about new tools and topics relevant to your role? (Select all that apply). - Selected Choice\nWhat are you most hoping to see from the data science industry this year? - Selected Choice\nWhat do you believe is the biggest challenge in the open-source community today? - Selected Choice\nHave supply chain disruption problems, such as the ongoing chip shortage, impacted your access to computing resources?\n\n\n\n\n0\nUnited States\n26-41\nDoctoral degree\nMale\nEducational institution\nData Scientist\n1-2 years\nData Scientist\nVery satisfied\nMore flexibility with my work hours\n...\n4.0\n2.0\n5.0\n6.0\nA reduction in job opportunities caused by aut...\nHands-on projects,Mentorship opportunities\nReading technical books, blogs, newsletters, a...\nFurther innovation in the open-source data sci...\nUndermanagement\nNo\n\n\n1\nUnited States\n42-57\nDoctoral degree\nMale\nCommercial (for-profit) entity\nProduct Manager\n5-6 years\nNaN\nVery satisfied\nMore responsibility/opportunity for career adv...\n...\n2.0\n5.0\n4.0\n6.0\nSocial impacts from bias in data and models\nTailored learning paths\nFree video content (e.g. YouTube)\nMore specialized data science hardware\nPublic trust\nYes\n\n\n2\nIndia\n18-25\nBachelor's degree\nFemale\nEducational institution\nData Scientist\nNaN\nNaN\nNaN\nNaN\n...\n1.0\n4.0\n2.0\n6.0\nA reduction in job opportunities caused by aut...\nHands-on projects,Mentorship opportunities\nReading technical books, blogs, newsletters, a...\nFurther innovation in the open-source data sci...\nUndermanagement\nI'm not sure\n\n\n3\nUnited States\n42-57\nBachelor's degree\nMale\nCommercial (for-profit) entity\nProfessor/Instructor/Researcher\n10+ years\nNaN\nModerately satisfied\nMore responsibility/opportunity for career adv...\n...\n1.0\n5.0\n4.0\n6.0\nSocial impacts from bias in data and models\nHands-on projects\nReading technical books, blogs, newsletters, a...\nNew optimized models that allow for more compl...\nTalent shortage\nNo\n\n\n4\nSingapore\n18-25\nHigh School or equivalent\nMale\nNaN\nStudent\nNaN\nNaN\nNaN\nNaN\n...\n4.0\n2.0\n3.0\n6.0\nSocial impacts from bias in data and models\nCommunity engagement and learning platforms,Ta...\nReading technical books, blogs, newsletters, a...\nFurther innovation in the open-source data sci...\nUndermanagement\nYes\n\n\n\n\n5 rows √ó 120 columns\n\n\n\n\n\nCode\n# Read the response into a dataframe, using the io.StringIO function to feed the response.txt.\n# Also, skip the first three rows\ndf = pd.read_csv(io.StringIO(response.text), skiprows=3)\n\n# Our very first dataframe!\ndf.head()\n\n# Jupyter notebook cells only output the last value... unless you use print commands!\nprint(f'Number of survey responses: {len(df)}')\nprint(f'Number of survey questions: {len(df.columns)}')\n\n\nNumber of survey responses: 3493\nNumber of survey questions: 120\n\n\n\n\nCode\n# 1. Filter the dataframe to only the questions about programming language usage, and \nfiltered_df = df.filter(like='How often do you use the following languages?').copy() # Use copy to force python to make a new copy of the data, not just a reference to a subset.\n\n# 2. Rename the columns to just be the programming languages, without the question preamble\nfiltered_df.rename(columns=lambda x: x.split('-')[-1].strip() if '-' in x else x, inplace=True)\n\n\n\n\nCode\n# Calculate the percentage of each response for each language\npercentage_df = filtered_df.apply(lambda x: x.value_counts(normalize=True).fillna(0) * 100).transpose()\n\n# Remove the last row, which is the \"Other\" category\npercentage_df = percentage_df[:-1]\n\n# Sort the DataFrame based on the 'Always' responses\nsorted_percentage_df = percentage_df.sort_values(by='Always', ascending=True)\n\n\n\n\nCode\n# Let's get ready to plot the 2022 data...\nfrom IPython.display import display\n\n# We are going to use the display command to update our figure over multiple cells. \n# This usually isn't necessary, but it's helpful here to see how each set of commands updates the figure\n\n# Define the custom order for plotting\norder = ['Always', 'Frequently', 'Sometimes', 'Rarely', 'Never']\n\ncolors = {\n    'Always': (8/255, 40/255, 81/255),       # Replace R1, G1, B1 with the RGB values for 'Dark Blue'\n    'Frequently': (12/255, 96/255, 152/255),   # Replace R2, G2, B2 with the RGB values for 'Light Ocean Blue'\n    'Sometimes': (16/255, 146/255, 136/255),    # and so on...\n    'Rarely': (11/255, 88/255, 73/255),\n    'Never': (52/255, 163/255, 32/255)\n}\n\n\n\n\nCode\n# Make the plot\nfig, ax = plt.subplots(figsize=(10, 7))\nsorted_percentage_df[order].plot(kind='barh', stacked=True, ax=ax, color=[colors[label] for label in order])\nax.set_xlabel('Percentage')\nax.set_title('Frequency of Language Usage, 2022',y=1.05)\n\nplt.show() # This command draws our figure. \n\n\n\n\n\n\n\nCode\n# Add labels across the top, like in the original graph\n\n# Get the patches for the top-most bar\nnum_languages = len(sorted_percentage_df)\n\npatches = ax.patches[num_languages-1::num_languages]\n# Calculate the cumulative width of the patches for the top-most bar\ncumulative_widths = [0] * len(order)\nwidths = [patch.get_width() for patch in patches]\nfor i, width in enumerate(widths):\n    cumulative_widths[i] = width + (cumulative_widths[i-1] if i &gt; 0 else 0)\n\n# Add text labels above the bars\nfor i, (width, label) in enumerate(zip(cumulative_widths, order)):\n    # Get the color of the current bar segment\n    # Calculate the position for the text label\n    position = width - (patches[i].get_width() / 2)\n    # Add the text label to the plot\n    # Adjust the y-coordinate for the text label\n    y_position = len(sorted_percentage_df) - 0.3  # Adjust the 0.3 value as needed\n    ax.text(position, y_position, label, ha='center', color=colors[label], fontweight='bold')\n\n# Remove the legend\nax.legend().set_visible(False)\n\n#plt.show()\ndisplay(fig) # This command shows our updated figure (we can't re-use \"plt.show()\")\n\n\n\n\n\n\n\nCode\n# Add percentage values inside each patch\nfor patch in ax.patches:\n    # Get the width and height of the patch\n    width, height = patch.get_width(), patch.get_height()\n    \n    # Calculate the position for the text label\n    x = patch.get_x() + width / 2\n    y = patch.get_y() + height / 2\n    \n    # Get the percentage value for the current patch\n    percentage = \"{:.0f}%\".format(width)\n    \n    # Add the text label to the plot\n    ax.text(x, y, percentage, ha='center', va='center', color='white', fontweight='bold')\n\ndisplay(fig) # Let's see those nice text labels!\n\n\n\n\n\n\n\nCode\n# Clean up the figure to remove spines and unecessary labels/ticks, etc..\n\n# Remove x-axis label\nax.set_xlabel('')\n\n# Remove the spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n# Remove the y-axis tick marks\nax.tick_params(axis='y', which='both', length=0)\n\n# Remove the x-axis tick marks and labels\nax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n\ndisplay(fig) # Now 100% less visually cluttered!"
  },
  {
    "objectID": "lectures/00_intro_to_python.html#the-end",
    "href": "lectures/00_intro_to_python.html#the-end",
    "title": "Lecture 1 - Intro to Python and Environmental Data Science",
    "section": "The End",
    "text": "The End"
  },
  {
    "objectID": "lectures/02_helpGPT.html#finding-help",
    "href": "lectures/02_helpGPT.html#finding-help",
    "title": "Getting Help",
    "section": "Finding Help",
    "text": "Finding Help\nWhen you get an error, or an unexpected result, or you are not sure what to do‚Ä¶\n\nOptions:\n\nFinding help inside Python\nFinding help outside Python\n\n\n\nFinding Help Inside Python\nHow do we interrogate the data (and other objects) we encounter while coding?\n\nmy_var = 'some_unknown_thing'\nWhat is it?\n\n\nCode\nmy_var = 'some_unknown_thing'\ntype(my_var)\n\n\nstr\n\n\nThe type() command tells you what sort of thing an object is.\n\n\nFinding Help Inside Python\nHow do we interrogate the data (and other objects) we encounter while coding?\n\nmy_var = 'some_unknown_thing'\nWhat can I do with it?\n\n\nCode\nmy_var = ['my', 'list', 'of', 'things']\nmy_var = my_var + ['a', 'nother', 'list']\ndir(my_var)\n\n\n['__add__',\n '__class__',\n '__class_getitem__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\nThe dir() command tells you what attributes an object has.\n\n\nUnderstanding object attributes\n\n\nCode\n# using the dir command\nmy_list = ['a', 'b', 'c']\nlist(reversed(dir(my_list)))\nmy_list.sort?\n\n\n\n\nWhat‚Äôs with all these __attributes__ ?\n__attributes__ are internal (or private) attributes associated with all python objects.\nThese are called ‚Äúmagic‚Äù or ‚Äúdunder‚Äù methods.\ndunder ‚Üí ‚Äúdouble under‚Äù ‚Üí __\n\n\nUnderstanding object attributes‚Ä¶ ‚Äúdunder‚Äù the hood üòí\nEverything in Python is an object, and every operation corresponds to a method.\n\n\nCode\n# __add__ and __mul__. __len__. (None). 2 Wrongs.\n\n3 + 4\n\n\n7\n\n\n\n\nUnderstanding object attributes‚Ä¶ ‚Äúdunder‚Äù the hood üòí\nGenerally, you will not have to worry about dunder methods.\nHere‚Äôs a shortcut function to look at only non-dunder methods\n\n\nTab Completion for object introspection\n\nJupyter Environments:\nYou can use the &lt;tab&gt; key in iPython (or Jupyter environments) to explore object methods. By default, only ‚Äúpublic‚Äù (non-dunder) methods are returned.\n\n\nVSCode:\nYou can usually just pause typing and VSCode will provide object introspection:\n\n\nCode\nstring = 'some letters'\n\n\n\n\n\nGetting help() inside Python\nMost objects - especially packages and libraries - provide help documentation that can be accessed using the python helper function‚Ä¶ called‚Ä¶ help()\n\n\nCode\n# 3, help, str, soil...\nimport math\nhelp(math)\n\n\nHelp on module math:\n\nNAME\n    math\n\nMODULE REFERENCE\n    https://docs.python.org/3.10/library/math.html\n    \n    The following documentation is automatically generated from the Python\n    source files.  It may be incomplete, incorrect or include features that\n    are considered implementation detail and may vary between Python\n    implementations.  When in doubt, consult the module reference at the\n    location listed above.\n\nDESCRIPTION\n    This module provides access to the mathematical functions\n    defined by the C standard.\n\nFUNCTIONS\n    acos(x, /)\n        Return the arc cosine (measured in radians) of x.\n        \n        The result is between 0 and pi.\n    \n    acosh(x, /)\n        Return the inverse hyperbolic cosine of x.\n    \n    asin(x, /)\n        Return the arc sine (measured in radians) of x.\n        \n        The result is between -pi/2 and pi/2.\n    \n    asinh(x, /)\n        Return the inverse hyperbolic sine of x.\n    \n    atan(x, /)\n        Return the arc tangent (measured in radians) of x.\n        \n        The result is between -pi/2 and pi/2.\n    \n    atan2(y, x, /)\n        Return the arc tangent (measured in radians) of y/x.\n        \n        Unlike atan(y/x), the signs of both x and y are considered.\n    \n    atanh(x, /)\n        Return the inverse hyperbolic tangent of x.\n    \n    ceil(x, /)\n        Return the ceiling of x as an Integral.\n        \n        This is the smallest integer &gt;= x.\n    \n    comb(n, k, /)\n        Number of ways to choose k items from n items without repetition and without order.\n        \n        Evaluates to n! / (k! * (n - k)!) when k &lt;= n and evaluates\n        to zero when k &gt; n.\n        \n        Also called the binomial coefficient because it is equivalent\n        to the coefficient of k-th term in polynomial expansion of the\n        expression (1 + x)**n.\n        \n        Raises TypeError if either of the arguments are not integers.\n        Raises ValueError if either of the arguments are negative.\n    \n    copysign(x, y, /)\n        Return a float with the magnitude (absolute value) of x but the sign of y.\n        \n        On platforms that support signed zeros, copysign(1.0, -0.0)\n        returns -1.0.\n    \n    cos(x, /)\n        Return the cosine of x (measured in radians).\n    \n    cosh(x, /)\n        Return the hyperbolic cosine of x.\n    \n    degrees(x, /)\n        Convert angle x from radians to degrees.\n    \n    dist(p, q, /)\n        Return the Euclidean distance between two points p and q.\n        \n        The points should be specified as sequences (or iterables) of\n        coordinates.  Both inputs must have the same dimension.\n        \n        Roughly equivalent to:\n            sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q)))\n    \n    erf(x, /)\n        Error function at x.\n    \n    erfc(x, /)\n        Complementary error function at x.\n    \n    exp(x, /)\n        Return e raised to the power of x.\n    \n    expm1(x, /)\n        Return exp(x)-1.\n        \n        This function avoids the loss of precision involved in the direct evaluation of exp(x)-1 for small x.\n    \n    fabs(x, /)\n        Return the absolute value of the float x.\n    \n    factorial(x, /)\n        Find x!.\n        \n        Raise a ValueError if x is negative or non-integral.\n    \n    floor(x, /)\n        Return the floor of x as an Integral.\n        \n        This is the largest integer &lt;= x.\n    \n    fmod(x, y, /)\n        Return fmod(x, y), according to platform C.\n        \n        x % y may differ.\n    \n    frexp(x, /)\n        Return the mantissa and exponent of x, as pair (m, e).\n        \n        m is a float and e is an int, such that x = m * 2.**e.\n        If x is 0, m and e are both 0.  Else 0.5 &lt;= abs(m) &lt; 1.0.\n    \n    fsum(seq, /)\n        Return an accurate floating point sum of values in the iterable seq.\n        \n        Assumes IEEE-754 floating point arithmetic.\n    \n    gamma(x, /)\n        Gamma function at x.\n    \n    gcd(*integers)\n        Greatest Common Divisor.\n    \n    hypot(...)\n        hypot(*coordinates) -&gt; value\n        \n        Multidimensional Euclidean distance from the origin to a point.\n        \n        Roughly equivalent to:\n            sqrt(sum(x**2 for x in coordinates))\n        \n        For a two dimensional point (x, y), gives the hypotenuse\n        using the Pythagorean theorem:  sqrt(x*x + y*y).\n        \n        For example, the hypotenuse of a 3/4/5 right triangle is:\n        \n            &gt;&gt;&gt; hypot(3.0, 4.0)\n            5.0\n    \n    isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)\n        Determine whether two floating point numbers are close in value.\n        \n          rel_tol\n            maximum difference for being considered \"close\", relative to the\n            magnitude of the input values\n          abs_tol\n            maximum difference for being considered \"close\", regardless of the\n            magnitude of the input values\n        \n        Return True if a is close in value to b, and False otherwise.\n        \n        For the values to be considered close, the difference between them\n        must be smaller than at least one of the tolerances.\n        \n        -inf, inf and NaN behave similarly to the IEEE 754 Standard.  That\n        is, NaN is not close to anything, even itself.  inf and -inf are\n        only close to themselves.\n    \n    isfinite(x, /)\n        Return True if x is neither an infinity nor a NaN, and False otherwise.\n    \n    isinf(x, /)\n        Return True if x is a positive or negative infinity, and False otherwise.\n    \n    isnan(x, /)\n        Return True if x is a NaN (not a number), and False otherwise.\n    \n    isqrt(n, /)\n        Return the integer part of the square root of the input.\n    \n    lcm(*integers)\n        Least Common Multiple.\n    \n    ldexp(x, i, /)\n        Return x * (2**i).\n        \n        This is essentially the inverse of frexp().\n    \n    lgamma(x, /)\n        Natural logarithm of absolute value of Gamma function at x.\n    \n    log(...)\n        log(x, [base=math.e])\n        Return the logarithm of x to the given base.\n        \n        If the base not specified, returns the natural logarithm (base e) of x.\n    \n    log10(x, /)\n        Return the base 10 logarithm of x.\n    \n    log1p(x, /)\n        Return the natural logarithm of 1+x (base e).\n        \n        The result is computed in a way which is accurate for x near zero.\n    \n    log2(x, /)\n        Return the base 2 logarithm of x.\n    \n    modf(x, /)\n        Return the fractional and integer parts of x.\n        \n        Both results carry the sign of x and are floats.\n    \n    nextafter(x, y, /)\n        Return the next floating-point value after x towards y.\n    \n    perm(n, k=None, /)\n        Number of ways to choose k items from n items without repetition and with order.\n        \n        Evaluates to n! / (n - k)! when k &lt;= n and evaluates\n        to zero when k &gt; n.\n        \n        If k is not specified or is None, then k defaults to n\n        and the function returns n!.\n        \n        Raises TypeError if either of the arguments are not integers.\n        Raises ValueError if either of the arguments are negative.\n    \n    pow(x, y, /)\n        Return x**y (x to the power of y).\n    \n    prod(iterable, /, *, start=1)\n        Calculate the product of all the elements in the input iterable.\n        \n        The default start value for the product is 1.\n        \n        When the iterable is empty, return the start value.  This function is\n        intended specifically for use with numeric values and may reject\n        non-numeric types.\n    \n    radians(x, /)\n        Convert angle x from degrees to radians.\n    \n    remainder(x, y, /)\n        Difference between x and the closest integer multiple of y.\n        \n        Return x - n*y where n*y is the closest integer multiple of y.\n        In the case where x is exactly halfway between two multiples of\n        y, the nearest even value of n is used. The result is always exact.\n    \n    sin(x, /)\n        Return the sine of x (measured in radians).\n    \n    sinh(x, /)\n        Return the hyperbolic sine of x.\n    \n    sqrt(x, /)\n        Return the square root of x.\n    \n    tan(x, /)\n        Return the tangent of x (measured in radians).\n    \n    tanh(x, /)\n        Return the hyperbolic tangent of x.\n    \n    trunc(x, /)\n        Truncates the Real x to the nearest Integral toward 0.\n        \n        Uses the __trunc__ magic method.\n    \n    ulp(x, /)\n        Return the value of the least significant bit of the float x.\n\nDATA\n    e = 2.718281828459045\n    inf = inf\n    nan = nan\n    pi = 3.141592653589793\n    tau = 6.283185307179586\n\nFILE\n    /Users/kellycaylor/mambaforge/envs/eds217_2023/lib/python3.10/lib-dynload/math.cpython-310-darwin.so\n\n\n\n\n\n\nGetting help?\nIn the iPython shell (or the Jupyter Notebook/Jupyter Lab environment), you can also access the help() command using ?.\n\n\nCode\nmath\n\n\n&lt;module 'math' from '/Users/kellycaylor/mambaforge/envs/eds217_2023/lib/python3.10/lib-dynload/math.cpython-310-darwin.so'&gt;\n\n\n\n\nGetting more help??\nIn the iPython shell (or the Jupyter Notebook/Jupyter Lab environment) you can use ?? to see the actual source code of python code\n\n\nGetting more help??\n?? only shows source code for for python functions that aren‚Äôt compiled to C code. Otherwise, it will show the same information as ?\n\n\n&lt;tab&gt; completion + ? = discovery & introspection\n\n\nCode\n\n\n\n\n['a', 'b', 'c', 'd', 'c']\n\n\n\n\nUsing print commands\nThe print command is the most commonly used tool for beginners to understand errors\n# This code generates a `TypeError` that \n# x is not the right kind of variable.\ndo_something(x) \nThe print command is the most commonly used debugging tool for beginners.\n\n\nprint Formatting with f-strings.\nPython has a string format called f-strings. These are strings that are prefixed with an f character and allow in-line variable substitution.\n\n\nCode\n# print using c-style format statements\nx = 3.45\nprint(f\"x = {x}\")\n\n\nx = 3.45\n\n\n\n\nCode\ndef do_something(x):\n    x = x / 2 \n    return x\n\n# This code generates a `TypeError` that \n# x is not the right kind of variable.\nx = 'f'\n# Check and see what is X?\nprint(\n    f\"calling do_something() with x={x}\" # Python f-string\n)\n\ndo_something(x) \n\n\ncalling do_something() with x=f\n\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\n\n\nHow to get help outside of Python\nAs of Fall 2002: - O‚ÄôRielly Books (Requires UCSB login) - My O‚ÄôRielly pdf library: https://bit.ly/eds-217-books (Requires UCSB login)\nAs of Fall, 2022: - Python Docs - Stack Overflow - Talk Python - Ask Python\nAs of Fall, 2023:\nLLMs.\n\nChatGPT - Need $ for GPT-4, 3.X fine debugger, but not always a great programmer.\nGitHub CoPilot - Should be able to get a free student account. Works great in VSCode; we will set this up together later in the course."
  },
  {
    "objectID": "lectures/02_helpGPT.html#how-to-move-from-a-beginner-to-a-more-advanced-python-user",
    "href": "lectures/02_helpGPT.html#how-to-move-from-a-beginner-to-a-more-advanced-python-user",
    "title": "Getting Help",
    "section": "How to move from a beginner to a more `advanced`` python user",
    "text": "How to move from a beginner to a more `advanced`` python user\nTaken from Talk Python to Me, Episode #427, with some modifications."
  },
  {
    "objectID": "lectures/02_helpGPT.html#know-your-goals",
    "href": "lectures/02_helpGPT.html#know-your-goals",
    "title": "Getting Help",
    "section": "Know your goals",
    "text": "Know your goals\n\nWhy are you learning python?\nWhy are you learning data science?"
  },
  {
    "objectID": "lectures/02_helpGPT.html#have-a-project-in-mind",
    "href": "lectures/02_helpGPT.html#have-a-project-in-mind",
    "title": "Getting Help",
    "section": "Have a project in mind",
    "text": "Have a project in mind\n\nWhat do you want to do with it?\nUse python to solve a problem you are interested in solving.\nDon‚Äôt be afraid to work on personal projects.\n\n\nSome examples of my personal ‚Äúproblem-solving‚Äù projects\nBiobib - Python code to make my CV/Biobib from a google sheets/.csv file.\nTriumph - Python notebooks for a 1959 Triumph TR3A EV conversion project.\nStoplight - A simple python webapp for monitoring EDS217 course pace."
  },
  {
    "objectID": "lectures/02_helpGPT.html#dont-limit-your-learning-to-whats-needed-for-your-project",
    "href": "lectures/02_helpGPT.html#dont-limit-your-learning-to-whats-needed-for-your-project",
    "title": "Getting Help",
    "section": "Don‚Äôt limit your learning to what‚Äôs needed for your project",
    "text": "Don‚Äôt limit your learning to what‚Äôs needed for your project\n\nLearn more than you need to know‚Ä¶\n‚Ä¶but try to use less than you think you need"
  },
  {
    "objectID": "lectures/02_helpGPT.html#read-good-code",
    "href": "lectures/02_helpGPT.html#read-good-code",
    "title": "Getting Help",
    "section": "Read good code",
    "text": "Read good code\n\nLibraries and packages have great examples of code.\nRead the code (not just docs) of the packages you use.\nGithub is a great place to find code."
  },
  {
    "objectID": "lectures/02_helpGPT.html#know-your-tools",
    "href": "lectures/02_helpGPT.html#know-your-tools",
    "title": "Getting Help",
    "section": "Know your tools",
    "text": "Know your tools\n\nLearn how to use your IDE (VSCode)\nLearn how to use your package manager (conda)\nLearn how to use your shell (bash)\nLearn how to use your version control system (git)\n\n\nLearn how to test your code\n\nTesting is part of programming.\nTesting is a great way to learn.\nFocus on end-to-end (E2E) tests (rather than unit tests)\n\nUnit tests:\nDoes it work the way you expect it to (operation-centric)?\nEnd-to-end test:\nDoes it do what you want it to do (output-centric)?"
  },
  {
    "objectID": "lectures/02_helpGPT.html#know-whats-good-enough-for-any-given-project",
    "href": "lectures/02_helpGPT.html#know-whats-good-enough-for-any-given-project",
    "title": "Getting Help",
    "section": "Know what‚Äôs good enough for any given project",
    "text": "Know what‚Äôs good enough for any given project\n\nYou‚Äôre not writing code for a self-driving car or a pacemaker.\n\nDon‚Äôt over-engineer your code.\nDon‚Äôt over-optimize your code.\nSimple is better than complex."
  },
  {
    "objectID": "lectures/02_helpGPT.html#embrace-refactoring",
    "href": "lectures/02_helpGPT.html#embrace-refactoring",
    "title": "Getting Help",
    "section": "Embrace refactoring",
    "text": "Embrace refactoring\nRefactoring is the process of changing your code without changing its behavior.\n\nShip of Theseus: If you replace every part of a ship, is it still the same ship?\n\n\nAs you learn more, you will find better ways to do things.\nDon‚Äôt be afraid to change your code.\nTests (especially end-to-end tests) help you refactor with confidence.\n‚ÄúCode smells‚Äù‚Ä¶ if it smells bad, it probably is bad.\n\nCode Smells\nComments can be a code smell; they can be a sign that your code is not clear enough."
  },
  {
    "objectID": "lectures/02_helpGPT.html#write-things-down",
    "href": "lectures/02_helpGPT.html#write-things-down",
    "title": "Getting Help",
    "section": "Write things down",
    "text": "Write things down\n\nKeep an ideas notebook\n\nWrite down ideas for projects\nWrite down ideas for code\n\n\n\nWrite comments to yourself and others\n\n\nWrite documentation\n\n\nWrite down questions (use your tools; github issues, etc.)"
  },
  {
    "objectID": "lectures/02_helpGPT.html#go-meet-people",
    "href": "lectures/02_helpGPT.html#go-meet-people",
    "title": "Getting Help",
    "section": "Go meet people!",
    "text": "Go meet people!\n\nThe Python (and Data Science) community is great!\n\nGo to Python & Data Science meetups.\n\nCentral Coast Python\n\n\n\nGo to python and data science conferences.\n\nPyCon 2024 & 2025 will be in Pittsburgh, PA\nPyData (Conferences all over the world)\n\n\n\nGo to hackathons.\n\nSB Hacks (UCSB)\nMLH (Major League Hacking)\nHackathon.com (Hackathons all over the world)"
  },
  {
    "objectID": "lectures/01_the_zen_of_python.html",
    "href": "lectures/01_the_zen_of_python.html",
    "title": "The Zen of Python",
    "section": "",
    "text": "Code\n# What is the Zen of Python??\nimport this"
  },
  {
    "objectID": "lectures/01_the_zen_of_python.html#python-errors",
    "href": "lectures/01_the_zen_of_python.html#python-errors",
    "title": "The Zen of Python",
    "section": "Python Errors",
    "text": "Python Errors\nThere are two types of errors in Python: SyntaxErrors and Exceptions.\n\nSyntaxErrors\nA SyntaxError happens when the Python language interpreter (the parser) detects an incorrectly formatted statement.\nThis code is trying to divide two numbers, but there are mismatched parentheses. What happens when we run it?\n&gt;&gt;&gt; print( 5 / 4 ))\n\n\nCode\nprint( 5 / 4 ))\n\n\nSyntaxError: unmatched ')' (2701704956.py, line 1)\n\n\nWhen python says SyntaxError, you should read this as I don't know what you want me to do!?\nOften the error includes some indication of where the problem is, although this indication can sometimes be misleading if the detection occurs far away from the syntax problem that created the error. Often the interpreter will attempt to explain what the problem is!\n\n\nExceptions\nAn Exception happens the code you have written violates the Python language specification.\nThis code is trying to divide zero by 0. Its syntax is correct. But what happens when we run it?\n&gt;&gt;&gt; print( 0 / 0 )\n\n\nCode\nprint( 0 / 0 )\n\n\nZeroDivisionError: division by zero\n\n\nWhen python says anything other than SyntaxError, you should read this as You are asking to do something I can't do\nIn this case, the ZeroDivisionError is raised because the Python language specification does not allow for division by zero.\n\n\nTypes of Exceptions\nPython has a lot of builtin Errors that correspond to the definition of the Python language.\nA few common Exceptions you will see include TypeError, IndexError, and KeyError.\n\n\nTypeError\nA TypeError is raised when you try to perform a valid method on an inappropriate data type.\n\n\nCode\n# TypeError Examples:\n'a' + 3\n\n\n\n\nIndexError\nAn IndexError is raised when you try to access an undefined element of a sequence. Sequences are structured data types whose elements are stored in a specific order. A list is an example of a sequence.\n\n\nCode\n# IndexError Example:\nmy_list = ['a', 'b', 'c', 'd']\nmy_list[4]\n\n\n\n\nKeyError\nA KeyError is raised when you try to perform a valid method on an inappropriate data type.\n\n\nCode\n# KeyError Examples:\n\nmy_dict = {'column_1': 'definition 1', 'another_word': 'a second definition'}\nmy_dict['column12']\n\n\n\n\nDeciphering Tracebacks\nWhen an exception is raised in python the interpreter generates a ‚ÄúTraceback‚Äù that shows where and why the error occurred. Generally, the REPL has most detailed Traceback information, although Jupyter Notebooks and iPython interactive shells also provide necessary information to debug any exception.\n\n\nCode\n# defining a function\ndef multiply(num1, num2):\n    result = num1 * num2\n    print(results)\n \n# calling the function\nmultiply(10, 2)\n\n\nNameError: name 'results' is not defined\n\n\n\n\nCode\n## The End"
  },
  {
    "objectID": "interactive_sessions/99_scipy.html",
    "href": "interactive_sessions/99_scipy.html",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "",
    "text": "Rainfall in many dryland ecosystems exhibits pronounced variability from year to year. Because rainfall occurs intermittently and with a low degree of predictability, we often are forced to characterize the occurrence and amount of rainfall in terms of probability.\nIn this session, we will investigate the probabilistic nature of rainfall at various locations in Kenya. We will use these data to explore the concepts of probability and conditional probability, as well as probability density functions and cumulative density functions. We will use these data to develop a stochastic model of rainfall that can be used to generate novel time series of rainfall and develop inference into the likelihood of various daily, monthly, seasonal, and annual rainfall totals."
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#determine-yearly-rainfall-totals.",
    "href": "interactive_sessions/99_scipy.html#determine-yearly-rainfall-totals.",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Determine yearly rainfall totals.",
    "text": "Determine yearly rainfall totals.\nThe most common ‚Äì but not always the most useful ‚Äì interval of rainfall characterization is annual. Let‚Äôs see what years we have available to investigate annual rainfall, using the pd.unique() function.\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nUse the &lt;code&gt;pd.unique()&lt;/code&gt; function to get a list of the unique years contained in the &lt;code&gt;Year&lt;/code&gt; column of our dataframe, &lt;code&gt;df&lt;/code&gt;. Assign this list of years to a new array called &lt;code&gt;all_years&lt;/code&gt;\n\nIf all goes well, you should get results that look like this:\n\n&gt; print(all_years)\n\n[1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985\n 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n 2014 2015 2016 2017]\nIt looks like we have almost five decades of rainfall data. The first thing we might want to do with this data is look at yearly summaries.\n\n\n\nüìö  &lt;b&gt; Practice 1. (The following steps can be combined into a single line of code)&lt;/b&gt; \n\n\nDetermine the annual rainfall totals for each year.\n\n\nUse method chaining combined with the df.groupby() function to get the sum of every year‚Äôs rainfall.\n\n\nUse the argument min_count in the sum() command to force pandas to only include sums of rainfall for years with at least 350 days of data.\n\n\nAssign these totals to a new Series variable called yearly_rainfall_total.\n\n\n\nIf all goes correctly, you should get results that look like this:\n&gt; yearly_rainfall_total.head()\n\nYear\n1972    681.228\n1973        NaN\n1974    378.968\n1975    791.464\n1976    363.220\nName: Rainfall (mm), dtype: float64"
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#quantifying-rainfall-variability",
    "href": "interactive_sessions/99_scipy.html#quantifying-rainfall-variability",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Quantifying rainfall variability",
    "text": "Quantifying rainfall variability\nWe can use the coefficient of variation to describe rainfall variability. The coefficient of variation, CV, of a group of numbers is the ratio of the standard deviation, \\sigma, to the mean, \\mu. We can calculate the population CV of a sample, \\widehat{CV}, as the ratio of standard deviation of the sample, s, and the sample mean, \\bar{x}:\n \\widehat{CV} = \\frac{s}{\\bar{x}} \n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nCreate a histogram of yearly rainfall amounts using the hist() command that is a built-in method of any pandas.Series.   Note: Your variable, yearly_rainfall_total should be a pandas.Series object.\n\nWe have a very pronounced mode, with a large degree of variation. Let‚Äôs calculate the \\widehat{CV}.\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nUse the formula above to calculate the \\widehat{CV} for the data in yearly_rainfall_total.\n\n\\widehat{CV} has some problems dealing with small sample sizes (n) and tends to be biased low. We can create an unbiased estimator, \\widehat{CV}^{*} using the following function{^1}:\n \\widehat{CV}^{*} = \\left(1 + \\frac{1}{4n}\\right)\\widehat{CV} \n{^1} technically, \\widehat{CV}^{*} is only valid for normally-distributed data, but we will use it anyway as an example.\n\nüìö  &lt;b&gt; Practice 2.&lt;/b&gt;\nCreate a function that calculates the $\\widehat{CV}^{*}$ for a set of data and use the function to determine the $\\widehat{CV}^{*}$ value for our yearly rainfall data."
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#examining-daily-rainfall-probabilities-and-amounts",
    "href": "interactive_sessions/99_scipy.html#examining-daily-rainfall-probabilities-and-amounts",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Examining daily rainfall probabilities and amounts",
    "text": "Examining daily rainfall probabilities and amounts\nAs we see from the analysis of yearly and monthly rainfall, the climatology of this location is characterized by a fairly high degree of variability. The same is true of many tropical drylands.\n\n1. What is the chance that it will rain?\nIn order to get at the rainfall process itself, let‚Äôs look at the distribution of rainfall events. We can find all the days of rainfall by simply filtering our DataFrame to find days when rain was greater than zero. To do this, we can use the loc() function.\nThe following line of code returns a new dataframe that contains only the rows where 'Rainfall (mm)' is greater than zero:\nrainy_days = df.loc[ (df['Rainfall (mm)'] &gt; 0) ]\n\nüìö  &lt;b&gt; Practice 3.&lt;/b&gt;\nCalculate the overall probability of daily rainfall.\n&lt;ol class=\"alpha\"&gt;\n    &lt;li&gt; Create a &lt;code&gt;DataFrame&lt;/code&gt; containing only rainy days (when rainfall is greater than zero) called &lt;code&gt;rainy_days&lt;/code&gt;&lt;/li&gt;\n    &lt;li&gt; Create a &lt;code&gt;DataFrame&lt;/code&gt; consisting of all observation days (when rainfall is not equal to &lt;code&gt;NaN&lt;/code&gt;) called &lt;code&gt;all_days&lt;/code&gt;&lt;/li&gt;\n    &lt;li&gt; Use the ratio of the length of &lt;code&gt;rainy_days&lt;/code&gt; and &lt;code&gt;all_days&lt;/code&gt; to determine the probability of rainfall and save this as a new variable called &lt;code&gt;prob_rain&lt;/code&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\nIf all goes well, then you should get the following value for prob_rain:\n\n&gt; print(prob_rain)\n0.13211859564472098\n\n\n\n\nMonthly Rainfall Totals and Probabilities\nOver the entire time period, the probability of rainfall was about 13%, which means that it rains - on average - a little less than once per week (approximately every 7.7 days). However, most regions have strong seasonality in rainfall. Our data comes from a site that is located very close to the equator in central Kenya. This means that the movement of the ITCZ across the tropics causes changes in the likelihood of rainfall from month to month. We should therefore look at monthly rainfall probabilies rather than simply the annual average.\n\nüìö  &lt;b&gt; Practice 4.&lt;/b&gt;\n&lt;ol class=\"alpha\"&gt;\n    &lt;li&gt; Determine the probability of rainfall for each month. Add these values to a list called &lt;code&gt;lambda_by_month&lt;/code&gt;. Hint: You can combine test criteria using logical operators (i.e. &lt;code&gt;&&lt;/code&gt; and &lt;code&gt;|&lt;/code&gt;).\n    &lt;li&gt;Create a bar graph of the monthly rainfall probabilites. Label your plot appropriately.\n&lt;/ol&gt;\n\n\n\n2. What is the amount that it will rain?\nWe‚Äôve already subsetted all of our data for days with rain and stored this in the variable rainy_days. Let‚Äôs look at the distribution of rain amounts:\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nrainy_days['Rainfall (mm)'].hist(bins=50)\n\n\nAs opposed to the annual rainfall distribution, the distribution of daily storm totals (or daily rainfall) has a much clearer distribution. This pattern of daily rainfall ‚Äì a positively skewed distribution with a short-tail ‚Äì is very consistent with what we see across tropical drylands, and even more broadly across any location where rainfall is dominated by convective processes. We might ask what the average storm total is‚Ä¶\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nCalculate the average rainfall amount on rainy days over the data record. Save this quantity as a new variable called &lt;code&gt;avg_rainfall_depth&lt;/code&gt;."
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#fitting-rainfall-depths-to-an-exponential-distribution",
    "href": "interactive_sessions/99_scipy.html#fitting-rainfall-depths-to-an-exponential-distribution",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Fitting rainfall depths to an exponential distribution",
    "text": "Fitting rainfall depths to an exponential distribution\nA simple rainfall model makes two assumptions; (1) that events arrive according to a Poisson process, and (2) that rainfall depths are distributed according to an exponential distribution. These two assumptions are accompanied by the need for two rainfall parameters; (1) the probability of rainfall events, \\lambda_r, and the average depth of rainfall events \\alpha. We‚Äôve already seen how to estimate both of these parameters from rainfall data, so here we are going to focus on testing the appropriateness of the model assumptions during the growing season for Laikipia, Kenya.\n\nStep 1. Fit the distribution\nTo fit the distribution, we are going to use some more functions from python‚Äôs suite of numerical analysis. In this case we are going to use some functions from scipy. The scipy.stats module has a large suite of distribution functions pre-defined, which we can use to develop a fit for our data. Using any of these distributions for fitting our data is very easy. The distribution we are most interested in is the exponential distribution, which is called expon in the stats module.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nimport scipy.stats as st\n\ndistribution = st.expon\ndata = rainy_days['Rainfall (mm)']\nparams = distribution.fit(data, loc=0) # Force the distribution to be built off of zero\n\nprint(params)\n\narg = params[:-2]\nloc = params[-2]\nscale = params[-1]\n\n\n\n\nStep 2. Calculate fitted PDF and error with fit in distribution\nTo test the fit of our distribution, we can compare the empirical histogram to that predicted by our model. To do this, we first use our data to generate the empirical histogram. In this exampkle, we break the data into 30 bins, and we generate a histrogram of density rather than counts. This allows for an easier comparison between our empirical data and the fitted probability distribution function. Here are the steps:\n\nGenerate a histogram, from the data. Save the bin locations in x and the density of values in y\nShift the x bin locations generated from the histogram to the center of bins.\nCalculate the value of the fitted pdf(x) for each of the bins in x.\nDetermine the residual sum of the squares, SS_{error}, and total sum of squares, SS_{yy}, according to:\n\n SS_{error} = \\sum_{i=1}^{n} \\left(y_i - f(x_i)\\right)^2   SS_{yy} = \\sum_{i=1}^{n} \\left(y_i - \\bar{y}\\right)^2 \n\nCalculate the r^2 of the fit, according to\n\n r^2 = 1- \\frac{SS_{error}}{SS_{yy}} \n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Step 1. Generate a density histogram of the data \ny, x = np.histogram(data, bins=30, density=True)\n\n# Step 2. Shift the x bin locations to the center of bins.\nx = (x + np.roll(x, -1))[:-1] / 2.0\n\n# Step 3. Calculate the values of pdx(x) for all x.\npdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n\n# Step 4. Determine the residual and total sum of the squares.\nss_error = np.sum(np.power(y - pdf, 2.0))\nss_yy = np.sum(np.power(y - y.mean(), 2.0))\n\nr_2 = 1 - ( ss_error / ss_yy )\nprint(r_2)\n\n\nThese results suggest that an exponential distribution is a really good fit for our observed data on rainfall amounts."
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#modeling-rainfall",
    "href": "interactive_sessions/99_scipy.html#modeling-rainfall",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Modeling rainfall",
    "text": "Modeling rainfall\nLet‚Äôs make a very simple model of rainfall that assumes a Poisson process (i.e.¬†a memoryless process). We just saw that this approach is probably too simple, and later we will look at how we could improve the model. But it helps to start with the most simple approach and then add complexity as needed.\nOur model will be built with the following assumptions:\n\nThe probability of an ‚Äúevent‚Äù (i.e.¬†rainfall) occuring on any given day is given by the parameter \\lambda_r, which has units day^{-1}\nThe total depth of rainfall on days with rain is a random variable, drawn from an exponential distribution with mean, \\alpha, which has units of mm.\n\nThis type of model is a ‚Äúmarked Poisson process‚Äù and is a special case of a Poisson process on a number line (in our case, the number line is time), where each event is characterized by a random ‚Äúmark‚Äù that is independent of the event.\n\nStep 1. Simulating Poisson events\nWe have a variety of means to simulate a Poisson process, and all of them will require the use of a random number generator. The numpy package has lots of different builtin functions to generate pseudo-random numbers, and we can use one of these.\nTo simulate the likelihood of a Poisson event, we can draw a sample from a uniform distribution in [0,1] and compare that to our probability of an event. If the value we draw is less than or equal to our probability, then an event occurs, otherwise no event occurs. The probability density function, f(x) of a uniform distribution sampled over the half open interval from a to b, [a,b) is given by\n\nf(x) = \\frac{1}{b - a}\n\nWe can sample from this distribution using the np.random.uniform() function:\n\ns = np.random.uniform(low=0,high=1)\nThe np.random.uniform() function also takes the optional argument size, which specifies the number of random samples to return. This allows for the generation of large lists of random samples without using a for loop or list comprehension approaches.\n# Returns an array of 2 random draws.\ns = np.random.uniform(low=0, high=1, size=2) \n\n# Returns an array of 2 rows each with 10 random draws\ns_mat = np.random.uniform(low=0, high=1, size=[2, 10])\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nUsing a $\\lambda_r$ value equal to your calculated value of &lt;code&gt;prob_rain&lt;/code&gt; and assuming that the length of a growing season, $T_{seas}$, is 160 days, simulate a season of rainfall \"events\", where the value of a day is &lt;code&gt;1&lt;/code&gt; if rainfall occurs, and &lt;code&gt;0&lt;/code&gt; if not.&lt;/div&gt;\n\n\nüí° You can use the pd.astype() command to force Boolean (True/False) values into integers (1,0)\n\n\n\nStep 2. Adding marks to events\nOur approach for creating marks (i.e.¬†daily rainfall depths) is to sample them randomly from an exponential distribution with mean \\alpha. The exponential probability density function f(x) for x\\gt0 as a function of \\alpha is expressed as\n\nf(x) = \\frac{1}{\\alpha} \\exp\\left(-\\frac{x}{\\alpha}\\right),\n\nJust as with sampling from a uniform distribution (and as with most everything in python/pandas), there‚Äôs a function for that. In this case, we are going to use the‚Ä¶ you guessed it‚Ä¶ np.random.exponential() function. It is used similarly to the np.random.uniform() function, but with a single parameter to describe the distribution:\ns = np.random.exponential(scale=11.5) \nThe scale parameter is the mean of the distribution, which in our simulations will be \\alpha (mm), the average rainfall depth on days with rain. Just as with np.random.uniform(), we can generate lists or arrays of samples from the exponential distribution.\n\ns = np.random.exponential(scale=11.5, size=2) # Returns an array of 2 random draws.\n\ns_mat = np.random.uniform(scale=11.5, size=[2, 10]) # Returns an array of 2 rows each with 10 random draws.\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nUse the average storm depth (&lt;code&gt;avg_rainfall_depth&lt;/code&gt;), probability of rainfall you calculated earlier, and the same $T_{seas}$ as before, generate a season of rainfall.&lt;/div&gt;\n\nüí° The product of 0 and any rainfall amount is still 0. That means you don‚Äôt need to worry about which days have rain and which don‚Äôt when multiplying a list of rainfall_amounts and a binary list of rain_days.\n\n\n\nSimulating multiple years of rainfall\n\nüìö  &lt;b&gt; Practice 5.&lt;/b&gt;\nUsing your &lt;code&gt;prob_rain&lt;/code&gt; and your &lt;code&gt;avg_rainfall_depth&lt;/code&gt;:\n&lt;ol class=\"alpha\"&gt;\n    &lt;li&gt; Generate 100 years of rainfall.&lt;/li&gt;\n    &lt;li&gt; Plot a histogram of the annual totals.&lt;/li&gt;\n    &lt;li&gt;Calculate the $\\widehat{CV}$ of seasonal rainfall.&lt;/li&gt;\n&lt;/ol&gt;\n\n\n\nCode"
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#conditional-probabilities-given-that-today-was-rainy-will-it-rain-tomorrow",
    "href": "interactive_sessions/99_scipy.html#conditional-probabilities-given-that-today-was-rainy-will-it-rain-tomorrow",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Conditional Probabilities: Given that today was rainy, will it rain tomorrow?",
    "text": "Conditional Probabilities: Given that today was rainy, will it rain tomorrow?\nFinally, we want to look to see if we can predict rainfall. The easiest way to think about predictability is to ask whether or not knowing what happened today significantly alters our expectation about what will happen tomorrow. There are two options:\n\nIf every day is random and unpredictable, then rainfall tomorrow will be independent of what happened today.\nIf what happens today affects tomorrow, then we should see dependency between today and tomorrow‚Äôs rainfall.\n\nWe can test the independence of rainfall likelihood by testing to see if rainfall on day t affects the probability of rainfall on day t+1.\nFormally, we can write the probability that rainfall, R, on some day t,is greater than zero as P[R_t&gt;0]. If $ P[R_t&gt;0] = P[R_t&gt;0 | R_{t-1} &gt;0] $, then we can say that P[R_t] and P[R_{t-1}] are independent.\nFirst, we use the index property of rainy_days, which is just a list of all the index values (or rows) in our original data, df, where rainfall was greater than zero. Then we increment the index and save all these rows from the original data into a new variable, days_after_rain.\n\nüìö  &lt;b&gt; Practice 6.&lt;/b&gt;\n&lt;ol class=\"alpha\"&gt;\n    &lt;li&gt; Make a list of the index locations of &lt;code&gt;rainy_days&lt;/code&gt; using the &lt;code&gt;index&lt;/code&gt; attribute of &lt;code&gt;rainy_days&lt;/code&gt;.&lt;/li&gt;\n    &lt;li&gt; Create a new dataframe called &lt;code&gt;days_after_rain&lt;/code&gt; that contains only the days after rainy days. You will need to use our original &lt;code&gt;df&lt;/code&gt; dataframe to get this new dataframe.&lt;/li&gt;\n    &lt;li&gt;Calculate the probability of rainfall following rainy days using your new &lt;code&gt;days_after_rain&lt;/code&gt; variable. Call this new probability &lt;code&gt;prob_rain_after_rain&lt;/code&gt;&lt;/li&gt;\n    &lt;li&gt;Compare the probability of rainfall following rainy days (&lt;code&gt;prob_rain_after_rain&lt;/code&gt;) to the overall probability of rainfall (&lt;code&gt;prob_rain&lt;/code&gt;). Based on these values, is an assumption of independence in the rainfall process valid?&lt;/li&gt;\n&lt;/ol&gt;"
  },
  {
    "objectID": "interactive_sessions/99_scipy.html#simulating-annual-rainfall-with-monthly-values",
    "href": "interactive_sessions/99_scipy.html#simulating-annual-rainfall-with-monthly-values",
    "title": "Probability and Stochastic Processes with Scipy",
    "section": "Simulating annual rainfall with monthly values",
    "text": "Simulating annual rainfall with monthly values\nOne improvement we can make to our model is to have monthly values for our rainfall probabilities. To get these monthly \\lambda_r values, we need to determine the probability of rainfall for each month by dividing the number of rainy days per month by the total number of observations in each month, which we did in Practice 4. For now, we assume stationarity in the monthly values, which means that we are assuming that the values of \\lambda_r in each month are the same through out the entire record (i.e.¬†Jan 1938 has the same properties as Jan 2008).\n\nüí° It‚Äôs worth thinking about how you could test our stationarity assumption. If you have an idea of how to do so, go ahead and give it a shot!\n\nTo improve our simulation of annual rainfall, we are going to use our monthly values to specify daily values of \\lambda_r using the monthly values we just calculated. The use of a variable \\lambda value in a Poisson process creates what is known as an ‚Äúinhomogenous Poisson process‚Äù (or, alternatively, ‚Äúnonhomogeneous‚Äù‚Ä¶ unfortunatetly, there isn‚Äôt much homogeneity in what we call it!). These types of processes allow the properties of the process to change in space and time. Our implementation ‚Äì using monthly values ‚Äì is a little clunky, and we‚Äôd prefer to have the \\lambda values change more smoothly throughout the year. However, we probably don‚Äôt have sufficient data to allow for this, even if we could accomodate the more complicated coding it would require.\nIn order to generate our nonhomogenous process, we will first generate a daily array of month numbers for the year 2018. This is really easy in python using datetime + timedelta (which we need to import).\n    from datetime import timedelta, datetime\n    datetimes = np.arange(\n        datetime(2018,1,1), datetime(2018,12,31),\n        timedelta(days=1)).astype(datetime)\n    month_value_by_day = np.array([datetime.month for datetime in datetimes])\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nfrom datetime import timedelta, datetime\ndatetimes = np.arange(datetime(2018,1,1), datetime(2019,1,1), timedelta(days=1)).astype(datetime)\nmonth_value_by_day = np.array([datetime.month for datetime in datetimes])\n\n\nNow we have a 12-element np.array of \\lambda_r values, organized by month number, which we‚Äôve stored in lambda_by_month and we have a list of 365 days that contains the month number for each day, which we‚Äôve stored in month_value_by_day. We can use these two variables to get a new variable that contains the correct \\lambda value for each day.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ndaily_lambda_values = np.array([lambda_by_month[i-1] for i in month_value_by_day])\n\n\nWith daily values of \\lambda_r, we only need to follow the same cookbook we used to make the stationary simulation.\n    simulated_rainy_days = (\n        np.random.uniform(\n            low=0, high=1, size=len(daily_lambda_values)\n        ) &lt;= daily_lambda_values).astype(int)\n    simulated_rainfall_values = np.random.exponential(\n        scale=alpha, size=len(daily_lambda_values)\n    )\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;    \nUse the code above to create a new daily rainfall simulation using our daily values of $\\lambda_r$. Plot the daily rainfall data. You can easily plot your rainfall data using the &lt;code&gt;datetimes&lt;/code&gt; object we already created as the basis of our x-axis.&lt;/div&gt;"
  },
  {
    "objectID": "interactive_sessions/test_environment.html",
    "href": "interactive_sessions/test_environment.html",
    "title": "Test Environment",
    "section": "",
    "text": "Return to Course Home Page\n\n\n\n\nThis notebook contains code that tests to make sure your JupyterLab instance has all the necessary libraries for working with EDS 217 course materials.\nTo use this notebook, select Run -&gt; Run All Cells from the JupyterLab menu bar at the top of this window.\n\n\nCode\ntry:\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    print(\"You're all set!\\n\")\n    pd.show_versions()\nexcept:\n    print(\"Uh-oh!\")\n\n\nYou're all set!\n\n\nINSTALLED VERSIONS\n------------------\ncommit           : 0f437949513225922d851e9581723d82120684a6\npython           : 3.10.12.final.0\npython-bits      : 64\nOS               : Darwin\nOS-release       : 22.5.0\nVersion          : Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\nmachine          : x86_64\nprocessor        : i386\nbyteorder        : little\nLC_ALL           : None\nLANG             : en_US.UTF-8\nLOCALE           : en_US.UTF-8\n\npandas           : 2.0.3\nnumpy            : 1.25.2\npytz             : 2023.3\ndateutil         : 2.8.2\nsetuptools       : 68.1.2\npip              : 23.2.1\nCython           : None\npytest           : None\nhypothesis       : None\nsphinx           : None\nblosc            : None\nfeather          : None\nxlsxwriter       : None\nlxml.etree       : None\nhtml5lib         : None\npymysql          : None\npsycopg2         : None\njinja2           : 3.1.2\nIPython          : 8.14.0\npandas_datareader: None\nbs4              : 4.12.2\nbottleneck       : None\nbrotli           : 1.0.9\nfastparquet      : None\nfsspec           : None\ngcsfs            : None\nmatplotlib       : 3.7.2\nnumba            : None\nnumexpr          : None\nodfpy            : None\nopenpyxl         : None\npandas_gbq       : None\npyarrow          : None\npyreadstat       : None\npyxlsb           : None\ns3fs             : None\nscipy            : None\nsnappy           : None\nsqlalchemy       : None\ntables           : None\ntabulate         : None\nxarray           : None\nxlrd             : None\nzstandard        : None\ntzdata           : 2023.3\nqtpy             : 2.3.1\npyqt5            : None\n\n\n/Users/kellycaylor/mambaforge/envs/eds217_2023/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")"
  },
  {
    "objectID": "interactive_sessions/Setting_up_local.html#general-plan",
    "href": "interactive_sessions/Setting_up_local.html#general-plan",
    "title": "Setting up your local Python",
    "section": "General Plan",
    "text": "General Plan\nThere are many ways to set up your local machine to run maintanable python data science code. In addition to the usual need to build your code within a repository, any strategy for local computation depends on three critical components that must work well together: Computational isolation, Functional consistency, Developer efficiency.\nIn practice, these three components necessitate three fundamental and inter-related progamming tools:\n\nA tool for managing computing environments\nA tool for managing python packages\nAn tool for managing python code, which is usually an integrated development environment (IDE) in which editing and running code occur interactively.\n\nWe are about to install tools that will meet these three needs on your computer and ensure a successful start on your python journey. I‚Äôve included details about some of the tools we will not use, and you‚Äôll see them mentioned (and discussed) across the Pythonverse. Don‚Äôt be afraid to try new tools!"
  },
  {
    "objectID": "interactive_sessions/Setting_up_local.html#managing-computing-environments",
    "href": "interactive_sessions/Setting_up_local.html#managing-computing-environments",
    "title": "Setting up your local Python",
    "section": "1. Managing Computing Environments",
    "text": "1. Managing Computing Environments\nThere are many options for managing computing environments.\nThese days, a common method is to use containers, in which an entire computational system (including processes, memory, disk space) is spun up as an isolated service on your local (or remote). Systems such as docker or python-specific shiv allow for isolated packaging and execution of python programs.\nA more common approach on local machines is to use the condaenvironment management system. Conda is developed by Anaconda, and is the most widely used environment management system in python data science. Other local solutions include venv, which is part of the main python distribution.\nIn this course, we will use conda for our environment management. We will be able to access conda through the terminal/command line, within a terminal inside our IDE, or even inside our notebooks themselves."
  },
  {
    "objectID": "interactive_sessions/Setting_up_local.html#managing-python-packages",
    "href": "interactive_sessions/Setting_up_local.html#managing-python-packages",
    "title": "Setting up your local Python",
    "section": "2. Managing Python Packages",
    "text": "2. Managing Python Packages\nOnce a computing environment is created in conda, there is a need to manage the individual packages within the environment. Once again, there are many ways to accomplish this task in python.\nFirstly, conda itself is a sophisticated package management system! The conda progra, is able to download and install almost any python package and often it is possible to install binaries of packages directly without the need for local compilation. conda also manages package dependencies, ensuring libraries are inter-operable.\nIn addition to conda, there is the Package Installer for Python pip. pip can install any package hosted on the Python Package Index (PyPI), as well as packages hosted on github and even packages you‚Äôve made on your local machine.\nRecently, a new entry to package management, poetry has started to become popular. poetry focuses on making package management - and especially dependency management between and amongst packages - much easier. It also simplifies building and packaging your own code for distribution.\nIn this class, we will use conda for our package management. Because conda also includes pip, we get all the advantages of conda (faster installs, easy integration with IDEs) without losing the broad capabilities of pip. In a few years, we might be using poetry, but for now, conda is still the most common tool you will see in professional python development shops, so it‚Äôs the one you should know best.\nConda can create new environments using a markup language specification called yaml. We will use an environment file created for our course to create an eds217_2023 environment on your local machine."
  },
  {
    "objectID": "interactive_sessions/Setting_up_local.html#managing-code-and-execution-ides",
    "href": "interactive_sessions/Setting_up_local.html#managing-code-and-execution-ides",
    "title": "Setting up your local Python",
    "section": "3. Managing code and execution (IDEs)",
    "text": "3. Managing code and execution (IDEs)\nFinally, we come to the tool you will use most when coding on your local computer ‚Äì the Integrated Development Environment, or IDE. The possibilities for IDEs is even more expansive than for either of the other tools. Common python IDEs include:\n\nVisual Studio Code\nJupyter Notebooks\nJupyter Labs\nSpyder\nPyCharm\nData Spell\nAtom\nRStudio\n\nAny of these could work well for a python data science workflow, but definitely some have more features focused on data science than others. For example, PyCharm is more focused on software engineering, but a new IDE called Data Spell, by the same company (Jet Brains), is squarely centered on data science workflows. That tool is too new (and niche) to spend a lot of time on in this course.\nThe best IDE is usually the one you are most familiar with. For that reason, RStudio isn‚Äôt a terrible choice for an IDE. Although you will only be able to write code in quarto (.qmd) files, RStudio could be sufficient for many of your python needs.\nHowever, if you‚Äôre going to develop python code professionally, you‚Äôre not going to see many teams using RStudio. The reason is because most python data science is developed in native python formats (.py files) or in Jupyter Notebook formats (.ipynb). RStudio can‚Äôt edit either of these formats. So it‚Äôs best to use an IDE that is designed to efficiently parse these files and allow you to execute code directly.\nWe will use both .py files and .ipybd files in this class. For notebooks, you could always edit them in a browser running Jupyter or JupyterLab However, it‚Äôs probably best to learn to use a non-browser IDE if possible, because that will provide more opportunities for customization and removes a layer of complication required when executing your code.\nToday we will look at both RStudio (for .qmd files) and Visual Studio Code (VSCode).\nHaving covered all the bases, we need to go ahead and get to work. Here are the steps for getting our class environment working on your machine, and within your IDE."
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html",
    "href": "interactive_sessions/2-2_structured_data.html",
    "title": "Session 2-2: Structured Data in Python",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nProbably the easiest mental model for thinking about structured data is a spreadsheet. You are all familiar with Excel spreadsheets, with their numbered rows and lettered columns. In the spreadsheet, data is often ‚Äústructured‚Äù so that each row is an entry, and each column is perhaps a variable recorded for that entry.\nEnvironmental data map really well to this model, especially data collected over time. A spreadsheet of weather observations would have a new row for each observation period, and then the columns would be the meteorological data that was collected at that time. As we move into our data science tools, we will see that a major aspect of these tools is creating efficient ways of working with structured data.\nThat being said, Python has a number of built-in data types that can be used to organize data in a structured manner. These basic data types containing structured data are all lumped into a single broad category called collections. Within these collection data types, some of the data types are sequences, which means that the items in the collection have a deterministic ordering. You‚Äôve already used the two most common sequence data types: the string and the list. A string is simply an ordered collection of characters, while a list data type structures a collection of anything into an ordered series of elements that can be referenced by their position in the list.\nIn this lesson, we are going to learn about an additional sequence, called a tuple, as well as two collection data types called sets (set) and dictionaries (dict)."
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#dictionaries",
    "href": "interactive_sessions/2-2_structured_data.html#dictionaries",
    "title": "Session 2-2: Structured Data in Python",
    "section": "1. Dictionaries ",
    "text": "1. Dictionaries \n\nTLDR: Dictionaries are a very common collection type that allows data to be organized using a key:value framework. Because of the similarity between key:value pairs and many data structures (e.g.¬†‚Äúlookup tables‚Äù), you will see Dictionaries quite a bit when working in python\n\nThe first collection we will look at today is the dictionary, or dict. This is one of the most powerful data structures in python. It is a mutable, unordered collection, which means that it can be altered, but elements within the structure cannot be referenced by their position and they cannot be sorted.\nYou can create a dictionary using the {}, providing both a key and a value, which are separated by a :.\nenvironmental_disciplines = {\n    'ecology':'The relationships between organisms and their environments.',\n    'hydrology':'The properties, distribution & effects of water on the surface, subsurface, & atmosphere.',\n    'geology':'The origin, history, and structure of the earth.',\n    'meteorology':'The phenomena of the atmosphere, especially weather and weather conditions.'\n    }\n\nüêç &lt;b&gt;Note.&lt;/b&gt; The use of whitespace and indentation is important in python. In the example above, the dictionary entries are indented relative to the brackets &lt;code&gt;{&lt;/code&gt; and &lt;code&gt;}&lt;/code&gt;. In addition, there is no space between the &lt;code&gt;'key'&lt;/code&gt;, the &lt;code&gt;:&lt;/code&gt;, and the &lt;code&gt;'value'&lt;/code&gt; for each entry. Finally, notice that there is a &lt;code&gt;,&lt;/code&gt; following each dictionary entry. This pattern is the same as all of the other &lt;i&gt;collection&lt;/i&gt; data types we've seen so far, including &lt;b&gt;list&lt;/b&gt;, &lt;b&gt;set&lt;/b&gt;, and &lt;b&gt;tuple&lt;/b&gt;.\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nenvironmental_disciplines = {\n    'ecology':'The relationships between organisms and their environments.',\n    'hydrology':'The properties, distribution & effects of water on the surface, subsurface, & atmosphere.',\n    'geology':'The origin, history, and structure of the earth.',\n    'meteorology':'The phenomena of the atmosphere, especially weather and weather conditions.'\n}\n\n\n\nAccessing elements in Dictionaries \nAccess an element in a dictionary is easy if you know what you are looking for. For example, if I want to know the definition of ecology, I can simply retireve the value of this defition using the key as my index into the dictionary:\nenvironmental_disciplines['ecology']\n&gt;&gt;&gt; 'The relationships between organisms and their environments.'"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nTry accessing the some of the definitions in the environmental_disciplines dictionary.\n\n\nCode\nenvironmental_disciplines['ecology']\n\n\n'The relationships between organisms and their environments.'\n\n\nBecause dictionaries are mutable, it is easy to add additional entries. This is done using the following notation:\n    environmental_discplines['geomorphology'] =  'The evolution and configuration of landforms.'"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-1",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-1",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nBiogeochemistry is defined as ‚Äúthe chemical, physical, geological, and biological processes and reactions that govern the composition of the natural environment.‚Äù Add this discpline to the dictionary environmental_disciplines.\n\n\nCode\nenvironmental_disciplines['biogeochemistry'] = 'the chemical, physical, geological, and biological processes and reactions that govern the composition of the natural environment.'\nprint(environmental_disciplines['biogeochemistry'])\n\n\nthe chemical, physical, geological, and biological processes and reactions that govern the composition of the natural environment.\n\n\n\nAccessing dictionary keys and values \nEvery dictionary has builtin methods to retrieve its keys and values. These functions are called, appropriately, keys() and values()\n\ndisciplines = environmental_disciplines.keys()\nprint(disciplines)\n&gt;&gt;&gt; dict_keys(['ecology', 'hydrology', 'geology', 'meteorology', 'biogeochemistry'])\n\ndefinitions = environmental_disciplines.values()\nprint(definitions)\n&gt;&gt;&gt; dict_values(\n    ['The relationships between organisms and their environments.', \n     'The properties, distribution & effects of water on the surface, subsurface, & atmosphere.', \n     'The origin, history, and structure of the earth.', \n     'The phenomena of the atmosphere, especially weather and weather conditions.', \n     'The chemical, physical, geological, and biological processes and reactions that govern the composition of the natural environment.'])\n\nüêç Note. The keys() and values() functions return a dict_key object and dict_values object, respectively. Each of these objects contains a list of either the keys or values. You can force the result of the keys() or values() function into a list by wrapping either one in a list() command.\nFor example: key_list = list(environmental_disciplines.keys()) will return a list of the keys in environmental_disciplines\n\n\n\nCode\nfor key, value in environmental_disciplines.items():\n    print(key, value)\n    environmental_disciplines[key] = value.capitalize()\n\n\necology The relationships between organisms and their environments.\nhydrology The properties, distribution & effects of water on the surface, subsurface, & atmosphere.\ngeology The origin, history, and structure of the earth.\nmeteorology The phenomena of the atmosphere, especially weather and weather conditions.\nbiogeochemistry the chemical, physical, geological, and biological processes and reactions that govern the composition of the natural environment.\n\n\n\n\nLooping through Dictionaries \nPython has an efficient way to loop through all the keys and values of a dictionary at the same time. The items() method returns a tuple containing a (key, value) for each element in a dictionary. In practice this means that we can loop through a dictionary in the following way:\nmy_dict = {'name': 'Homer Simpson',\n           'occupation': 'Nuclear Engineer',\n           'address': '742 Evergreen Terrace',\n           'city': 'Springfield',\n           'state': ' ? '\n          }\n\nfor key, value in my_dict.items():\n    print(f\"{key.capitalize()}: {value}.\")\n\n\n&gt;&gt;&gt; Name: Homer Simpson.\n    Occupation: Nuclear Engineer.\n    Address: 742 Evergreen Terrace.\n    City: Springfield.\n    State:  ? ."
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-2",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-2",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nLoop through the environmental_disciplines dictionary and print out a sentence providing the definition of each subject (e.g.¬†‚ÄúEcology is the study of‚Ä¶.‚Äù).\n\nAccessing un-assigned elements in Dictionaries \nAttempting to retrieve an element of a dictionary that doesn‚Äôt exist is the same as requesting an index of a list that doesn‚Äôt exist - Python will raise an Exception. For example, if I attempt to retrieve the definition of a field that hasn‚Äôt been defined, then I get an error.\nenvironmental_disciplines['xenohydrology']\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n&lt;ipython-input-46-d4d91bf18209&gt; in &lt;module&gt;\n----&gt; 1 environmental_disciplines['xenohydrology']\n\nKeyError: 'xenohydrology'\nWhile it‚Äôs easy to determine what indicies are in a list using the len() command, it‚Äôs sometimes hard to know what elements are in a dict (but we‚Äôll learn how soon!). Regardless, to avoid getting an error when requesting an element from a dict, you can use the get() function. The get() function will return None if the element doesn‚Äôt exist:\nunknown_definition = environmental_disciplines.get('xenohydrology')\nprint(unknown_definition)\n&gt;&gt;&gt; None\nThe get() function will also allow you to pass an additional argument. This additional argument specifies a ‚Äúdefault‚Äù value which will be returned for any undefined elements:\nenvironmental_disciplines.get('xenohydrology', 'Discipline not defined.')\n&gt;&gt;&gt; 'Discipline not defined.'\nlist_of_disciplines = ['climatology', 'ecology', 'meteorology', 'geology', 'biogeochemistry']"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-3",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-3",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nUsing the list of discplines given above, write a for loop that either prints the definition of the discipline, or prints ‚ÄòDiscipline not defined.‚Äô"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#sets",
    "href": "interactive_sessions/2-2_structured_data.html#sets",
    "title": "Session 2-2: Structured Data in Python",
    "section": "2. Sets ",
    "text": "2. Sets \n\nTLDR: Sets are useful for comparing groups of items to determine their overlap or their differences. Sometimes used in data science, but rarely when working with large datasets.\n\nAs opposed to a list or tuple, a set is not a sequence. Although a set is iterable (like the sequences you‚Äôve already met), a set is an unordered collection data type, which means it is not a sequence. However, a set is mutable, which means - like a list - it can be modified after being created. Finally - and most uniquely - a set has no duplicate elements. In this sense, a set in python is very much like a mathematical set.\nWe‚Äôve seen that a list is implemented using [], while a tuple is implemented using ().\nA set is implemented using {}:\nnum_set = {1, 3, 6, 10, 15, 21, 28}\nstr_set = {'hydrology', 'ecology', 'geology', 'climatology'}\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Define set variables\nnum_set = {1, 3, 6, 10, 15, 21, 28}\nstr_set = {'hydrology', 'ecology', 'geology', 'climatology'}\n\n\nAs with all other collections, you can also create a set using the set() function:\nnum_set = set([1, 3, 6, 10, 15, 21, 28, 45, 45, 45, 45, 45])"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-4",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-4",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the set() function to create a set containing the first four prime numbers.\n\n\nCode\nnum_set = set([1, 3, 6, 10, 15, 3, 10, 21, 28])\nprint(num_set)\n\n\n{1, 3, 6, 10, 15, 21, 28}\n\n\n\nMutability \nSets are mutable.\nTo remove an element from a set, use the discard() method:\n\nstr_set.discard('ecology')\n    \nTo add an element from to set, use the add() method:\n\nstr_set.add('oceanography')\n    \nTo add multiple elements to a set at the same time, use the update() method. The items to add should be contained in a list.\n\nstr_set.update(['oceanography', 'microbiology'])"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-5",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-5",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nAdd ‚Äòbiogeochemistry‚Äô and ‚Äòmeteorology‚Äô to str_set and then remove ‚Äòecology‚Äô.\nMany of the same functions that worked on list and tuple also work for a set.\nlen(str_set)\n&gt;&gt;&gt; 4\nThe min() and max() commands can also be used to find the minimum and maximum values in a tuple. For a tuple of strings, this corresponds to the alphabetically first and last elements.\nmin(str_set)\n&gt;&gt;&gt; 'climatology'\n\nmax(str_tuple)\n&gt;&gt;&gt; 'oceanography'"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-6",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-6",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the len(), min(), and max() commands to find the length, minimum, and maximum of num_set.\n\nMixed Data Types in Collections and Sequences \nAs a reminder, it‚Äôs usually a good idea to make sure your sets are all of the same basic data type. The reason is because Python doesn‚Äôt know how to compare the magnitude of different data types.\nWhich is larger: ecology, or the number 3? Python doesn‚Äôt know the answer, and neither do I. If you try to use functions like max or min on a mixed data type set you will get a TypeError exception.\n\nmixed_set = {3, 4, 'ecology', 'biology'}\nmax(mixed_set)\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-49-a4da84ba3cd4&gt; in &lt;module&gt;\n      1 mixed_set = {3, 4, 'ecology', 'biology'}\n----&gt; 2 max(mixed_set)\n\nTypeError: '&gt;' not supported between instances of 'int' and 'str'\n\n\nSet Methods \nGiven their similarity to mathematical sets, there are some specific functions that allow us to compare and combine the contents of different sets.\n\nUnion\nA union of sets contains all the items that are in any of the sets.\nThe union of sets A and B is defined as $ A B $.\n\n\n\nimage\n\n\nodds = {1, 3, 5, 7, 9, 11, 13, 15}\nevens = {2, 4, 6, 8, 10, 12, 14, 16}\n\nintegers = odds.union(evens)\nprint(integers)\n\n&gt;&gt;&gt; {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nknows_python = {'Bart', 'Maggie', 'Homer', 'Lisa', 'Professor Frink', 'Nelson'}\nknows_R = {'Homer', 'Nelson', 'Lisa', 'Marge', 'Ralph', 'Milhouse', 'Ms. Krabappel'}\n\n\n\n\nIntersection\nAn intersection of sets contains all the items that are found in all of the sets.\nThe intersection of sets A and B is defined as $ A B $.\n\n\n\nimage\n\n\n\nsquares = {4, 9, 16, 25, 36, 49}\nmultiples_of_nine = {9, 18, 27, 36, 45}\n\nsquares_divisible_by_nine = squares.intersection(multiples_of_nine)\nprint(squares_divisible_by_nine)\n\n&gt;&gt;&gt; {9, 36}"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-7",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-7",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the intersection() method to determine who knows both python and R.\n\n\nCode\n# knows_both = \n\n\n\nDifference\nAn difference of two sets contains all the items that are in A but not in B.\nThe difference (or relative complement) of set A and B is defined as $ A B $.\n\n\n\nimage\n\n\n\nsquares = {4, 9, 16, 25, 36, 49}\nmultiples_of_nine = {9, 18, 27, 36, 45}\n\nsquares_not_divisible_by_nine = squares.difference(multiples_of_nine)\nprint(squares_not_divisible_by_nine)\n\n&gt;&gt;&gt; {16, 49, 4, 25}\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Because a &lt;b&gt;set&lt;/b&gt; is an &lt;i&gt;unordered&lt;/i&gt; collection, the result of a set function will return elements in an unpredictable order. In the example above, the intersection returned `{16, 49, 4, 25}` rather than `{4, 16, 25, 49}`, which you may have expected."
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-8",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-8",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the difference() method to determine who knows R, but does not know Python.\n\nSymmetric Difference\nThis method returns all the items that are unique to each set.\nThe symmetric difference (or disjunctive union) of sets A and B is A \\triangle B (also sometimes written as A \\oplus B)\n\n\n\nimage\n\n\n\nsquares = {4, 9, 16, 25, 36, 49}\nmultiples_of_nine = {9, 18, 27, 36, 45}\n\nsquares_not_divisible_by_nine = squares.symmetric_difference(multiples_of_nine)\nprint(squares_not_divisible_by_nine)\n\n&gt;&gt;&gt; {16, 49, 18, 4, 25, 27, 45}"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-9",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-9",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the symmetric_difference() method to determine who only knows either R or Python.\n\nAdditional Set Methods: isdisjoint(), issubset(), issuperset()\nThere are three additional set functions that allow you to determine the relationships between two sets. Each of these functions returns either True or False, which means they are Boolean operators.\nisdisjoint() determines if two sets are disjoint. It returns True if the contents of two sets are completely distinct, and False if they have any overlap\nodds.isdisjoint(evens)\n&gt;&gt;&gt; True\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Set &lt;i&gt;A&lt;/i&gt; is &lt;b&gt;disjoint&lt;/b&gt; from set &lt;i&gt;B&lt;/i&gt; if, and only if, the &lt;b&gt;intersection&lt;/b&gt; of &lt;i&gt;A&lt;/i&gt; and &lt;i&gt;B&lt;/i&gt; is &lt;code&gt;None&lt;/code&gt;.\n\nissubset() returns True if the content of set A is a subset of set B, and False if it is not a subset.\n\nprimes = {1, 3, 5, 7, 11}\nprimes.issubset(odds)\n&gt;&gt;&gt; True\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Set &lt;i&gt;A&lt;/i&gt; is a &lt;b&gt;subset&lt;/b&gt; of set &lt;i&gt;B&lt;/i&gt; if, and only if, the &lt;b&gt;intersection&lt;/b&gt; of &lt;i&gt;A&lt;/i&gt; and &lt;i&gt;B&lt;/i&gt; is &lt;i&gt;A&lt;/i&gt;.\n\nissupserset() returns True if the content of set A is a superset of set B, and False if it is not a superset.\n\nodds.issuperset(primes)\n&gt;&gt;&gt; True\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Set &lt;i&gt;A&lt;/i&gt; is a &lt;b&gt;superset&lt;/b&gt; of set &lt;i&gt;B&lt;/i&gt; if, and only if, set &lt;i&gt;B&lt;/i&gt; is a subset of &lt;i&gt;A&lt;/i&gt;.\n\nThere is a lot more to learn about dictionaries, including methods for deleting elements, merging dictionaries, and learning about additional collection types like OrderedDict that allow you to preserve the arrangement of dictionary elements (essentially making them sequences). We will keep coming back to them throughout the class. If you want to learn more, check out the great material in our reading: Dictionaries"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#tuples",
    "href": "interactive_sessions/2-2_structured_data.html#tuples",
    "title": "Session 2-2: Structured Data in Python",
    "section": "3. Tuples ",
    "text": "3. Tuples \n\nTLDR: Tuples are a kind of list that can‚Äôt be altered. They are not very common in data science applications, but you might run across them from time to time. ‚ÄúNamed Tuples‚Äù allow for the creation of simple structured data ‚Äúobjects‚Äù that don‚Äôt require much coding overhead.\n\nTuples are a type of sequence, similar to list, which you‚Äôve already seen. They primary difference between a tuple and a list is that a tuple is immutable, which means that it‚Äôs value cannot be changed once it is defined. A tuple is implemented using ():\nnum_tuple = (4, 23, 654, 2, 0, -12, 4391)\nstr_tuple = ('energy', 'water', 'carbon')\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Define tuple variables\nnum_tuple = (4, 23, 654, 2, 0, -12, 4391)\nstr_tuple = ('energy', 'water', 'carbon')\n\n\nAs with a list, a tuple may contain mixed data types, but this is not usually recommended.\nBecause they are both sequences, tuples and lists share many of the same methods. For example, just like lists, the len() command returns the length of the tuple.\nlen(str_tuple)\n&gt;&gt;&gt; 3\nThe min() and max() commands can also be used to find the minimum and maximum values in a tuple. For a tuple of strings, this corresponds to the alphabetically first and last elements.\nmin(str_tuple)\n&gt;&gt;&gt; 'carbon'\n\nmax(str_tuple)\n&gt;&gt;&gt; 'water'"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-10",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-10",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the len(), min(), and max() commands to find the length, minimum, and maximum of num_tuple.\n\n\nCode\n# Find the length of num_tuple\n\n# Minimum value of num_tuple\n\n# Maximum value of num_tuple\n\n\n\n\n\nOther ways to create tuples\nTuples can also be constructed by:\n\n\nUsing a pair of parentheses to indicate an empty tuple: ()\n\nUsing a trailing comma for a tuple with a single element: a, or (a,)\n\nSeparating items with commas: a, b, c or (a, b, c)\n\nusing the tuple() built-in function: tuple(iterable).\n\n\nüêç &lt;b&gt;Note.&lt;/b&gt; An &lt;i&gt;iterable&lt;/i&gt; is any object that is capable of returning its contents one at a time. Strings are iterable objects, so &lt;code&gt;tuple('abc')&lt;/code&gt; returns &lt;code&gt;('a', 'b', 'c')&lt;/code&gt;.\n\ntuple('earth')\n&gt;&gt;&gt; ('e', 'a', 'r', 't', 'h')"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-11",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-11",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nCreate three separate tuples containing the latitude and longitudes of the following cities:\n\nLos Angeles, CA (34.05, -118.25)\nJohannesburg, South Africa (-26.20, 28.05)\nCairo, Egypt (30.03, 31.23)\nCreate a fourth tuple that is made up of the three tuples (i.e.¬†a ‚Äútuple of tuples‚Äù).\n\n\n\nCode\n# Define a three new tuples, one for each city.\n\n# los_angeles = \n\n# johannesburg = \n\n# singapore = \n\n# Create a new tuple that is a tuple made up of the three city location tuples:\n# tuple_of_tuples = \n\n\n\nIndexing \nAs you learned with lists, any element of a sequence data type can be referenced by its position within the sequence. To access an element in a sequence by its index, use square brackets [].\nIndividual elements of tuples are accessed in the exact same manner as lists:\nnum_tuple[0]\n&gt;&gt;&gt; 4\nnum_tuple[-2]\n&gt;&gt;&gt; -12\nword_tuple = tuple('antidisestablishmentarianism')\n\nword_tuple[14]\n&gt;&gt;&gt; 's'\n\nword_tuple[::3]\n&gt;&gt;&gt; 'aistlhnrnm'"
  },
  {
    "objectID": "interactive_sessions/2-2_structured_data.html#try-it.-12",
    "href": "interactive_sessions/2-2_structured_data.html#try-it.-12",
    "title": "Session 2-2: Structured Data in Python",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse indexing to create a new tuple from the 2nd element in str_tuple. Find the 3rd element of this new tuple.\n\n\nCode\n# new_tuple = \n\n# 3rd element of new_tuple:\n\n\n\n\n\nImmutability \nAll objects in python are either mutable or immutable. A mutable object is one whose value can change. In contrast, an immutable object has a fixed value. You‚Äôve already been introduced to a few immutable objects including numbers, strings and now, tuples. These objects cannot be altered once created.\n\nüêç &lt;b&gt;Note.&lt;/b&gt;  If you attempt to modify the value of an existing tuple, you will get a &lt;code&gt;TypeError&lt;/code&gt; exception from the Python interpreter.\n\nnum_tuple[0] = 3\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input&gt; in &lt;module&gt;\n----&gt; 1 num_tuple[0] = 1\n\nTypeError: 'tuple' object does not support item assignment\n    \n\n\n\n\nTuple Operations \nBecause they are immutable, tuples do not have the same robust set of functions that lists have. Attempting to change a tuple (for example, by trying to append elements) will raise an AttributeError, because the append method isn‚Äôt available to tuple objects.\n\ntuple_of_colors = ('red', 'blue', 'green', 'black', 'white')\ntuple_of_colors.append('pink') # &lt;- UH-OH!\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-8-857308f688f6&gt; in &lt;module&gt;\n----&gt; 1 tuple_of_colors.append('pink')\n\nAttributeError: 'tuple' object has no attribute 'append'\nInstead of appending data to an existing tuple, when you want to change the contents of a tuple, you need to either create a new one, or modify the variable by re-defining it.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ntuple_of_colors = ('red', 'blue', 'green', 'black', 'white')\ntuple_of_colors = tuple_of_colors + ('pink',)\nprint(tuple_of_colors)\n\n\n('red', 'blue', 'green', 'black', 'white', 'pink')\n\n\n\n\n\n\nDIVING DEEPER: Named Tuples \nTuples are convenient for storing information that you do not want to change. However, remembering which index should be used for each value can lead to errors, especially if the tuple has a lot of fields and is constructed far from where it is used.\nAs an example, we created the coordinate location of Cairo, Egypt as:\ncairo_location = (30.03, 31.23)\nBut wait‚Ä¶ Are those coordinates stored (latitude, longitude) or (longitude, latitude)? You might think it is easy to sort this out for most cities, but for Cairo it‚Äôs really difficult!\nPython has an additional immutable collection data type called a namedtuple which assigns names, as well as the numerical index, to each member. The namedtuple is part of the standard python library but it is not immediately available. In order to use the namedtuple data type, you first need to import it to your working environment. We will be using the import command quite a bit in order to extend what python can do and take advantage of all the tools that people have developed for environmental data science. For now, we need to import namedtuple from the collections library within python. The code for that looks like this:\nfrom collections import namedtuple\nOnce we import the namedtuple, we can create a new kind of custom data type that we can use to store our locations:\nLocation = namedtuple('Location', ['latitude', 'longitude'])\nIn the code above, the first argument to the namedtuple function is the name of the new tuple object type you want to create. We called this new object type a Location. The second argument is a list of the field names that the Location objects will have. In general, Location objects on Earth are defined by two pieces of information: the latitude and the longitude.\nNow that we‚Äôve defined this new Location object type, we can create a new Location object using this code:\ncairo_location = Location(latitude=30.03, longitude=31.23)\nNote that this code isn‚Äôt that different than the code we used to make a tuple:\ncairo_location = tuple(30.03, 31.23)\nThe difference is that we are using our custom namedtuple type called Location, and we are able to specify exactly which values correspond to the latitude and longitude fields. We can retrieve any field in our Location tuple by specifying the field:\ncairo_location.latitude\n&gt;&gt;&gt; 30.03\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nfrom collections import namedtuple\n\nLocation = namedtuple('Location', ['latitude', 'longitude'])\ncairo_location = Location(latitude=30.03, longitude=31.23)\ncairo_location.latitude, cairo_location.longitude\n\n\n(30.03, 31.23)"
  },
  {
    "objectID": "interactive_sessions/1-2_lists.html",
    "href": "interactive_sessions/1-2_lists.html",
    "title": "Session 1-2: Lists + Indexing",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nPython has four collection data types, the most common of which is the list. This session introduces lists and a few of the important list operations. We will also cover indexing, a key feature of programming."
  },
  {
    "objectID": "interactive_sessions/1-2_lists.html#lists",
    "href": "interactive_sessions/1-2_lists.html#lists",
    "title": "Session 1-2: Lists + Indexing",
    "section": "Lists",
    "text": "Lists\nA list is a Python object used to contain multiple values. Lists are ordered and changeable. They are defined as follows:\nnum_list = [4, 23, 654, 2, 0, -12, 4391]\nstr_list = ['energy', 'water', 'carbon']\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Define list variables\nnum_list = [4, 23, 654, 2, 0, -12, 4391]\nstr_list = ['energy', 'water', 'carbon']\n\n\nWhile you can create lists containing mixed data types, this is not usually recommended.\nThe len() command returns the length of the list.\nlen(str_list)\n&gt;&gt;&gt; 3\nThe min() and max() commands are used to find the minimum and maximum values in a list. For a list of strings, this corresponds to the alphabetically first and last elements.\nmin(str_list)\n&gt;&gt;&gt; 'carbon'\n\nmax(str_list)\n&gt;&gt;&gt; 'water'\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nUse the &lt;code&gt;len()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;, and &lt;code&gt;max()&lt;/code&gt; commands to find the length, minimum, and maximum of &lt;code&gt;num_list&lt;/code&gt;.\n\n\n\n\nIndexing\nThe index is used to reference a value in an iterable object by its position. To access an element in a list by its index, use square brackets [].\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Python is zero-indexed. This means that the first element in the list is 0, the second is 1, and so on. The last element in a list with $n$ elements is $n - $1.\n\nnum_list[2]\n&gt;&gt;&gt; 654\nYou can also access an element based on its position from the end of the list.\nnum_list[-2]\n&gt;&gt;&gt; -12\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nFind the 2nd element in &lt;code&gt;str_list&lt;/code&gt; in two different ways. Remember that Python is zero-indexed!\n\nAccessing a range of values in a list is called slicing. A slice specifies a start and an endpoint, generating a new list based on the indices. The indices are separated by a :.\n\nüêç &lt;b&gt;Note.&lt;/b&gt;  The endpoint index in the slice is &lt;i&gt;exclusive&lt;/i&gt;. To slice to the end of the list, omit an endpoint.\n\nnum_list[2:6]\n&gt;&gt;&gt; [654, 2, 0, -12]\n\nnum_list[0:4]   \n&gt;&gt;&gt; [4, 23, 654, 2]\n\nnum_list[:4]    \n&gt;&gt;&gt; [4, 23, 654, 2]\n\nnum_list[-6:-1] \n&gt;&gt;&gt; [23, 654, 2, 0,-12]\nIt is also possible to specify a step size, i.e.¬†[start:stop:step]. A step size of 1 would select every element, 2 would select every other element, etc.\nnum_list[0:4:2]  \n&gt;&gt;&gt; [4, 654]\n\nnum_list[::2]    \n&gt;&gt;&gt;[4, 654, 0, 4391]\nA step of -1 returns the list in reverse.\nnum_list[::-1]\n&gt;&gt;&gt; [4391, -12, 0, 2, 654, 23, 4]\nLike lists, strings can also be indexed using the same notation. This can be useful for many applications, such as selecting files in a certain folder for import based on their names or extension.\nword_str = 'antidisestablishmentarianism'\n\nword_str[14]\n&gt;&gt;&gt; 's'\n\nword_str[::3]\n&gt;&gt;&gt; 'aistlhnrnm'\n\n\n\n\nList Operations\nElements can be added to a list using the command list.append().\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ncolors = ['red', 'blue', 'green', 'black', 'white']\n\n\nYou can add an element to a list in a specific position using the command list.insert().\ncolors.insert(4, 'purple')\nprint(colors)\n&gt;&gt;&gt; ['red', 'blue', 'green', 'black', 'purple', 'white', 'pink']\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nAdd &lt;code&gt;'purple'&lt;/code&gt; to the list &lt;code&gt;colors&lt;/code&gt; between &lt;code&gt;'green'&lt;/code&gt; and &lt;code&gt;'black'&lt;/code&gt;.\n\nThere are multiple ways to remove elements from a list. The commands list.pop() and del remove elements based on indices.\ncolors.pop()       # removes the last element\ncolors.pop(2)      # removes the third element\ndel colors[2]      # removes the third element\ndel colors[2:4]    # removes the third and fourth elements\nThe command list.remove() removes an element based on its value.\ncolors.remove('red')\nprint(colors)\n&gt;&gt;&gt; ['blue', 'green', 'black', 'purple', 'white', 'pink']\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nRemove &lt;code&gt;'pink'&lt;/code&gt; and &lt;code&gt;'purple'&lt;/code&gt; from &lt;code&gt;colors&lt;/code&gt;, using &lt;code&gt;del&lt;/code&gt; for one of the strings and &lt;code&gt;list.remove()&lt;/code&gt; for the other.\n\nYou can sort the elements in a list (numerically or alphabetically) in two ways. The first uses the command list.sort().\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nrand_list = [5.1 , 3.42 , 3.333 , 100.4 , 0.5 , 26.0 , 7.44 , 5.8 , 39.0]\nrand_list.sort()\nprint(rand_list)\n\n\nSetting reverse=True within this command sorts the list in reverse order:\nrand_list = [5.1 , 3.42 , 3.333 , 100.4 , 0.5 , 26.0 , 7.44 , 5.8 , 39.0]\nrand_list.sort(reverse=True)\nprint(rand_list)\n&gt;&gt;&gt; [100.4, 39.0, 26.0, 7.44, 5.8, 5.1, 3.42, 3.333, 0.5]\nSo far, all of the list commands we‚Äôve used have been in-place operators. This means that they perform the operation to the variable in place without requiring a new variable to be assigned. By contrast, standard operators do not change the original list variable. A new variable must be set in order to retain the operation.\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nVerify that &lt;code&gt;rand_list&lt;/code&gt; was, in fact, sorted in place by using the &lt;code&gt;min()&lt;/code&gt; and &lt;code&gt;max()&lt;/code&gt; functions to determine the minmum and maximum values in the list and printing the first and last values in the list.\n\n\n\nCode\n# Print the min and max values in rand_list.\n\n# Print the first and last values in rand_list.\n\n\nThe other method of sorting a list is to use the sorted() command, which does not change the original list. Instead, the sorted list must be assigned to a new variable.\nrand_list = [5.1 , 3.42 , 3.333 , 100.4 , 0.5 , 26.0 , 7.44 , 5.8 , 39.0]\nsorted_list = sorted(rand_list)\nprint(rand_list[0])\nprint(sorted_list[0])\n&gt;&gt;&gt; 5.1\n    0.5\nTo avoid changing the original variable when using an in-place operator, it is wise to create a copy. There are multiple ways to create copies of lists, but it is important to know the difference between a true copy and a view. A view of a list can be created as follows:\nstr_list = ['energy', 'water', 'carbon']\nstr_list_view = str_list\nAny in-place operation performed on str_list_view will also be applied to str_list. To avoid this, create a copy of str_list using any of the following methods:\nstr_list_copy = str_list.copy()\n# or\nstr_list_copy = str_list[:]\n# or\nstr_list_copy = list(str_list)\nIn addition to adding single elements to a list using list.append() or list.insert(), multiple elements can be added to a list at the same time by adding multiple lists together.\nrainbow  = ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']\nshades = ['coral', 'chartreuse', 'cyan', 'navy']\nprint( rainbow + shades )\n&gt;&gt;&gt; ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet', 'coral', 'chartreuse', 'cyan', 'navy']\nSingle lists can be repeated by multiplying by an integer.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nstr_list2 = str_list * 2\nnum_list4 = num_list * 4\nprint( str_list2 )\nprint( num_list4 )\n\n\n\n\nGenerating sequential lists\nSequential lists are valuable tools, particularly for iteration, which we will explore in the next session. The range() function is used to create an iterable object based on the size of an integer argument.\nrange(4)\n&gt;&gt;&gt; range(0, 4)\nTo construct a sequential list from the range() object, use the list() function.\nlist(range(4))\n&gt;&gt;&gt; [0, 1, 2, 3]\nUsing multiple integer arguments, the range() function can be used to generate sequential lists between two bounds: range(start, stop [, step]).\n\nüêç &lt;b&gt;Note.&lt;/b&gt; \nLike indexing, all Python functions using &lt;span style=\"font-style: italic\"&gt; start &lt;/span&gt; and &lt;span style=\"font-style: italic\"&gt; stop &lt;/span&gt; arguments, the &lt;span style=\"font-style: italic\"&gt; stop &lt;/span&gt; value is &lt;span style=\"font-weight: bold\"&gt; exclusive &lt;/span&gt;.\n\nrange_10 = list(range(1,11))\nodds_10 = list(range(1,11,2))\nprint(range_10)\nprint(odds_10)\n&gt;&gt;&gt; [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    [1, 3, 5, 7, 9]"
  },
  {
    "objectID": "interactive_sessions/survey_responses.html",
    "href": "interactive_sessions/survey_responses.html",
    "title": "Entry survey response visualizations in Python written with ChatGPT‚Äôs help",
    "section": "",
    "text": "Code\n# load libraries  -- make sure to activate your eds 217 environment first!\nimport pandas as pd\nimport matplotlib.pyplot as plt\nCode\n# load in your data\ndf = pd.read_csv('../data/entry_survey_responses_2023.csv')\nprint(df.columns)\n\n\nIndex(['In terms of programming in general, I consider myself to be',\n       'In terms of python in particular, I have',\n       'In terms of my confidence in my ability to use python programming language, I am:',\n       'In terms of my confidence with using python data science libraries, I am: ',\n       'In terms of my confidence with python computing tools such as conda, jupyter notebooks, and IDEs such as Visual Studio Code, I am:',\n       'I find that I learn coding best by [Studying independently]',\n       'I find that I learn coding best by [Working in small groups]',\n       'I find that I learn coding best by [Following along through examples ]',\n       'I find that I learn coding best by [Tinkering with code myself]',\n       'I find that I learn coding best by [Open-ended exercises]',\n       'I find that I learn coding best by [Focused practice sessions]'],\n      dtype='object')"
  },
  {
    "objectID": "interactive_sessions/survey_responses.html#ask-chatgpt-for-help",
    "href": "interactive_sessions/survey_responses.html#ask-chatgpt-for-help",
    "title": "Entry survey response visualizations in Python written with ChatGPT‚Äôs help",
    "section": "Ask ChatGPT for help",
    "text": "Ask ChatGPT for help\nI wanted to make a some plots of the first two columns, so I asked chatGPT the following:\nI have a pandas dataframe with the following two columns with numeric 1-5 values. Make histograms using matplotlib to visualize this data: ‚Äú‚ÄòIn terms of programming in general, I consider myself to be‚Äô, ‚ÄòIn terms of python in particular, I have‚Äô‚Äù\nIt gave me the code below:\n\n\nCode\n# Create the first histogram\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.hist(df['In terms of programming in general, I consider myself to be'], bins=5, edgecolor='black')\nplt.title('Programming in General')\nplt.xlabel('Skill Level (1-5)')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 6))\n\n# Create the second histogram\nplt.subplot(1, 2, 2)\nplt.hist(df['In terms of python in particular, I have'], bins=5, edgecolor='black')\nplt.title('Python in Particular')\nplt.xlabel('Skill Level (1-5)')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 6))\n\n# Show the plots\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "interactive_sessions/survey_responses.html#ask-chatgpt-to-modify-its-output",
    "href": "interactive_sessions/survey_responses.html#ask-chatgpt-to-modify-its-output",
    "title": "Entry survey response visualizations in Python written with ChatGPT‚Äôs help",
    "section": "Ask ChatGPT to modify its output",
    "text": "Ask ChatGPT to modify its output\nI didn‚Äôt like that the skill level wasn‚Äôt centered around the integers so I followed up with ChatGPT:\n‚Äúthe skill level is an integer value not continuous‚Äù\nIt responded with the following code modifications:\n\n\nCode\n# Create histograms with bars centered at integers\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.hist(df['In terms of programming in general, I consider myself to be'], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], edgecolor='black', alpha=0.7)\nplt.title('Programming in General')\nplt.xlabel('Skill Level (1-5)')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 6))\n\nplt.subplot(1, 2, 2)\nplt.hist(df['In terms of python in particular, I have'], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], edgecolor='black', alpha=0.7)\nplt.title('Python in Particular')\nplt.xlabel('Skill Level (1-5)')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 6))\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "interactive_sessions/survey_responses.html#read-understand-and-modify-chatgpt-code",
    "href": "interactive_sessions/survey_responses.html#read-understand-and-modify-chatgpt-code",
    "title": "Entry survey response visualizations in Python written with ChatGPT‚Äôs help",
    "section": "Read, understand, and modify ChatGPT code",
    "text": "Read, understand, and modify ChatGPT code\nI liked these plots, but now I want to make similar graphs for the next three columns. Let‚Äôs see if we can adapt the code above to make that plot.\n\n\nCode\n# Create histograms with bars centered at integers\nplt.figure(figsize=(18, 6))\n\nplt.subplot(1, 3, 1)\nplt.hist(df['In terms of my confidence in my ability to use python programming language, I am:'], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5], edgecolor='black', alpha=0.7)\nplt.title('Python')\nplt.xlabel('Confidence')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 11))\n\nplt.subplot(1, 3, 2)\nplt.hist(df['In terms of my confidence with using python data science libraries, I am: '], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5], edgecolor='black', alpha=0.7)\nplt.title('Data Science Libraries')\nplt.xlabel('Confidence')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 11))\n\nplt.subplot(1, 3, 3)\nplt.hist(df['In terms of my confidence with python computing tools such as conda, jupyter notebooks, and IDEs such as Visual Studio Code, I am:'], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5], edgecolor='black', alpha=0.7)\nplt.title('Computing tools (conda, jupyter, VS Code)')\nplt.xlabel('Confidence')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 11))\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "interactive_sessions/survey_responses.html#another-example",
    "href": "interactive_sessions/survey_responses.html#another-example",
    "title": "Entry survey response visualizations in Python written with ChatGPT‚Äôs help",
    "section": "Another example",
    "text": "Another example\nFinally, I worked with ChatGPT to make a graph of the final questions on learning preferences. If you‚Äôre interested, you can see our full conversation here\n\n\nCode\ndf = df.iloc[:, -6:]\n\n# Count the occurrences of each response for each method\ncounts = {}\nfor column in df.columns:\n    counts[column] = df[column].value_counts()\n\n# Define possible responses and initialize counts\nresponses = ['Strongly Disagree', 'Somewhat Disagree', 'Neither Agree or Disagree', 'Somewhat Agree', 'Strongly Agree']\nfor column in df.columns:\n    for response in responses:\n        if response not in counts[column]:\n            counts[column][response] = 0\n\n# Sort the response counts for consistency\nfor column in df.columns:\n    counts[column] = counts[column].loc[responses]\n\n# Prepare data for stacked bar chart\nshort_labels = [s.split('[')[-1].rstrip(']') for s in counts.keys()]  # Shorten the labels\ndata = {}\nfor response in responses:\n    data[response] = [counts[label].get(response, 0) for label in counts.keys()]\n\n# Define gradient colors\ngradient_colors = ['#FF0000', '#FF5500', '#FFAA00', '#FFFF00', '#7FFF00']\n\n# Create the stacked bar chart\nfig, ax = plt.subplots(figsize=(15, 7))\n\nbottoms = [0] * len(short_labels)\nfor i, (response, values) in enumerate(data.items()):\n    ax.bar(short_labels, values, label=response, bottom=bottoms, color=gradient_colors[i])\n    bottoms = [i + j for i, j in zip(bottoms, values)]\n\n# Add some text for labels, title, and axes ticks\nax.set_xlabel('Learning Method')\nax.set_ylabel('Frequency')\nax.set_title('Preferred Learning Methods for Coding')\nax.legend()\n\n# Rotate x-axis labels to prevent overlap\nax.set_xticklabels(short_labels, rotation=45)\n\n# Show the plot\nplt.show()\n\n\n/var/folders/1f/_ptk0jz93h39qj25crwwtb0w0000gn/T/ipykernel_15649/2467521698.py:43: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.set_xticklabels(short_labels, rotation=45)"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html",
    "href": "interactive_sessions/99_functions_objects_classes.html",
    "title": "Session 1-5: Functions & Classes",
    "section": "",
    "text": "In order to effecitvely use Python, we need to learn how to use functions and classes.\nFunctions are a fundamental part of almost any programming language, and Python is no different. We have already been introduced to many of the excellent builtin functions that are part of the standard Python library. However, as you develop your own analyses, you will need to be able to author your own functions. These functions will allow you to create stand-alone pieces of code that perform consistent operations on input data.\nClasses are even more versatile than functions. They are present in almost all object-oriented programming languages and provide a means to bundle functions and data together. Defining a new class creates a new type of object (recall that objects are the fundamental building block of Python), allowing new instances of that object type to be made."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#functions",
    "href": "interactive_sessions/99_functions_objects_classes.html#functions",
    "title": "Session 1-5: Functions & Classes",
    "section": "Functions",
    "text": "Functions\nA function is simply a set of instructions that you wish to use repeatedly on varying data. Sometimes a function is used to group a complex set of instructions that allows you to compartmentalize your code in ways that improve its readability. There are three types of functions in Python: builtin functions, user-defined functions, and anonymous functions. We have already seen many builtin functions, and you will meet many more in the coming weeks. This session focuses on user-defined and anonymous functions, both of which are important for advanced data analysis.\n\nUser-defined Functions (UDFs)\nA UDF is created using some very specific syntax. First, a function is delcared using the def keyword. The name of the function - and any arguments it takes - follows the def keyword, followed by a :. The combination of def and : is a similar construction to other control statements in Python that you‚Äôve already seen, such as for + :, and if + :. The code block below is the simplest possible function.\ndef my_function():\n    pass\nThe pass keyword means ‚Äúdo nothing‚Äù. Therefore, we have defined a function that: (1) does not take any arguments; (2) does nothing, and then (3) returns nothing.\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Technically, a function that lacks a &lt;code&gt;return&lt;/code&gt; statement will still return a value. But the value it returns is &lt;a href=\"https://docs.python.org/3/c-api/none.html\"&gt;&lt;code&gt;None&lt;/code&gt;&lt;/a&gt;, which is python-ese for nothing. Just like the concept of &lt;a href=https://www.amazon.com/Zero-Biography-Dangerous-Charles-Seife/dp/0140296476&gt;`0`&lt;/a&gt;, the concept of &lt;code&gt;None&lt;/code&gt; will turn out to be quite useful!\n\nThe next function below still does not take any arguments and it still doesn‚Äôt do anything. It does, however, include a return statement. As the note above indicates, the return statement isn‚Äôt necessary in Python functions; they will just automatically return None if you don‚Äôt specify otherwise. However, using the return statement is required if you ever want to work with any output from your functions.\ndef my_function():\n    return True\nNext, we can take a look at an example of a function that takes an argument (a) and returns a value (also a)‚Ä¶ but it still doesn‚Äôt actually do anything!\ndef my_function(a):\n    return a\nHopefully your functions will be more useful than the ones above that do nothing. However, we‚Äôve introduced these three ‚Äúdo-nothing functions‚Äù in order to highlight three important aspects of all functions. The ability to (1) pass an argument into a function, (2) transform data within - or based on - the value of a function argument, and (3) return some new data or result based on those manipulations. These three factors combine to make functions extremely useful. Finally the code below provides an example of a function that has all three components and does something that should be quite familiar to you at this point.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ndef my_function(msg):\n    print(msg)\n\nmy_function(\"Hello World\")\n\n\n\n\nCode\n# Define a simple function\ndef convert_F_to_C(temp_F):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\n\nThe function above takes a Temperature in Fahrenheit and converts it to Celsius. It then returns this new value."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nCall the convert_F_to_C() function with the value 98.6 (¬∞F). It should return 37.0.\n\n\nCode\nconvert_F_to_C(98.6)\n\n\n\nFunction Arguments & Parameters\nWhen we define a function, we specify the parameters the function requires. The definition of convert_F_to_C contains a single parameter, temp_F. When we call a function, we supply arguments to the function which are then mapped to the function parameters.\nProviding the argument 98.6 to the function maps this number to the temp_F parameter. So wherever temp_F appears in the function, 98.6 is used instead.\nWhat happens if we call a function without supplying arguments for the parameters?\n\nconvert_F_to_C() # Uh-oh... we didn't provide an argument for the temp_F parameter.\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-3-60e83d2545ed&gt; in &lt;module&gt;\n----&gt; 1 convert_F_to_C()\n\nTypeError: convert_F_to_C() missing 1 required positional argument: 'temp_F'\nIn the error above, we see that not providing a required argument raises a TypeError, and provides some additional detail regarding what went wrong. In this case, we are told that we are mssing one required positional argument, which needs to be assigned to the temp_F parameter.\n\nSpecifying default parameters\nWhen defining a function, it is possible to set a default value for any parameter. This is done by assigning the parameter the default value right inside the parameter list:\ndef convert_F_to_C(temp_F=0):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Functions are no different than variables (or any other object in Python). Therefore, any function you create in a notebook can be re-defined by simply editing the function and re-running the cell!"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-1",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-1",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nRe-define the convert_F_to_C() function so that the default value of temp_F is 0. Test what happens if you call this re-defined function without an argument.\n\n\nCode\ndef convert_F_to_C(temp_F):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\nconvert_F_to_C()\n\n\n\nRequired arguments\nArguments that are included in the parameter list and do not have default values are called required arguments. In the convert_temp_to_C function below, both temp and unit are required parameters.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ndef convert_temp_to_C(temp, unit='F'):\n    \"\"\" Converts a temperature to Celsius\n    \n    Parameters\n    ----------\n        temp : float\n            Temperature value to convert\n        unit : str\n            temp units ('K' or 'F')\n       \n    Returns\n    -------\n        temp_C : float\n            The value of temp converted to Celsius\n            \n    \"\"\"\n    if unit.capitalize() == 'K':\n        temp_C = temp - 273.15\n    elif unit.capitalize() == 'F':\n        temp_C = (temp-32)*5/9\n    \n    return temp_C\n\n\nYou can also see that we have added some comments to the function right below the definition. These commments are known as Docstrings, and they are critical to allow users to understand what your program is doing.\nThe use of \"\"\" to begin and end the docstrings signifies we are writing a multi-line comment (as opposed to # which specifys a single line comment in Python).\nThe first line of a function‚Äôs docstrings should always be a short description of what the function does. The rest of the docstrings should specify the required arguments that the function needs and what values it returns, if any.\n\nüêç &lt;b&gt;The ABC of Python:&lt;/b&gt; Always. Be. Commenting.\n\n\nüêç &lt;b&gt;Note.&lt;/b&gt; You can see the function definition and &lt;b&gt;docstrings&lt;/b&gt; for any function (if they exist) by using the builtin &lt;code&gt;help()&lt;/code&gt; function."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-2",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-2",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nUse the help() function to see the function definition and docstrings for the convert_temp_to_C function.\n\nüìö  &lt;b&gt; Practice 1. &lt;/b&gt; \nCreate a new function, &lt;code&gt;convert_temp_to_K&lt;/code&gt; that converts a temperature to Kelvin from either Fahrenheit or Celsius, depending on user-supplied arguments. \n\n\nKeyword arguments\nIn both convert_temp_to_C and convert_temp_to_K, the order of parameters is very important. If we tried calling the convert_temp_to_C function like this: convert_temp_to_C('F', 212.0) we would get an error! The reason we get an error is because the function definition assumes that the first argument should be mapped to the first parameter temp and the second argument should be mapped to the second parameter unit. That‚Äôs why the TypeError refered to temp_Fas a required positional argument in the section above.\nThis assumption that arguments be mapped to parameters in a specific order can make working with complicated functions that have many parameters almost impossible. For this reason, Python provides the ability to pass keyword arguments to functions.\nRather than making assumptions about how arguments map to parameters based on their order, keyword arguments specify exactly how arguments are mapped to parameters within a function. This is done by assigning an argument to a specific parameter within the function call.\nFor example, instead of writing convert_temp_to_C('F', 212.0), we can instead call the same function using convert_temp_to_C(unit='F', temp=212.0).\n\nüêç Note. Python doesn‚Äôt require you to change anything about a function‚Äôs definition to take advantage of keyword arguments. For this reason, it‚Äôs good practice to use keyword arguments whenever possible."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-3",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-3",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nCall the convert_temp_to_K function that you created using keyword arguments.\nAn important consideration when using keyword arguments is that all keyword arguments must all follow any positional arguments that are passed to a function.\nIn other words, if you are calling a function with a mix of positional arguments and keyword arguments, the positional arguments need to all be listed first.\nSo, using our simple temperature conversion function as an example, convert_temp_to_C(212.0, unit='F') is valid, but convert_temp_to_C(temp=212.0, 'F') is not.\n\nAnonymous (lambda) functions\nSometimes we may just want to create a very simple function without having to go through all the trouble of using def to define the function, writing docstrings and adding a return statement.\nFor these ‚Äúone-liners‚Äù Python has the concept of anonymous functions. Instead of using def, these functions are declared using lambda notation, so they are often refered to as lambda functions.\nBecause they are meant to be simple, a lambda function declaration is always contained in a single line:\nQ = lambda T: 5.67e-8 * T**4\nThe function above calculates the Energy Flux, Q [W/m ^2], for a blackbody object at a specified temperature, T [Kelvin], assuming an emissivity of 1:\nQ = 5.67x10^{-8} \\times T^4\nWe can use this lambda function just like any other function:\nQ(50+273.15)\n&gt;&gt;&gt; 618.3006455416394\n\nüìö  &lt;b&gt; Practice 2. &lt;/b&gt; \nCreate a &lt;code&gt;lambda&lt;/code&gt; function in the cell below that converts a Celsius temperature to Kelvin.&lt;/div&gt;\n\n\n\nDocumenting Functions\nAs we saw above, the use of docstrings can greatly improve your ability to understand what a program requires in terms of arguments and what the function returns.\nThere is no standard for docstrings, but there are some best practices. A good docstring should contain:\n\nA brief description of what the function does.\nA more detailed explanation of how the functions works, if necessary.\nInformation on any arguments - both required and optional - that may be passed into the function.\nInformation on any values that the function returns.\nInformation on any parameter default values.\nInformation on any exceptions that the function raises.\nAny information about side effects the function may cause, or restrictions on when the function can be used.\n\nThe last couple of items on the list above aren‚Äôt very common, but the first four are essential components of all function docstrings. While it is fine to develop your own docstring style, here‚Äôs another example of what a docstring should look like:\ndef Q(T, epsilon=1, unit='C'):\n    \"\"\" Calculates energy emitted by an object with temperature T\n\n    Uses the Stefan-Bolzmann Law to calculate total radiative \n    emmittance in W/m^2 based on temperature and emissivity:\n    \n    Q = epsilon * sigma * T**4\n    \n    where sigma is the Stefan-Boltzmann constant (5.67e-8 W/m^2/K^4),\n    epsilon is the emissitivity (0-1), and T is temperature in Kelvin.\n\n    Parameters\n    ----------\n        T: float\n            Temperature of object\n        epsilon: float, optional\n            emissivity of object [0-1] (default is 1)\n        unit: str, optional\n            units of T, either 'F', 'C', or 'K' (default is 'C')\n    \n    Returns\n    -------\n        Q: float\n            Energy emitted by object [W/m^2]\n    \"\"\"\n\n    # Set Stefan-Boltzmann constant:\n    SIGMA = 5.67e-8 # W/m2/K^4                    \n                \n    # If T is in Fahrenheit, convert to C:\n    if unit == 'F':\n        T = (T - 32) * (5./9.)\n        unit = 'C' # Re-assign unit to C\n        \n    # If T is in Celsius, convert to Kelvin\n    if unit == 'C':\n        T = T + 273.15\n    \n    # Calculate Q and return the value\n    Q = epsilon * SIGMA * T**4\n    return Q"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#practice-3.",
    "href": "interactive_sessions/99_functions_objects_classes.html#practice-3.",
    "title": "Session 1-5: Functions & Classes",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \nWrite a complete set of docstrings for your function, convert_temp_to_K. Check to make sure they work using the help() function."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#classes",
    "href": "interactive_sessions/99_functions_objects_classes.html#classes",
    "title": "Session 1-5: Functions & Classes",
    "section": "Classes",
    "text": "Classes\nClasses are Python objects that contain both attributes (i.e.¬†data) and methods (i.e.¬†functions). Classes are the essence of any object-oriented programming (OOP) language. A Class is created using the class keyword:\n\nclass Temperature:\n    value = 74.0\n    unit = 'F'\n    \nThe above code defines a new class called Temperature. It then assigns two attributes to the class, value and unit. This simple class has no methods. We will get to those next!\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nclass Temperature:\n    value = 74.0\n    unit = 'F'\n\n\n\nCreating an Instance of a Class\nWe create an instance of the class by calling it (like we call a function) and assigning the output of the call to a new variable:\nmy_temp = Temperature()\n\n\nAccessing Class Data\nClass objects are mutable, so it‚Äôs possible to change the data in a class. We can access ‚Äì and alter ‚Äì the attributes of a class using . notation:\nprint(my_temp.value) # Use . notation to access attributes of a class.\n&gt;&gt;&gt; 74.0\n\nmy_temp.value = 83.2  # Assign a new value to this instance of Temperature.\nprint(my_temp.value)  # Check to see if the value has been changed...\n&gt;&gt;&gt; 83.2\n\nüìö  Practice 4.  Create an instance of the Temperature class and print out the string: ‚ÄúThe temperature is 74 ¬∞F‚Äù.\n\n\n\nClass Initialization\nIn the example above, we saw how to create an instance of a Temperature. But you probably noticed that every instance of our class will have the same temperature and unit: 74.0 degress F.\nWhile it‚Äôs possible to change these values later (in python parlance, we‚Äôd say ‚Äúafter the object is instanced‚Äù), it‚Äôd be better if we could initialize our class instances with the values we want. To do this, we will create our first class method, the __init__ method.\n\n\n__init__() method\nThe __init__() method is a special function that we create for classes that tells python how to create a new instance of the class. This function is included as part of a class‚Äôs definition, and usually should be the very first method that appears in the class.\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Python uses the \"double underscore + name + double underscore\" syntax (&lt;code&gt;__&lt;/code&gt; + &lt;code&gt;init&lt;/code&gt; + &lt;code&gt;__&lt;/code&gt;) to define a suite of \"magic\" functions. The exact way to pronounce these strange functions isn't settled, but most people use \"dunder\" to refer to the double underscore, so &lt;code&gt;__init__()&lt;/code&gt; is referred to as the \"dunder init dunder\" function, or \"dunder init\" for short.\n\nThe __init__() function is the initializer method for a Class. It gets passed whatever arguments are provided when a class is created. For example, if we called T = Temperature(10, 'F'), the __init__() method would automatically be passed these two arguments.\nWe define the __init__ method just like any other function, with one difference: It always includes self as its first argument:\n\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n\nWhy self?\nIt‚Äôs not at all obvious why we need to add an extra parameter (which, by convention is always called self ) to the initializer method. Even weirder is the fact that we need to add this extra parameter, self to every class method! To beginning Pythonistas, the concept of self is deeply strange.\nHowever, there is a fairly straight-foward reason for its existence.\nPython functions ‚Äì like functions in most programming languages ‚Äì can only manipulate data that exist within the function itself. Speaking generally, Python functions aren‚Äôt supposed to manipulate data that they haven‚Äôt been passed via argument. The consequences of this ‚Äúseparation of namespaces‚Äù is that ‚Äì paradoxically ‚Äì a class method can‚Äôt operate on class data unless the class data itself is passed into the method!\nBy convention, we use the self parameter to allow us to work with the properties of a class within our class methods. If we didn‚Äôt include this extra parameter, the functions that we write inside of a class wouldn‚Äôt even be able to access the attributes of the class that they were inside of!\nEssentially, you can think of self as a placeholder for a class instance. In fact, Python automatically passes a class instance into any class function whenever that class function is called. The class instance argument is inserted by Python before any other arguments. Therefore, we include the self parameter at the beginning of every class method (remember methods and functions are the same thing), knowing that Python will pass a class instance into our function first, and all of the attributes of that instance will get assigned to the self parameter.\nThere are many, many other explanations out there about the need for the self parameter in class methods.\nBecause the use of self in Python is such a confusing concept, there have also been formal proposals to get rid of self and warnings about its misuse in popular culture.\nThere is even a blog post about the necessity self from the creator of self‚Ä¶ himself.\n\nüêç &lt;b&gt;Bottom Line.&lt;/b&gt; Whenever you write a class function, you will need to include &lt;code&gt;self&lt;/code&gt; as the first positional parameter in the function definition. In addition, whenever you want to access class attributes within a class method, you will need to use &lt;code&gt;self&lt;/code&gt; as the object that contains the data.\n\n\nUsing the __init__() function\nWe almost never call the __init__() function directly. Instead, the Class constructor function calls it for us. We already saw that a class instance is created using the constructor function like my_temp = Temperature(). With our new __init__() function defined for the Temperature class, we can now create Temperature instances with any data we want:\nT = Temperature(83.2, 'F')\nprint(T.value)\n&gt;&gt;&gt; 83.2"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-4",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-4",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nCopy the example code above to create an new Temperature class that contains an init method that sets the value and units. Create a few new Temperature instances with different values and units.\n\nUser Defined Class Methods\nWe often want to create our own methods that allow us to manipulate and work with class data. For example, now that we have a Temperature class, we might want to create a method that allows us to get the value of temperature in any unit. We can add this functionality by defining a class method. The class method is just the same as every other Python function, except, like __init__(), it has self as its first argument:\n\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n        self.temp_K = self.get_K()\n\n    def get_K(self):\n        \n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n            unit = 'C' # Re-assign unit to C\n        \n        # If T is in Celsius, convert to Kelvin\n        if unit == 'C':\n            T = T + 273.15\n\n        return T\n    \nIn this example, we‚Äôve added a class function called get_K that always returns the Temperature object‚Äôs value in degrees Kelvin. You will notice that we can even use this function inside the __init__() function. This means that after creating an instance of an object, we will end up with the temp_K property of the object set for us automatically.\nWe can also run any class methods by calling it directly. Just as we used . notation to access class data, we use . notation to access class methods:\n\nmy_temp = Temperature(50,'C')\nmy_temp.get_K()\n&gt;&gt;&gt; 323.15"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-5",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-5",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nCopy the example code above to create an new Temperature class that contains the get_K method, which is used to set the value of temp_K during intialization. Create a few new Temperature instances with different values and units and test to make sure temp_K is being set correctly.\n\nüìö  &lt;b&gt; Practice 5. &lt;/b&gt; \nUse the cell below to create a new &lt;code&gt;Temperature&lt;/code&gt; class that contains a user-defined class function of your own design. This function can do anything you want. It doesn't need to be fancy or even useful, just make sure you test your function by creating an instance of &lt;code&gt;Temperature&lt;/code&gt; class and running the function.\n\n\nTwo additional - and very useful - Class ‚ÄúMagic‚Äù Methods\nIn addition to the __init__() function, there are some other useful ‚Äúmagic‚Äù class methods. The first, __repr__ is a function that allows you to define how a Class object represents itself. For example, check out this example for a string (str) variable:\n\nSIGMA = 5.67e-8 # Create a variable that contains the Stefan-Boltzmann constant\n\nSIGMA               # What happens if you just execute a line that contains the variable? \n&gt;&gt;&gt; 5.67e-08\nYou see that when the variable SIGMA is invoked, the Python interpreter returns 5.67e-08, which is not exactly what you wrote when you assigned SIGMA. That‚Äôs because what is happening ‚Äúbehind the scenes‚Äù is that Python is calling the __repr__() function for the object SIGMA:\nSIGMA.__repr__()\n&gt;&gt;&gt; 5.67e-08\nThere is a similar magic function, __str__() that is called whenever print() is invoked on an object:\nprint(SIGMA)\n&gt;&gt;&gt; 5.67e-08\n\nSIGMA.__str__()\n&gt;&gt;&gt; 5.67e-08\nIn the case of float variables (type(SIGMA) is float), __repr__() and __str__() return the same thing. But they don‚Äôt have to. Look at this example, using a datetime object, which is part of the standard Python library and the primary object for dealing with time/date information in Python:\nfrom datetime import datetime\n\ncurrent_time = datetime.now()\n\ncurrent_time\n&gt;&gt;&gt; datetime.datetime(2020, 4, 17, 12, 50, 52, 778357) # Your time will be different!\n\nprint(current_time)\n&gt;&gt;&gt; 2020-04-17 12:51:38.750213\nWe see that the representation of a datetime object (created by the class‚Äôs __repr__() function) is different than the class‚Äôs __str__() function.\nYou can create these functions inside a class in the same way you created the __init__() function:\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n    def __repr__(self):\n        return \"Temperature({value},¬∞{unit})\".format(value=self.value,unit=self.unit)\n\n    def __str__(self):\n        return \"The temperature is {value} ¬∞{unit}\".format(value=self.value, unit=self.unit)\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;  \nUse the example above to define a new &lt;code&gt;Temperature&lt;/code&gt; class that adds &lt;code&gt;__repr__&lt;/code&gt; and &lt;code&gt;__str__&lt;/code&gt; methods. Test out the &lt;code&gt;__str__()&lt;/code&gt; method by creating an instance and using the &lt;code&gt;print()&lt;/code&gt; command. \n\n\n\nDocumenting Classes\nJust like functions, classes should contain docstrings. The format and content of docstrings is similar to a function, but there is a need for even more description. This is because the docstrings should include information about all of the attributes of the class as well as any class methods that are defined. So for a simple Weather class we might have something like this:\nclass Weather:\n    \"\"\"\n    A class used to represent the weather\n\n    Attributes\n    ----------\n    \n    temperature : float\n        air temperature, in deg-C\n        \n    relative_humidity : float\n        relative humidity, in %\n    \n    pressure : float\n        air pressure, in kPa\n    \n    Methods\n    -------\n    \n    sat_vap_pressure()\n        returns the saturation vapor pressure for the current weather condition\n        \n    \"\"\"\n    \n    def __init__(self, temp, RH, P):\n        \"\"\" \n        Parameters\n        ----------\n        temp : float\n            air temperature, in ¬∞C\n        \n        RH : float\n            relative humidity, in %\n        \n        P : float\n            pressure, in kPa\n        \"\"\"\n        \n        self.temperature = temp\n        self.relative_humidity = RH\n        self.pressure = P \n        \n    def sat_vap_pressure(self):\n        \"\"\" Determines Saturation Vapor Pressure\n        \n        Uses the Tetens equation to estimate saturation vapor pressure (svp) given air Temp.\n        \n        P = 0.61078 * exp((17.27 * T)/(T + 237.3))\n        \n        where P is svp in kPa and T is air temperature in ¬∞C.\n        \n        \n        Returns:\n        --------\n        \n        P, saturation vapor pressure, in kPa\n        \n        \"\"\"\n        from math import exp\n        \n        P = 0.61078 * exp(17.27*self.C)/(self.T + 237.3)\n        \n        return P\n\nüêç ABC!\nNotice how there are more docstrings in this definition than there is code! This is because the concept of abstraction ‚Äì creating classes and functions that represent general concepts and methods ‚Äì requires a high degree of documentation in order for the abstractions to be used correctly.\nThe same code written in a notebook cell (without abstraction) would be easier to read and require much less documentation.\n\n\nüìö  &lt;b&gt; Practice 6. &lt;/b&gt; \nUse the cell below to create a final version of your &lt;code&gt;Temperature&lt;/code&gt; class that includes docstrings. Check to see if your docstrings are working using the &lt;code&gt;help()&lt;/code&gt; function."
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#loading-functions-and-classes",
    "href": "interactive_sessions/99_functions_objects_classes.html#loading-functions-and-classes",
    "title": "Session 1-5: Functions & Classes",
    "section": "Loading functions and classes",
    "text": "Loading functions and classes\nIn the last practice cell, you probably noticed that your class definition is getting pretty large. While it‚Äôs nice to be able to edit this code easily in your notebook, once you have settled on a function or class definition, it is often helpful to move the definitions out of your notebook and just load them when you need them. Python uses the import function to load objects from external libraries and files.\n\nMoving your class definition to a new file"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#practice-7.",
    "href": "interactive_sessions/99_functions_objects_classes.html#practice-7.",
    "title": "Session 1-5: Functions & Classes",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \nFollow the directions below to save your final Temperature class definition into a new file called temperature.py\n\nGo to the JupyterLab File menu and click New -&gt; Text File\n\n\n\nCopy the entire Temperature class definition you created during Practice 5 and paste it into the text file.\nRename the text file temperature.py. You can do this easily by right-clicking on the filename in the file‚Äôs tab (see the image below)\n\n\n\nüêç &lt;b&gt;Note:&lt;/b&gt;Make sure you save your file with the &lt;code&gt;.py&lt;/code&gt; extension and not &lt;code&gt;.txt&lt;/code&gt;. You will know if you saved it correctly if the file appears with python code formating as in the image below:\n\n\n\nSave the new file. This will create a file called temperature.py in your current directory.\n\n\nImporting your class from the temperature.py file.\nAssuming you were able to save your file correctly, and that your Temperature class definition doesn‚Äôt have any errors in it, you can import the Temperature class into your notebook like this:\n\nfrom temperature import Temperature\n\nT = Temperature(98.6, unit='F')"
  },
  {
    "objectID": "interactive_sessions/99_functions_objects_classes.html#try-it.-6",
    "href": "interactive_sessions/99_functions_objects_classes.html#try-it.-6",
    "title": "Session 1-5: Functions & Classes",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nLoad your Temperature class from the temperature.py file using the import command. Make some new Temperature instances to ensure that your class loaded correctly and works okay."
  },
  {
    "objectID": "interactive_sessions/1-1_variables.html",
    "href": "interactive_sessions/1-1_variables.html",
    "title": "Interactive Session: Variables & Operators",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nAll programming languages contain the same fundamental tools: variables, operators, and functions. This session will covers the first two of these basic elements of the Python language."
  },
  {
    "objectID": "interactive_sessions/1-1_variables.html#variables-operators",
    "href": "interactive_sessions/1-1_variables.html#variables-operators",
    "title": "Interactive Session: Variables & Operators",
    "section": "Variables + Operators",
    "text": "Variables + Operators\nVariables are used in Python to create references to an object (e.g.¬†string, float, DataFrame, etc.). Variables are assigned in Python using =.\n\nüêç &lt;b&gt;Note.&lt;/b&gt;\nVariable names should be chosen carefully and should indicate what the variable is used for. Python etiquette generally dictates using lowercase variable names. Underscores are common. Variable names cannot start with a number. Also, there are several names that cannot be used as variables, as they are reserved for built-in Python commands, functions, etc. We will see examples of these throughout this session.\n\n\n\n\nNumbers\nNumbers in Python can be either integers (whole numbers) or floats (floating point decimal numbers).\nThe following syntax is used to define an integer:\nx = 1\ny = 42\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\n# Define variables x and y as integers.\nx = 1\ny = 42\n\n\nThe following syntax is used to define a float:\na = 1.0\nb = 42.0\nc = 23.782043\n###\n\n‚úèÔ∏è Try it. Define variables a, b, and c according to the values above.\n\n\n\nCode\n# Define variables a, b, and c as floats.\na = 1.0\nb = 42.0\nc = 23.782043\n\n\n\n Arithmetic Operators \n\nJust like a calculator, basic arithmetic can be done on number variables. Python uses the following symbols\n\n\n\nSymbol\nTask\n\n\n\n\n+\nAddition\n\n\n-\nSubtraction\n\n\n*\nMultiplication\n\n\n/\nDivision\n\n\n%\nModular\n\n\n//\nFloor division\n\n\n**\nPower\n\n\n\n###\n\n‚úèÔ∏è Try it. Practice these arithmetic operations by running the code in the cell below. Feel free to add more to test the operators. Use the print() command to output your answers.\n\n\n\nCode\n# Do some math.\n\n\nNotice that the order of operations applies.\n\n Boolean Operators \n\nBoolean operators evaluate a condition between two operands, returning True if the condition is met and False otherwise. True and False are called booleans.\n\n\n\nSymbol\nTask\n\n\n\n\n==\nEquals\n\n\n!=\nDoes not equal\n\n\n&lt;\nLess than\n\n\n&gt;\nGreater than\n\n\n&lt;=\nLess than or equal to\n\n\n&gt;=\nGreater than or equal to\n\n\n\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( b &gt;= a )\nprint( 87 &lt; -2 )\nprint( c != 0 )\nprint( y == x)\n\n\n\n Built-in functions \n\nPython has a number of built-in functions. Here we will introduce a few of the useful built-in functions for numerical variables.\nThe type() function is used to check the data type of a variable. For numerical arguments, either float or int is returned.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\n\n\n\n1\n\n\nThe isinstance() function is used to determine whether an argument is in a certain class. It returns a boolean value. Multiple classes can be checked at once.\nisinstance(12, int)\n&gt;&gt;&gt; True\n\nisinstance(12.0,int)\n&gt;&gt;&gt; False\n\nisinstance(12.0,(int,float))\n&gt;&gt;&gt; True\nThe commands int() and float() are used to convert between data types.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( float(y) )\nprint( int(c) )\n\n\nNotice that when converting a float value to an integer, the int() command always rounds down to the nearest whole number.\nTo round a float to the nearest whole number, use the function round(). You can specify the number of decimal places by adding an integer as an argument to the round() function .\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( round(c) )\nprint( round(c,3) )\n\n\nThe complex() function is used to define a complex number. We won‚Äôt be using complex numbers in this course, but it‚Äôs important to know that python is happy to handle them.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nd = complex('5+2j')\n\n\nTo return the absolute value of a number, use the abs() function.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( abs(d) )\nprint( abs(-12) )\n\n\nThe divmod() function returns the quotient and remainder of two input operands in a tuple. (Tuples are another data type that we will cover later.)\ndivmod(64, 4.2)\nOutput:\n(15.0, 0.9999999999999973)\n\nThe pow() function is an alternative to the ** operator for raising a number to an exponent, i.e.¬†x^y. An optional third argument is used to return the modulus (%) of the power of a number, i.e.¬†x^y % z.\npow(8,2)\nOutput:\n64\npow(8,2,3)\nOutput:\n1\n\n\n\n\nStrings\nPieces of text in Python are referred to as strings. Strings are defined with either single or double quotes. The only difference between the two is that it is easier to use an apostrophe with double quotes.\nmytext = 'This is a string.'\nmytext2 = \"This is also a string.\"\nTo use an apostrope or single quotes inside a string defined by single quotes (or to use double quotes), use a single backslash ( \\ ) referred to as an ‚Äúescape‚Äù character.\nq1a = \"What is Newton's 1st law of motion?\"\nq1b = 'What is Newton\\'s 1st law of motion?'\n\n Built-in functions \n\nJust like the int() and float commands, the str() command converts a number to a string.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nystr = str(y)\n\n\nThe + operator can be used to combine two or more strings.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\ns = 'isaac' + ' ' + 'newton'\n\n\nThe commands string.upper() and string.capitalize() can be used to convert all letters in the string to uppercase and capitalize the first letter in the string, respectively.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( s.upper() )\nprint( s.capitalize() )\n\n\n\n Formatted print statements \n\nPython uses C-style formatting to create new, formatted strings with the % operator. This is useful for printing variables in functions and when asking for user input, both of which we will discuss later. Formatted print statements contain a string argument with one of the following specifiers:\n\n\n\nSymbol\nTask\n\n\n\n\n%s\nStrings\n\n\n%d\nIntegers\n\n\n%f\nFloating point numbers\n\n\n\nThe second argument can contain a variable name or a tuple, which is a list of a fixed size. The arguments are separated by the % operator.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\ncity = 'Santa Barbara'\nyrs = 3\nprint( 'I live in %s.' % city )\nprint( 'I have lived in %s for %d years.' % (city,yrs))\n\n\n\n\nCode\n# Define the variable info.\ninfo = (first, age)\n# Complete the sentence to be printed\nsentence = \"My name...\"\n# Print\nprint( sentence % info)\n\n\nWhen printing floats, the %f argument specifier can be accompanied by a number of decimal places to print only a certain number of digits.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nimport math\npi_sqrt = math.sqrt(math.pi)\nprint(\"The square root of pi is %f.\" % pi_sqrt)\nprint(\"The square root of pi is %.2f.\" % pi_sqrt)\n\n\n\n\nThe input() function allows for user input within a script or program. Importantly, when Python prompts the user for input, the input is stored as a string, regardless of what it is. Thus, if you write a function (a type of object we will explore in a future session) prompting the user for a number, you must be sure to convert the variable storing the input to an integer or float.\nTo demonstrate this, run the following cell, entering the month in which you were born in numerical format (e.g.¬†if you were born in April, your input would be 4) when prompted.\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nmonth_in = input('Month of birth (1-12): ')\ntype(month_in)"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#open-a-terminal",
    "href": "interactive_sessions/jupyter_setup.html#open-a-terminal",
    "title": "jupyter setup for EDS 217",
    "section": "Open a terminal",
    "text": "Open a terminal\nWindows: Open PowerShell or Command Prompt\nMac/Linux: Open Terminal"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#activate-the-eds217_2023-environment",
    "href": "interactive_sessions/jupyter_setup.html#activate-the-eds217_2023-environment",
    "title": "jupyter setup for EDS 217",
    "section": "Activate the EDS217_2023 environment",
    "text": "Activate the EDS217_2023 environment\nconda activate eds217_2023"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#change-directory-to-the-root-of-the-class-repository",
    "href": "interactive_sessions/jupyter_setup.html#change-directory-to-the-root-of-the-class-repository",
    "title": "jupyter setup for EDS 217",
    "section": "Change directory to the root of the class repository",
    "text": "Change directory to the root of the class repository\ncd path/to/eds217_2023\nNote: Your path will be different depending on where you cloned your repo in the previous step.\nYou can find the path by right-clicking on the folder in the file explorer and selecting ‚ÄúProperties‚Äù (Windows) or ‚ÄúGet Info‚Äù (Mac)."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#launch-the-server",
    "href": "interactive_sessions/jupyter_setup.html#launch-the-server",
    "title": "jupyter setup for EDS 217",
    "section": "Launch the server",
    "text": "Launch the server\njupyter notebook\nA browser window should open automatically. If it doesn‚Äôt, you can copy the URL from the terminal and paste it into your browser."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#creating-a-new-notebook",
    "href": "interactive_sessions/jupyter_setup.html#creating-a-new-notebook",
    "title": "jupyter setup for EDS 217",
    "section": "Creating a new notebook",
    "text": "Creating a new notebook\nYou can create a new notebook by clicking the ‚ÄúNew‚Äù button in the upper right corner of the file browser and selecting ‚Äúnotebook‚Äù. This will create a new notebook in the current directory. The default name is Untitled.ipynb. We can change that later, so for now, just open the file by clicking on it."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#selecting-a-kernel",
    "href": "interactive_sessions/jupyter_setup.html#selecting-a-kernel",
    "title": "jupyter setup for EDS 217",
    "section": "Selecting a kernel",
    "text": "Selecting a kernel\nA kernel is the ‚Äúcomputational engine‚Äù that runs your notebook. It is the thing that actually executes the code you write. When you open a new notebook, you will be prompted to select a kernel. Select the eds217_2023 kernel. You can set our class environment as the default kernel by clicking the ‚ÄúAlways start the preferred kernel‚Äù button."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#the-notebook-interface",
    "href": "interactive_sessions/jupyter_setup.html#the-notebook-interface",
    "title": "jupyter setup for EDS 217",
    "section": "The notebook interface",
    "text": "The notebook interface\nIf everything has gone to plan, you should now be seeing a browser window that looks a lot like this:\n\n\n\nnotebook interface\n\n\nLet‚Äôs take a quick tour of the interface together.\n\nThe title bar\nThe title bar is the row of text at the top of the notebook. It contains the name of the notebook as well as the time since the last save (or ‚ÄúCheckpoint‚Äù). You can change the name of the notebook by clicking on the name and typing a new one.\nChange the title of your notebook to test_environment\n\n\nThe toolbar\nThe toolbar is the row of buttons at the top of the notebook. It contains buttons for saving the notebook, adding cells, running cells, and more. We‚Äôll go over these in more detail later. For now, the important point to notice is the text at the far right of the toolbar. It should say eds217_2023. This is the name of the kernel that is running your notebook. If you click on it, you can change the kernel (but don‚Äôt do that now!)"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#saving-a-notebook",
    "href": "interactive_sessions/jupyter_setup.html#saving-a-notebook",
    "title": "jupyter setup for EDS 217",
    "section": "Saving a notebook",
    "text": "Saving a notebook\nYou save a notebook by clicking the ‚ÄúSave‚Äù button in the upper left corner of the toolbar (it looks like a floppy disk). Do this now. You will see the ‚ÄúLast Checkpoint‚Äù update:\n\n\n\nlast checkpoint"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#working-with-cells",
    "href": "interactive_sessions/jupyter_setup.html#working-with-cells",
    "title": "jupyter setup for EDS 217",
    "section": "Working with cells",
    "text": "Working with cells\nThere are two cell types in a jupyter notebook: code cells and markdown cells. Code cells are for writing code, and markdown cells are for writing text. You can change the type of a cell by clicking on the dropdown menu in the toolbar and selecting the type you want.\nThe notebook has been initialized with a single cell. You can tell it‚Äôs a code cell because it has [ ]: to the left of it. We want a markdown cell instead, so we can add a title to this notebook and describe what it‚Äôs for.\nChange the cell type to markdown by clicking the dropdown menu in the toolbar and selecting ‚ÄúMarkdown‚Äù\nYou can now type text into the cell. Try typing a title for the notebook and a short description of what it‚Äôs for. You can use markdown syntax to format the text. If you need a refresher on markdown syntax, you can find one here.\n\n\n\nmarkdown cell"
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#running-a-cell",
    "href": "interactive_sessions/jupyter_setup.html#running-a-cell",
    "title": "jupyter setup for EDS 217",
    "section": "Running a cell",
    "text": "Running a cell\nOnce you‚Äôve written your text, you can render it by running the cell. You can do this by clicking the ‚ÄúRun‚Äù button in the toolbar, or by pressing Shift+Enter. Do this now.\n\n\n\nrendered markdown cell\n\n\nNote: You can always edit the cell again by double-clicking on it. Re-rendering the cell by running it again will update the cell output."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#adding-a-cell-to-a-notebook",
    "href": "interactive_sessions/jupyter_setup.html#adding-a-cell-to-a-notebook",
    "title": "jupyter setup for EDS 217",
    "section": "Adding a cell to a notebook",
    "text": "Adding a cell to a notebook\nYou can add a cell to a notebook by clicking the ‚Äú+‚Äù button in the toolbar. This will add a cell below the currently selected cell.\nYou can also add a cell above +[] or below []+ the currently selected cell by clicking the buttons in the cell‚Äôs toolbar on the far right. These buttons have keyboard shortcuts (A) and (‚ÄòB‚Äô).\nPress B to add a cell below the currently selected cell\nThe default new cell type is code."
  },
  {
    "objectID": "interactive_sessions/jupyter_setup.html#deleting-a-cell",
    "href": "interactive_sessions/jupyter_setup.html#deleting-a-cell",
    "title": "jupyter setup for EDS 217",
    "section": "Deleting a cell",
    "text": "Deleting a cell\nYou can delete a cell by clicking the scissors button in the toolbar. This will delete the currently selected cell. There is also a trashcan icon in the cell toolbar that will delete the cell. Finally, you can also use the keyboard shortcut D,D (press D twice).\nPractice adding, deleting, and changing the type of cells until you are comfortable with the process"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html",
    "href": "interactive_sessions/3-1_numpy.html",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nHaving covered the basics of Python, we will now explore its applications for data science. Bypassing the hype, data science is an interdisciplinary subject that lies at the intersection of statistics, computer programming, and domain expertise. It is best to think of data science not as a new field of knowledge itself, but rather as a set of skills for analysing and interrogating datasets within your existing area of expertise ‚Äì¬†in our case, environmental science and management.\nPython‚Äôs extensive, active ‚Äúecosystem‚Äù of packages like NumPy, Pandas, SciPy, and Matplotlib ‚Äì¬†all of which we will explore in this next set of sessions ‚Äì¬†lends itself well to data analysis and scientific computing. In addition, this section outlines techniques for importing, manipulating, visualizing, and exporting data in Python.\nWhile data come in a wide variety of formats, it is useful to conceptualize all data as arrays of numbers (recall the spreadsheet analogy from Session 1-4). For example, an image is, at its core, a two-dimensional array of numbers representing the brightness of each pixel across the image area. When envisioned this way, it is easy to see how the image can be transformed and analysed by manipulating values in the array:"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#introduction-to-numpy",
    "href": "interactive_sessions/3-1_numpy.html#introduction-to-numpy",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "Introduction to NumPy",
    "text": "Introduction to NumPy\n\nNumPy, an abbreviation for Numerical Python, is the core library for scientific computing in Python. In addition to manipulation of array-based data, NumPy provides an efficient way to store and operate on very large datasets. In fact, nearly all Python packages for data storage and computation are built on NumPy arrays.\nThis exercise will provide an overview of NumPy, including how arrays are created, NumPy functions to operate on arrays, and array math. While most of the basics of the NumPy package will be covered here, there are many, many more operations, functions, and modules. As always, you should consult the NumPy Docs to explore its additional functionality.\nBefore jumping into NumPy, we should take a brief detour through importing libraries in Python. While most packages we will use ‚Äì including NumPy ‚Äì¬†are developed by third-parties, there are a number of ‚Äústandard‚Äù packages that are built into the Python API. The following table contains a description of a few of the most useful modules worth making note of.\n\n\n\n\n\n\n\n\nModule\nDescription\nSyntax\n\n\n\n\n os \nProvides access to operating system functionality\n import os \n\n\n math \nProvides access to basic mathematical functions\n import math \n\n\n random \nImplements pseudo-random number generators for various distributions\n import random \n\n\n datetime \nSupplies classes for generating and manipulating dates and times\n import datetime as dt \n\n\n\n\nüêç &lt;b&gt;Import syntax.&lt;/b&gt; \nAs we've seen already, modules and packages can be loaded into a script using an &lt;code&gt;import&lt;/code&gt; statement: &lt;code&gt;import [module]&lt;/code&gt; for the entire module, or &lt;code&gt;from [module] import [identifier]&lt;/code&gt; to import a certain class of the module. All modules and packages used in a program should be imported at the beginning of the program.\nMany packages are imported with standard abbreviations (such as dt for the datetime module) using the following syntax:\n\nimport [module] as [name]\n\nThe standard syntax for importing NumPy is:\n\nimport numpy as np\n\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nimport numpy as np\n\n\n\nNumPy Arrays\n\n\nThe n-dimensional array object in NumPy is referred to as an ndarray, a multidimensional container of homogeneous items ‚Äì¬†i.e.¬†all values in the array are the same type and size. These arrays can be one-dimensional (one row or column vector), two-dimensional (m rows x n columns), or three-dimensional (arrays within arrays).\n\n Constructing arrays from lists \n\nThere are two main ways to construct NumPy arrays. The first involves using the np.array() function to generate an array from one or more lists:\nnp.array([8,0,9,1,4])\n&gt;&gt;&gt; array([8, 0, 9, 1, 4])\nRecall that unlike lists, all elements within an array must be of the same type. If the types do not match, NumPy will ‚Äúupcast‚Äù if possible (e.g.¬†convert integers to floats):\nnp.array([8.14,0.12,9,1.77,4])\n&gt;&gt;&gt; array([8.14, 0.12, 9.  , 1.77, 4.  ])\nIn these examples, we have created one-dimensional arrays. By default, elements in a one-dimensional array are cast as rows in a column (i.e.¬†a column vector). If, however, we wanted a row vector instead, we could use double brackets [[]] to create an array with one row and multiple columns:\nnp.array([[8,0,9,1,4]]) # row vector with 5 columns\n&gt;&gt;&gt; array([[8, 0, 9, 1, 4]])\nThis is because NumPy treats the inner element(s) or list(s) as rows. This is easier to see with a multidimensional array:\nnp.array([[3,2,0,1],[9,1,8,7],[4,0,1,6]]) # array with 3 rows x 4 columns\n\n&gt;&gt;&gt; array([[3, 2, 0, 1],\n           [9, 1, 8, 7],\n           [4, 0, 1, 6]])"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-1.",
    "href": "interactive_sessions/3-1_numpy.html#practice-1.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö Practice 1.",
    "text": "üìö Practice 1.\nCreate the following arrays and assign the corresponding variable names:\n\na\n\n\\begin{bmatrix}\n     4 & 5 & 0 & 12 & -1 \\\\\n     8 & -21 & -4 & 6 & 3 \\\\\n     17 & 1 & -13 & 7 & 0\n\\end{bmatrix}\n\nb\n\n\\begin{bmatrix}\n     1.0 & 2.7 & 0 & 0.188 & 4.07 & 0.24\n\\end{bmatrix}\n\nc\n\n\\begin{bmatrix}\n     0.4 \\\\\n     0.8 \\\\\n     1.2 \\\\\n     1.6 \\\\\n     2.0 \\\\\n     2.4\n\\end{bmatrix}\n\n\n\n Constructing arrays using functions \n\nOftentimes, it will be more efficient to construct arrays from scratch using NumPy functions. The np.arange() function is used to generate an array with evenly spaced values within a given interval. np.arange() can be used with one, two, or three parameters to specify the start, stop, and step values. If only one value is passed to the function, it will be interpreted as the stop value:\n# Create an array of the first seven integers \nnp.arange(7)\n&gt;&gt;&gt; array([0, 1, 2, 3, 4, 5, 6])\n\n# Create an array of floats from 1 to 12\nnp.arange(1.,13.)\n&gt;&gt;&gt; array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n\n# Create an array of values between 0 and 20, stepping by 2\nnp.arange(0,20,2)\n&gt;&gt;&gt; array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\nSimilarly, the np.linspace() function is used to construct an array with evenly spaced numbers over a given interval. However, instead of the step parameter, np.linspace() takes a num parameter to specify the number of samples within the given interval:\n# Create an array of 5 evenly spaced values between 0 and 1\nnp.linspace(0,1,5)\n&gt;&gt;&gt; array([0.  , 0.25, 0.5 , 0.75, 1.  ])\nNote that unlike np.arange(), np.linspace() includes the stop value by default (this can be changed by passing endpoint=True). Finally, it should be noted that while we could have used np.arange() to generate the same array in the above example, it is recommended to use np.linspace() when a non-integer step (e.g.¬†0.25) is desired.\n\nüìö  &lt;b&gt; Practice 2. &lt;/b&gt; \n\n\nCreate a new array d of integers the multiples of 3 between 0 and 100.\n\n\nCreate an array f 10 evenly spaced elements between 0 and 2.\n\n\nRe-create array c from Practice 1c using a function. Assign this to variable name g.\n\n\n\nThere are several functions that take a shape argument to generate single-value arrays with specified dimensions passed as a tuple (rows,columns):\n# Create a 1D array of zeros of length 4\nnp.zeros(4)\n&gt;&gt;&gt; array([0., 0., 0., 0.]\n\n# Create a 4 x 3 array filled with zeros\nnp.zeros((4,3))\n&gt;&gt;&gt; array([[0., 0., 0.],\n           [0., 0., 0.],\n           [0., 0., 0.],\n           [0., 0., 0.]])\n\n# Create a 4 x 3 array filled with ones\nnp.ones((4,3))\n&gt;&gt;&gt; array([[1., 1., 1.],\n           [1., 1., 1.],\n           [1., 1., 1.],\n           [1., 1., 1.]])\n\n\n# Create a 4 x 3 array filled with 3.14\nnp.full((4,3),9.87)\n&gt;&gt;&gt; array([[9.87, 9.87, 9.87],\n           [9.87, 9.87, 9.87],\n           [9.87, 9.87, 9.87],\n           [9.87, 9.87, 9.87]])\nThe np.random.rand() function is used to generate n-dimensional arrays filled with random numbers between 0 and 1:\n# Create a 4 x 3 array of uniformly distributed random values\nnp.random.rand(4,3)\n&gt;&gt;&gt; array([[0.17461878, 0.74586348, 0.9770975 ],\n           [0.77861373, 0.28807114, 0.10639001],\n           [0.09845499, 0.36038089, 0.58533369],\n           [0.30983962, 0.74786381, 0.27765305]])\nAs we will see, the np.random.rand() function is very useful for sampling and modeling.\nThe last array-construction function we will consider (but by no means the last in the NumPy API!) is the np.eye() function, which is used to generate the two-dimensional identity matrix:\n# Create a 4 x 4 identity matrix\nnp.eye(4)\n&gt;&gt;&gt; array([[1., 0., 0., 0.],\n           [0., 1., 0., 0.],\n           [0., 0., 1., 0.],\n           [0., 0., 0., 1.]])\nLastly, it‚Äôs worth noting that nearly all of these functions contain an optional dtype parameter, which can be used to specify the data-type of the resulting array (e.g.¬†np.ones((4,3),dtype=int) would return a 4 x 3 array of ones as integers, rather than the default floats)."
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-3.-assign-the-following-to-variables",
    "href": "interactive_sessions/3-1_numpy.html#practice-3.-assign-the-following-to-variables",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 3.  Assign the following to variables:",
    "text": "üìö  Practice 3.  Assign the following to variables:\n\n\nA 5x3 array of ones.\n\n\nA one-dimensional array of 6 zeros.\n\n\nA 7x7 identity array.\n\n\nA random 10x10 array.\n\n\n\nArray Manipulation\n\n\nHaving established how to construct arrays in NumPy, let‚Äôs explore some of the attributes of the ndarray, including how to manipulate arrays. Nearly all data manipulation in Python involves NumPy array manipulation; many other Python data tools like Pandas (Session 2-2) are built on the NumPy array. Thus, while many of the examples below may seem trivial, understanding these operations will be critical to understanding more complex operations and Python data manipulation more broadly.\n\n Array attributes \n\nArray attributes are properties that are intrinsic to the array itself. While there are quite a few attributes of NumPy arrays, the ones we will use most often provide information about the size, shape, and type of the arrays:\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\n ndarray.ndim \nNumber of array dimensions\n\n\n ndarray.shape \nTuple of array dimensions (rows, columns)\n\n\n ndarray.size \nTotal number of elements in the array\n\n\n ndarray.dtype \nData-type of array elements\n\n\n\nFor example, let‚Äôs create a random two-dimensional array and explore its attributes using the above methods.\n# Initialize array\na = np.random.rand(4,7)\n\n# Determine array dimensions\na.ndim\n&gt;&gt;&gt; 2\n\n# Determine array shame\na.shape\n&gt;&gt;&gt; (4, 7)\n\n# Determine array size\na.size\n&gt;&gt;&gt; 28\n\n# Determine data-type\na.dtype\n&gt;&gt;&gt; dtype('float64')"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#try-it.",
    "href": "interactive_sessions/3-1_numpy.html#try-it.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "‚úèÔ∏è  Try it. ",
    "text": "‚úèÔ∏è  Try it. \nConstruct two array vectors, a column vector and a row vector, from the list [8,0,9,1,4], as in the first example. Using the ndarray.ndim and ndarray.shape methods, show the difference between constructing an array with single vs.¬†double brackets."
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-4.-use-array-methods-and-the-array-you-created-in-practice-2a-d-to-count-the-number-of-multiples-of-3-between-0-and-100.",
    "href": "interactive_sessions/3-1_numpy.html#practice-4.-use-array-methods-and-the-array-you-created-in-practice-2a-d-to-count-the-number-of-multiples-of-3-between-0-and-100.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 4.  Use array methods and the array you created in Practice 2a (d) to count the number of multiples of 3 between 0 and 100.",
    "text": "üìö  Practice 4.  Use array methods and the array you created in Practice 2a (d) to count the number of multiples of 3 between 0 and 100.\n\n Indexing + slicing \n\nIndexing arrays is analogous to indexing lists:\n# Initialize a one-dimensional array\nx1 = np.array([8,0,9,1,4])\n\n# Return the value in position 1\nx1[1]\n&gt;&gt;&gt; 0\nWith multidimensional arrays, a tuple of indices can be passed to access the rows and columns of an array: ndarray[row,column]. If a single index is passed, the corresponding row element will be returned:\n# Initialize a two-dimensional array\nx2 = np.array([[3,2,0,1],\n               [9,1,8,7],\n               [4,0,1,6]])\n\n# Return the value of the element in the 2nd row, 3rd column\nx2[1,2]\n&gt;&gt;&gt; 8 \n\n# Return the entire second row\nx2[1]\n&gt;&gt;&gt; array([9, 1, 8, 7])\nSlicing of arrays allows you to access parts of arrays or subarrays. Just like with lists, slicing follows the syntax ndarray[start:stop:step].\n# Return the elements in positions 1-4\nx1[1:]\n&gt;&gt;&gt; array([0, 9, 1, 4])\nFor multidimensional arrays, a tuple of slices is used: ndarray[row_start:row_end:row_step, col_start:col_end:col_step].\n# Return the entire third column\nx2[:,2]\n&gt;&gt;&gt; array([0, 8, 1])\n\n# Return the first two rows and two columns\nx2[:2,:2]\n&gt;&gt;&gt; array([[3, 2],\n           [9, 1]])\n\n# Return all rows and every other column\nx2[:,::2]\n&gt;&gt;&gt; array([[3, 0],\n           [9, 8],\n           [4, 1]])"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-5.",
    "href": "interactive_sessions/3-1_numpy.html#practice-5.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \nUsing the array you created in Practice 3d,\n\n\nPrint all the elements in column 4.\n\n\nPrint all the elements in row 7.\n\n\nExtract the 4x4 subarray at the center of the array and assign it as a new variable.\n\n\nPrint the last two values in column 10."
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-6.",
    "href": "interactive_sessions/3-1_numpy.html#practice-6.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \nCreate a blank 8x8 matrix and fill it with a checkerboard pattern of 0s and 1s using indexing.\n\n\nCode\n&lt;h4 style=\"border:1px; border-style:solid; border-color:black; padding: 0.5em;\"&gt; &lt;span style=\"color:black\"&gt; Array reduction &lt;/span&gt; &lt;/h4&gt;\n\n**Array reduction** refers to the computation of summary statistics on an array ‚Äì i.e. *reducing* an array to a single aggregate value, such as the mean, minimum, maximum, etc. These array reduction methods are similar to those used for lists:\n\n```python\nx2 = np.array([[3,2,0,1],\n               [9,1,8,7],\n               [4,0,1,6]])\n\n# Sum of all values in array\nx2.sum()\n&gt;&gt;&gt; 42\n\n# Maximum value of the array\nx2.max()\n&gt;&gt;&gt; 9\n\n# Minimum value of the array\nx2.min()\n&gt;&gt;&gt; 0\n\n# Mean value of the array\nx2.mean()\n&gt;&gt;&gt; 3.5\n\n# Standard deviation of the array\nx2.std()\n&gt;&gt;&gt; 3.095695936834452\n\n```\n\nAll of these methods can be passed with an *`axis`* argument, which allows for aggregation across the rows or columns of the array. In NumPy ‚Äì as well as the many libraries built on NumPy, axis `0` always refers to the *rows* of an array, while axis `1` refers to the *columns*:\n\n```python\n# Mean of each row (calculated across columns)\nx2.mean(axis=1)\n&gt;&gt;&gt; array([1.5 , 6.25, 2.75])\n\n# Maximum value of each column (calculated across rows)\nx2.max(axis=0)\n&gt;&gt;&gt; array([9, 2, 8, 7])\n```\n\n\n\nüêç &lt;b&gt;Functions vs. Methods.&lt;/b&gt; \nAs we'll explore later in this course, &lt;i&gt;functions&lt;/i&gt; and &lt;i&gt;methods&lt;/i&gt; in Python are essentially the same thing. The key difference, however, is that functions can be called generically, while methods are always attached to and called on objects. It is also worth noting that while a method may alter the object itself, a function &lt;i&gt;usually&lt;/i&gt; simply operates on an object without changing it, and then prints something or returns a value.\nFor each of the array reduction methods demonstrated above, there is a corresponding function. For example, the mean of an array can be calculated using the method ndarray.mean() or the function np.mean(ndarray).\nThese ‚Äì¬†and the many additional ‚Äì aggregation functions in NumPy can be used, not only on arrays, but on any numerical object.\n\n\n Reshaping, resizing, + rearranging arrays \n\nOther useful array operations include reshaping, resizing, and rearranging arrays. The ndarray.reshape() method is used to change the shape of an array:\n# Initialize a one-dimensional array with 16 elements\na = np.arange(1.0,17.0)\n\na\n&gt;&gt;&gt; array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n       14., 15., 16.])\n\n# Reshape array a into a 4x4 array\nb = a.reshape(4,4)\n\nb\n&gt;&gt;&gt; [[ 1.  2.  3.  4.]\n     [ 5.  6.  7.  8.]\n     [ 9. 10. 11. 12.]\n     [13. 14. 15. 16.]]\n\nThere are a few important things to note about the ndarray.reshape() method. First and unsurprisingly, the size of array must be preserved (i.e.¬†the size of the reshaped array must match that of the original array). Secondly, and perhaps more importantly, the ndarray.reshape() method creates a view of the original array a, rather than a copy, which would allow the two variables to exist independently. Because b is a view of a, any changes made to b will also be applied to a:\n# Reset the value in the third row, third column (11.0)\nb[2,2] = 0.0\n\nb\n&gt;&gt;&gt; array([[ 1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.],\n           [ 9., 10.,  0., 12.],\n           [13., 14., 15., 16.]])\n\na\n&gt;&gt;&gt; array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  0., 12., 13., \n           14., 15., 16.])\nUnlike ndarray.reshape(), the ndarray.resize() method operates in-place on the original array. The ndarray.resize() method is used to add or delete rows and/or columns:\n# Initialize a 2 x 3 array\na = np.array([[1,2,3],[4,5,6]])\n\n# Copy the original array\nsmaller = a.copy()\n# Use ndarray.resize() to reshape to a 2x2 array and delete the last two elements\nsmaller.resize(2,2)\n\nsmaller\n&gt;&gt;&gt; array([[1, 2],\n           [3, 4]])\n\n# Copy the original array\nbigger = a.copy()\n# Use ndarray.resize() to reshape to a 6x6 array by adding zeros\nbigger.resize(6,6)\n\nbigger\n&gt;&gt;&gt; array([[1, 2, 3, 4, 5, 6],\n           [0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0]])\n\nüêç &lt;b&gt;Copies vs. Views&lt;/b&gt; \nThis is just one example of many occasions when it is advisable to create a &lt;b&gt;copy&lt;/b&gt; of the original object before manipulating it. Had we not copied &lt;code&gt;a&lt;/code&gt; before resizing it to a 2x2 array, the last two elements would have been permanently deleted, as &lt;code&gt;a&lt;/code&gt; itself would have been resized. A good rule of thumb is to &lt;b&gt;always create a copy&lt;/b&gt; before changing or deleting any data.\n\nOften it is useful to rearrange the elements in an array. The ndarray.transpose() method ‚Äì¬†or simply ndarray.T, transposes the array, switching the rows and columns, while the np.flip(), np.flipud(), and np.fliplr() functions reverse the order of elements in the array along a given axis:\n# Initialize a new 4x5 array\nx = np.array([[4, 2, 0, 1, 5],\n              [9, 4, 1, 3, 0],\n              [6, 0, 8, 5, 9],\n              [7, 3, 2, 7, 4]])\n\n# Transpose rows + columns\nx.T\n&gt;&gt;&gt; array([[4, 9, 6, 7],\n           [2, 4, 0, 3],\n           [0, 1, 8, 2],\n           [1, 3, 5, 7],\n           [5, 0, 9, 4]])\n\n# Flip the array (reverse the order of all elements)\nnp.flip(x)\n&gt;&gt;&gt; array([[4, 7, 2, 3, 7],\n           [9, 5, 8, 0, 6],\n           [0, 3, 1, 4, 9],\n           [5, 1, 0, 2, 4]])\n\n# Flip the array up/down (reverse the order of the rows)\nnp.flipud(x)\n&gt;&gt;&gt; array([[7, 3, 2, 7, 4],\n           [6, 0, 8, 5, 9],\n           [9, 4, 1, 3, 0],\n           [4, 2, 0, 1, 5]])\n\n# Flip the array left/right (reverse the order of the columns)\nnp.fliplr(x)\n&gt;&gt;&gt; array([[5, 1, 0, 2, 4],\n           [0, 3, 1, 4, 9],\n           [9, 5, 8, 0, 6],\n           [4, 7, 2, 3, 7]])\nWhen passed with the axis argument, np.flip() mimics the np.flipud() and np.fliplr() functions:\n# Flip the array over the row axis (same as np.flipud(x))\nnp.flip(x, axis=0)\n&gt;&gt;&gt; array([[7, 3, 2, 7, 4],\n           [6, 0, 8, 5, 9],\n           [9, 4, 1, 3, 0],\n           [4, 2, 0, 1, 5]])\n\n# Flip the array over the column axis (same as np.fliplr(x))\nnp.flip(x, axis=1)\n&gt;&gt;&gt; array([[5, 1, 0, 2, 4],\n           [0, 3, 1, 4, 9],\n           [9, 5, 8, 0, 6],\n           [4, 7, 2, 3, 7]])"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-7.",
    "href": "interactive_sessions/3-1_numpy.html#practice-7.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \n\n\nCreate a 3x3 matrix with values ranging from 0 to 8.\n\n\nReverse the order of elements in your random 10x10 array from excercise 3d.\n\n\n\n Joining + splitting arrays \n\nSo far, we have considered array manipulation routines that operatee on a single array. We will encounter many scenarios in which it is necessary to combine multiple arrays into one or, conversely, to split a single array into two or more separate objects.\nConcatenation in computer programming refers to the process of joining multiple objects end-to-end. The most common way of concatenating arrays in NumPy is with the np.concatenate() function, which takes a tuple of arrays:\n# Initialize a 3x3 array\nx = np.array([[4,2,0],\n              [9,4,1],\n              [6,0,8]])\n# Initialize a 1x3 array\ny = np.array([[2,8,6]])\n\n# Concatenate x and y\nnp.concatenate((x,y))\n&gt;&gt;&gt; array([[4, 2, 0],\n           [9, 4, 1],\n           [6, 0, 8],\n           [2, 8, 6]])\nNote that, by default, np.concatenate() operates along the row axis (0). To concatenate along the column axis, we must specify axis=1 as an argument:\n# Concatenate x and y along the column axis\nnp.concatenate((x,y), axis=1)\n&gt;&gt;&gt; ---------------------------------------------------------------------------\n    ValueError                                Traceback (most recent call last)\n    &lt;ipython-input-65-6c2205ef28d2&gt; in &lt;module&gt;\n          5 y = np.array([[2,8,6,0]])\n          6 \n    ----&gt; 7 np.concatenate((x,y),axis=1)\n\n    &lt;__array_function__ internals&gt; in concatenate(*args, **kwargs)\n\n    ValueError: all the input array dimensions for the concatenation axis must match exactly, but along \n    dimension 0, the array at index 0 has size 3 and the array at index 1 has size 1\nUh-oh! Unsurprisingly, when we tried to concatenate an array with 1 row to an array with 3 rows, we got a ValueError. For np.concatenate() to work, the dimensions must match. Thus, we must first transpose y before adding it to x as a column:\n# Transpose y and concatenate x and y along the column axis\nnp.concatenate((x,y.T),axis=1)\n&gt;&gt;&gt; array([[4, 2, 0, 2],\n           [9, 4, 1, 8],\n           [6, 0, 8, 6]])\nEquivalently, we could use the np.vstack() or np.hstack() function to concatenate directly along the row or column axis, respectively:\n# Stack rows of x and y (same as np.concatenate((x,y), axis=0)\nnp.vstack((x,y))\n&gt;&gt;&gt; array([[4, 2, 0],\n           [9, 4, 1],\n           [6, 0, 8],\n           [2, 8, 6]])\n\n# Stack columns of x and y (same as np.concatenate((x,y), axis=1)\nnp.hstack((x,y.T))\n&gt;&gt;&gt; array([[4, 2, 0, 2],\n           [9, 4, 1, 8],\n           [6, 0, 8, 6]])"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-8.",
    "href": "interactive_sessions/3-1_numpy.html#practice-8.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 8. ",
    "text": "üìö  Practice 8. \nCreate two random 1-D arrays of length 10. Merge them into a 2x10 array and then a 10x2 array.\nConversely, splitting allows you to breakdown a single array into multiple arrays. Splitting is implemented with the np.split(), np.vsplit(), and np.hsplit() functions.\n# Initialize a 4x3 array\nz = np.array([[4, 2, 0],\n              [9, 4, 1],\n              [6, 0, 8],\n              [2, 8, 6]])\n\n# Split z into two arrays at row 1\nnp.split(z,[1])\n&gt;&gt;&gt; [array([[4, 2, 0]]), array([[9, 4, 1],\n                                [6, 0, 8],\n                                [2, 8, 6]])]\n\n# OR\nnp.vsplit(z,[1])\n&gt;&gt;&gt; [array([[4, 2, 0]]), array([[9, 4, 1],\n                                [6, 0, 8],\n                                [2, 8, 6]])]\n\n# Split z into two arrays at column 1\nnp.hsplit(z,[1])\n&gt;&gt;&gt; [array([[4],\n            [9],\n            [6],\n            [2]]), \n     array([[2, 0],\n            [4, 1],\n            [0, 8],\n            [8, 6]])]\nMultiple indices can be passed to the np.split() and related functions, with n indices (split points) resulting in n + 1 subarrays."
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-9.",
    "href": "interactive_sessions/3-1_numpy.html#practice-9.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 9. ",
    "text": "üìö  Practice 9. \n\n\nSplit your random 10x10 array from 3d into two 10x5 arrays.\n\n\nCombine the first 10x5 array from (a), the 10x2 array from 8b, and the other 10x5 array from (a). In other words, recombine the 10x10 array from 3d with two new columns in index positions 5 and 6. Your final array should have 10 rows and 12 columns. Verify this by printing the shape of the resulting array.\n\n\n\nArray Math\n\n\nOne of the key advantages of NumPy is its ability to perform vectorized operations using universal functions (ufuncs), which perform element-wise operations on arrays very quickly. For example, say we had a very large list of data, and we wanted to perform some mathematical operation on all of the data elements. We could store this data as a list or an ndarray:\n# Create a list of the first 10,000 integers\na = list(range(10000))\n\n# Create a one-dimensional array of the first 10,000 integers\nb = np.arange(10000)\nNow, let‚Äôs multiply each element in our dataset by 2. We can accomplish this by using a for loop for the list a and a ufunc for array b. (The %timeit module is a built-in Python function used to calculate the time it takes to execute short code snippets.)\n# Use a for loop to multiply every element in a by 2\n%timeit [i*2 for i in a]\n# Use a ufunc to multiply every element in b by 2\n%timeit b * 2\n\n&gt;&gt;&gt; 388 ¬µs ¬± 30.6 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1000 loops each)\n    3.58 ¬µs ¬± 41.1 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each)\nThe %timeit module is a built-in Python function used to calculate the time it takes to execute short code snippets.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Create a list of the first 10,000 integers\nlist10 = list(range(10000))\n# Use a for loop to multiply every element in a by 2\n%timeit [i*2 for i in list10]\n\n# Create a one-dimensional array of the first 10,000 integers\narray10 = np.arange(10000)\n# Use a ufunc to multiply every element in b by 2\n%timeit array10 * 2\n\n\n361 ¬µs ¬± 2.25 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n4.18 ¬µs ¬± 33.5 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)\n\n\nAs you can see, the for loop took about 100 times longer than the exact same element-wise array operation!\n\n Computation on single arrays using ufuncs \n\nUfuncs are fairly straightforward to use, as they rely on Python‚Äôs native operators (e.g.¬†+, -, *, /):\n# Create a 2x4 array of floats\nx  = np.array([[1.,2.,3.,4.],\n               [5.,6.,7.,8.]])\n\n# Do some math\n# Addition\nx + 12\n&gt;&gt;&gt; array([[13., 14., 15., 16.],\n           [17., 18., 19., 20.]])\n\n# Subtraction\nx - 400\n&gt;&gt;&gt; array([[-399., -398., -397., -396.],\n           [-395., -394., -393., -392.]])\n\n# Exponentiation\nx ** 2\n&gt;&gt;&gt; array([[ 1.,  4.,  9., 16.],\n           [25., 36., 49., 64.]])\n\n# Combine operations\n10 ** (x/2)\n&gt;&gt;&gt; array([[3.16227766e+00, 1.00000000e+01, 3.16227766e+01, 1.00000000e+02],\n           [3.16227766e+02, 1.00000000e+03, 3.16227766e+03, 1.00000000e+04]])\nThese arithmetic operators act as wrappers (effectively shortcuts) around specific built-in NumPy functions; for example, the + operator is a convenient shortcut for the np.add() function:\nx + 2\n&gt;&gt;&gt; array([[ 3.,  4.,  5.,  6.],\n           [ 7.,  8.,  9., 10.]])\n\nnp.add(x,2)\n&gt;&gt;&gt; array([[ 3.,  4.,  5.,  6.],\n           [ 7.,  8.,  9., 10.]])\nThe following table contains a list of arithmetic operators implemented by NumPy. Note that these functions work on all numerical objects, not just arrays.\n\n\n\nArithmetic functions in NumPy \n\n\n\n\n\n\n\n\n\nOperator\nufunc\nDescription\n\n\n\n\n +\n np.add() \nAddition\n\n\n -\n np.subtract() \nSubtraction\n\n\n * \n np.multiply() \nMultiplication\n\n\n / \n np.divide() \nDivision\n\n\n // \n np.floor_divide() \nFloor division (returns largest integer)\n\n\n ** \n np.power() \nExponentiation\n\n\n % \n np.mod() \nModulus/remainder\n\n\n **(1/2) \n np.sqrt() \nSquare root-alize\n\n\n\nFurthermore, as a numerical package, NumPy implements many additional mathematical operations for use in Python ‚Äì¬†on arrays or otherwise. The following tables show some of the more commonly used mathematical functions in NumPy. The x is used to denote a numerical object ‚Äì this could be an int, float, list, ndarray, etc.\n\n\n\nLogarithmic functions \n\n\n\n\n\n\n\n\nufunc\nOperation\n\n\n\n\n np.exp(x) \ne^x\n\n\n np.log(x) \n\\ln x\n\n\n np.log10(x) \n\\log x\n\n\n\n\n\n\n Trigonometric functions \n\n\n\n\n\n\n\n\nufunc\nDescription\n\n\n\n\n np.sin(x) \n\\sin{x}\n\n\n np.cos(x) \n\\cos{x}\n\n\n np.tan(x) \n\\tan{x}\n\n\n np.arcsin(x) \n\\sin^{-1}{x}\n\n\n np.arccos(x) \n\\cos^{-1}{x}\n\n\n np.arctan(x) \n\\tan^{-1}{x}\n\n\n\n\n\nNote: NumPy assumes all inputs to trigonometic functions are in units of radians. The np.radians() function can be used to convert from degrees to radians, while the np.degrees() function does the opposite.\n\n\n\n Useful mathematical constants \n\n\n\n\n\n\n\n\nConstants\nDescription\n\n\n\n\n np.e \ne\n\n\n np.pi \n\\pi\n\n\n\n\n Array-to-array math \n\nSo far, we have only considered operations between a single array and an integer, but often it is necessary to perform mathematical operations on multiple arrays. Much like NumPy handles single array operations, array-to-array math in NumPy uses ufuncs to perform element-wise calculations. For arrays of the same dimensions, this is straight forward:\nx  = np.array([[1.,2.,3.,4.],\n               [5.,6.,7.,8.]])\n\ny = np.array([[9.,87.,3.,5.6],\n              [-1.,4.,7.1,8.]])\n\n# Addition\nx + y\n&gt;&gt;&gt; array([[10. , 89. ,  6. ,  9.6],\n           [ 4. , 10. , 14.1, 16. ]])\n\n# Division\nx / y\n&gt;&gt;&gt; array([[ 0.11111111,  0.02298851,  1.        ,  0.71428571],\n           [-5.        ,  1.5       ,  0.98591549,  1.        ]])\nFor arrays whose dimensions do not match, NumPy does something called broadcasting. So long as one dimension of each array matches and one array has a dimension of 1 in one direction, the smaller array is ‚Äúbroadcast‚Äù to the dimensions of the larger array. In this process, the row or column is replicated to match the dimensions of the larger array. This is best illustrated in the following diagram:\n\na = np.array([[1.,2.,3.,4.],\n             [5.,6.,7.,8.]])\n\nb = np.array([10,11,12,13])\n\nc = np.array([[1.],\n             [20.]])\n\n# Row-wise\na + b\n&gt;&gt;&gt; array([[11., 13., 15., 17.],\n           [15., 17., 19., 21.]])\n\n# Column-wise\na + c\n&gt;&gt;&gt; array([[ 2.,  3.,  4.,  5.],\n           [25., 26., 27., 28.]])\n\n# Multiple operations\na + c**2\n&gt;&gt;&gt; array([[  2.,   3.,   4.,   5.],\n           [405., 406., 407., 408.]])"
  },
  {
    "objectID": "interactive_sessions/3-1_numpy.html#practice-10.",
    "href": "interactive_sessions/3-1_numpy.html#practice-10.",
    "title": "Session 3-1: Introduction to NumPy",
    "section": "üìö  Practice 10. ",
    "text": "üìö  Practice 10. \n\n\nRaise array b to the power of array c.\n\n\nCreate a new 5x10 array of random values. Subtract the mean of each row from every value.\n\n\n\nMissing Data\n\n\nMost real-world datasets ‚Äì¬†environmental or otherwise ‚Äì¬†have data gaps. Data can be missing for any number of reasons, including observations not being recorded or data corruption. While a cell corresponding to a data gap may just be left blank in a spreadsheet, when imported into Python, there must be some way to handle ‚Äúblank‚Äù or missing values.\nMissing data should not be replaced with zeros, as 0 can be a valid value for many datasets, (e.g.¬†temperature, precipitation, etc.). Instead, the convention is to fill all missing data with the constant NaN. NaN stands for ‚ÄúNot a Number‚Äù and is implemented in NumPy as np.nan.\nNaNs are handled differently by different packages. In NumPy, all computations involving NaN values will return nan:\ndata = np.array([[2.,2.7.,1.89.],\n                 [1.1, 0.0, np.nan],\n                 [3.2, 0.74, 2.1]])\n\ndata.mean()\n&gt;&gt;&gt; nan\nIn this case, we‚Äôd want to use the alternative np.nanmean() function, which ignores NaNs:\ndata.nanmean()\n&gt;&gt;&gt; 1.71625\nNumPy has several other functions ‚Äì including np.nanmin(), np.nanmax(), np.nansum() ‚Äì that are analogous to the regular ufuncs covered above, but allow for computation of arrays containing NaN values.\n\n\n\n\nWrapping up\nThe topics covered in this session are but a small window into the wide world of NumPy, but by now you should be familiar with the basic objects and operations in the NumPy library, which are the building blocks of data science in Python. As always ‚Äì especially now that we‚Äôve begun exploring third-party packages ‚Äì refer to the NumPy docs for comprehensive information on all functions, methods, routines, etc. and to check out more of NumPy‚Äôs capabilities.\nNext, we‚Äôll explore one of data scientists‚Äô favorite libraries: üêº."
  },
  {
    "objectID": "interactive_sessions/2-1_control_flow_statements.html",
    "href": "interactive_sessions/2-1_control_flow_statements.html",
    "title": "Session 2-1: Control Flow Statements",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nThe control flow of a program refers to the order in which its code is executed. In Python, control flow is regulated by conditional statements, loops, and functions. This session will cover if statements, for loops, and while loops; functions will be covered in a later session."
  },
  {
    "objectID": "interactive_sessions/2-1_control_flow_statements.html#try-it.",
    "href": "interactive_sessions/2-1_control_flow_statements.html#try-it.",
    "title": "Session 2-1: Control Flow Statements",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nRun the following cell, changing the value of x to be negative or positive to demonstrate how the if statement works.\n\n\nCode\n# Define x\nx = 4\n# Evaluate condition\nif x &gt; 0:\n    print('x is a positive number.')\n\n\nThe if statement can be used in conjunction with the else command to instruct the program to do something different if the condition is not met.\ny = -3218\nif y &gt; 0:\n    print('y is a positive number.')\nelse:\n    print('y is not a positive number.')\n\n &gt;&gt;&gt;  y is not a positive number.\n\nTo evaluate multiple conditions, add the elif command after the if statement. Infinite elif statements can be included.\ny = -3218\nif y &gt; 0:\n    print('y is a positive number.')\nelif y == 0:\n    print('y = 0')\nelse:\n    print('y is a negative number.')\n\n &gt;&gt;&gt;  y is a negative number."
  },
  {
    "objectID": "interactive_sessions/2-1_control_flow_statements.html#try-it.-1",
    "href": "interactive_sessions/2-1_control_flow_statements.html#try-it.-1",
    "title": "Session 2-1: Control Flow Statements",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\n\n\nCode\n# Experiment with if, elif, and else statements.\n\n\n\n\n\n Operators \n\nThere are several operators that can be used within if statements to evaluate more complex conditions. The in operator is used to check if an object exists within an iterable object container, such as a list.\naminoacids = ['histidine', 'isoleucine', 'leucine', 'lysine', 'methionine', \n              'phenylalanine', 'threonine', 'tryptophan', 'valine', 'alanine', \n              'arginine', 'asparagine', 'aspartate', 'cysteine', 'glutamate', \n              'glutamine', 'glycine', 'proline', 'serine', 'tyrosine']\n\norg_compound = 'cysteine'\n\nif org_compound in aminoacids:\n    print(org_compound.capitalize() + ' is an amino acid.' )\nelse:\n    print(org_compound.capitalize() + ' is not an amino acid.')\n\n &gt;&gt;&gt;  Cysteine is an amino acid.\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# List of amino acids\naminoacids = ['histidine', 'isoleucine', 'leucine', 'lysine', 'methionine', \n              'phenylalanine', 'threonine', 'tryptophan', 'valine', 'alanine', \n              'arginine', 'asparagine', 'aspartate', 'cysteine', 'glutamate', \n              'glutamine', 'glycine', 'proline', 'serine', 'tyrosine']\n\norg_compound = 'adenine'\nif org_compound in aminoacids:\n    print(org_compound.capitalize() + ' is an amino acid.' )\nelse:\n    print(org_compound.capitalize() + ' is not an amino acid.')\n\n\nThe and and or operators can be used to build more complex if statements based on multiple expressions. The and operator is used to specify that multiple conditions must be satisfied.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nessential = ['histidine', 'lysine', 'threonine', 'tryptophan', \n             'valine', 'methionine', 'leucine', 'phenylalanine']\naromatic = ['phenylalanine', 'tryptophan', 'tyrosine']\n\naa = 'tyrosine'\n\nif aa in aromatic and aa in essential:\n    print(aa.capitalize() + ' is an essential, aromatic amino acid.')\nelif aa in essential:\n    print(aa.capitalize() + ' is an essential, non-aromatic amino acid.')\nelif aa in aromatic:\n    print(aa.capitalize() + ' is a non-essential, aromatic amino acid.')\nelif aa in aminoacids:\n    print(aa.capitalize() + 'is a non-essential amino acid.')\nelse:\n    print(aa.capitalize() + ' is not an amino acid.')\n\n\nThe or operator is used to write an if statement where one of multiple conditions must be met.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ncharged = ['arginine', 'lysine', 'aspartate', 'glutamate']\npolar_un = ['glutamine', 'asparagine', 'histidine', 'serine', 'threonine', 'tyrosine', 'cysteine']\n\nif aa in charged or polar_un:\n    print(aa.capitalize() + ' is a polar amino acid.')\nelif aa in aminoacids:\n    print(aa.capitalize() + ' is a non-polar amino acid.')\nelse:\n    print(aa.capitalize() + ' is not an amino acid.')\n\n\n\n Nested if statements \n\nif statements can build on one another to perform specific actions based on each condition by nesting if statements. For example, the previous cell could be re-written as follows:\nif aa in aminoacids:\n    if aa in charged or polar_un:\n        print(aa.capitalize() + ' is a polar amino acid.')\n    else:\n        print(aa.capitalize() + ' is a non-polar amino acid.')\nelse:\n    print(aa.capitalize() + ' is not an amino acid.')    \nWhile this is a trivial example, nested if statements can be quite useful when inside a program as they allow the program to skip to the end if the first condition is not satisfied."
  },
  {
    "objectID": "interactive_sessions/2-1_control_flow_statements.html#try-it.-2",
    "href": "interactive_sessions/2-1_control_flow_statements.html#try-it.-2",
    "title": "Session 2-1: Control Flow Statements",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\n\n\nCode\n# Experiment with nested if statements."
  },
  {
    "objectID": "interactive_sessions/2-1_control_flow_statements.html#loops",
    "href": "interactive_sessions/2-1_control_flow_statements.html#loops",
    "title": "Session 2-1: Control Flow Statements",
    "section": "Loops",
    "text": "Loops\n\n\n\nfor loops\nfor loops are the most commonly used type of loop and are extremely useful. for loops are used to iterate or loop through any object capable of returning its members one at time, i.e.¬†an iterable object.\n\nüêç &lt;b&gt;Note.&lt;/b&gt;  The &lt;b&gt;iterator&lt;/b&gt; in a &lt;code&gt;for&lt;/code&gt; loop is a temporary variable used to store each value in the iterable object. The iterator is defined in the &lt;code&gt;for&lt;/code&gt; loop syntax as follows:\nfor &lt;ITERATOR&gt; in &lt;ITERABLE&gt;:\n    do something to iterator\nThe name of the iterator should reflect the nature of the list. i is commonly used as an enumerator or counter variable and should be avoided for other uses.\n\nA generic counter for loop can be generated using the range() function.\nfor i in range(4):\n    print(i + 1)\n    \n&gt;&gt;&gt; 1\n    2\n    3\n    4\nfor loops are commonly used to iterate through lists. As with the generic range() for loop, the iterator is assigned the next value from the list at the end of the indented code block.\nfor aa in aminoacids:\n    print(aa)\n    \n&gt;&gt;&gt; histidine\n    isoleucine\n    leucine\n    lysine\n    methionine\n    phenylalanine\n    threonine\n    tryptophan\n    valine\n    alanine\n    arginine\n    asparagine\n    aspartate\n    cysteine\n    glutamate\n    glutamine\n    glycine\n    proline\n    serine\n    tyrosine\n\n Built-in functions \n\nThe enumerate() function can be used in a for loop to keep track of the index of the iterator. This can be useful for keeping track of the number of iterations completed, accessing other elements in the same list based on their relative index (e.g.¬†the value immediately following the current iterator value), or accessing elements in another list based on the iterator‚Äôs index.\ngases = ['N2', 'O2', 'Ar', 'H2O', 'CO2']\n\nfor i,gas in enumerate(gases):\n    rank = i + 1\n    print('The #%d most abundant gas in the atmosphere is %s.' %(rank,gas))\n\n &gt;&gt;&gt;  The #1 most abundant gas in the atmosphere is N2.\n\n\nThe #2 most abundant gas in the atmosphere is O2.\n\n\nThe #3 most abundant gas in the atmosphere is Ar.\n\n\nThe #4 most abundant gas in the atmosphere is H2O.\n\n\nThe #5 most abundant gas in the atmosphere is CO2.\n\n\n\nCode\n# Define list of atomic masses of 6 most abundant elements\natomic_mass = [12.011, 1.00784, 14.0067, 15.999, 30.97376, 32.065]  # g/mol\n\n# Iterate through org_elements + print the atomic mass of each element\n\n\nTo iterate through multiple lists at the same time without indexing, use the zip() function.\ngas_frac = [0.78084, 0.209476, 0.00934, 0.0025, 0.000314]\ngas_molar_mass = [14.0067, 15.999, 39.948, 18.01528, 44.01]\n\nmass_atmosphere = 5.148e21   # grams\nn_a = 6.022e23    # Avogadro's number\n\nfor frac,mol_mass in zip(gas_frac,gas_molar_mass):\n    mass = frac * mass_atmosphere\n    molecules = (mass / mol_mass ) * n_a\n    print(molecules)\n\n&gt;&gt;&gt; 1.7282458205744395e+44\n    4.0590156271366957e+43\n    7.248215956743767e+41\n    4.302078013774973e+41\n    2.211859664621677e+40\nThe zip() function is nearly always used when each element of one list corresponds to an element in the same index position in another list. Therefore, it should mostly be used with two or more lists of the same length. If the lists do not have the same length, however, the number of iterations of the for loop will match the length of the shortest list.\nThe enumerate() and zip() functions can also be used together, if necessary, to keep track of the index position of iterators.\nfor i,(frac,mol_mass) in enumerate(zip(gas_frac,gas_molar_mass)):\n    gas = gases[i]\n    mass = frac * mass_atmosphere\n    molecules = (mass / mol_mass ) * n_a\n    print('There are ' + '{:.2e}'.format(molecules) + ' molecules of %s in the atmosphere.' % (gas))\n\n &gt;&gt;&gt;  There are 1.73e+44 molecules of N2 in the atmosphere.\n\n\nThere are 4.06e+43 molecules of O2 in the atmosphere.\n\n\nThere are 7.25e+41 molecules of Ar in the atmosphere.\n\n\nThere are 4.30e+41 molecules of H2O in the atmosphere.\n\n\nThere are 2.21e+40 molecules of CO2 in the atmosphere.\n\n\n Nested for loops \n\nLike if statements, for loops can be nested to perform an operation multiple times for each iterator in the overall loop.\nfor aa in aminoacids:\n    vowels = 0\n    for letter in aa:\n        if letter in ['a', 'e', 'i', 'o', 'u']:\n            vowels = vowels + 1\n    print(aa.capitalize() + ' has ' + str(vowels) + ' vowels.')\n    \n&gt;&gt;&gt; Histidine has 4 vowels.\n    Isoleucine has 6 vowels.\n    Leucine has 4 vowels.\n    Lysine has 2 vowels.\n    Methionine has 5 vowels.\n    Phenylalanine has 5 vowels.\n    Threonine has 4 vowels.\n    Tryptophan has 2 vowels.\n    Valine has 3 vowels.\n    Alanine has 4 vowels.\n    Arginine has 4 vowels.\n    Asparagine has 5 vowels.\n    Aspartate has 4 vowels.\n    Cysteine has 3 vowels.\n    Glutamate has 4 vowels.\n    Glutamine has 4 vowels.\n    Glycine has 2 vowels.\n    Proline has 3 vowels.\n    Serine has 3 vowels.\n    Tyrosine has 3 vowels.\n\n\n\n\nwhile loops\nwhile loops are used to repeatedly execute a block of code while a given condition is satisfied. The indented code block will be contiuously executed until the condition becomes False.\nx = 0\nwhile x &lt; 4:\n    x = x + 1\n    print(x)\n&gt;&gt;&gt; 1\n    2\n    3\n    4\nwhile loops are often used for user input, which allows the program to ‚Äústall,‚Äù repeatedly prompting the user until an acceptable answer is input.\n\n‚úèÔ∏è Try it. Run the following cell to see how a while loop works, inputing various answers that do not satisfy the condition before inputing the value that will end the loop.\n\n\n\nCode\n# Define a blank string variable\nuser_txt = \"\"\n# Wait for a specific answer, repeatedly asking for input until the condition is satisfied.\nwhile user_txt != \"42\":\n    user_txt = input(\"What is the answer to life, the universe, and everything? \")\n\n\n\nüêç &lt;b&gt;Note.&lt;/b&gt; &lt;code&gt;while&lt;/code&gt; loops can be infinite, so they should be used very judiciously. For example, imagine if instead of &lt;code&gt;x = x + 1&lt;/code&gt; in the previous example, the code block executed in the &lt;code&gt;while&lt;/code&gt; loop were &lt;code&gt;x = x - 1&lt;/code&gt;:\nx = 0\nwhile x &lt; 4:\n    x = x - 1\n    print(x)\n&gt;&gt;&gt; -1\n    -2\n    -3\n    -4\n    -5\n    -6\n    ... # and so on\nThis loop would never stop executing because the condition can never be met.\n\n\n\n\n\nEscaping loops\nSometimes it is necessary to terminate a loop iteration or the loop itself. The break and continue statements are used to escape loops.\nbreak statements in Python are used to escape an entire loop based on a condition. In nested loops, a break will only exit out of one level.\n\n\n\nbreak_chart\n\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nwhile True:\n    print(\"What is the answer to life, the universe, and everything? \")\n    option = input(\"   Your answer: \")\n    if option.isdigit():\n        if int(option) == 42:\n            print('You have solved the ultimate question.')\n            break\n        else:\n            print(\"Nope. Try again...\\n\")\n    else:\n        print(\"Nope. Try again...\\n\")\n\n\ncontinue statements are used to skip the remainder of the loop for a given iteration.\n\n\n\ncontinue_chart\n\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nfor x in [47, 22.5342, 'four hundred eighty-two', 0, 72104, -932.14, 6, -23, 'eleven']:\n    # Check to see if value is a string\n    if type(x) == str:\n        # If so, skip to next iteration\n        continue\n    # Otherwise, divide by 2 and print\n    print(x/2)\n\n\n\n\n\n\nList comprehensions\nA list comprehension is a quick, concise way to generate a list. They are generally used to condense the generation of a list from a simple expression into one line of code.\nFor example, say you wanted a list of all the squares from 0 and 100. As we learned in Session 1-2, this could be accomplished as follows:\nsquares = []\n\nfor x in range(11):\n    squares.append(x**2)\n\nprint(squares)\n&gt;&gt;&gt; squares = [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nUsing a list comprehension, the same list could be generated in a single line of code as follows:\nsquares = [x**2 for x in range(11)]\n\nprint(squares)\n&gt;&gt;&gt; squares = [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nList comprehensions are often combined with if statements. For example, the following line of code creates a list of all even numbers from 0 to 100.\nevens = [x for x in range(101) if x%2 == 0]\n\nprint(evens)\n&gt;&gt;&gt; evens = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, \n               22, 24, 26, 28, 30, 32, 34, 36, 38, 40,\n               42, 44, 46, 48, 50, 52, 54, 56, 58, 60, \n               62, 64, 66, 68, 70, 72, 74, 76, 78, 80, \n               82, 84, 86, 88, 90, 92, 94, 96, 98]\n\n‚úèÔ∏è Try it. Change the code above to create a list of all even squares from 0 to 100."
  },
  {
    "objectID": "trypy/01_trypy_stl_blood/stl_blood_exercise.html#part-0.-setup-steps",
    "href": "trypy/01_trypy_stl_blood/stl_blood_exercise.html#part-0.-setup-steps",
    "title": "TryPy 01 - Exploring St.¬†Louis Blood Toxicity Data",
    "section": "Part 0. Setup Steps",
    "text": "Part 0. Setup Steps\n\nCreate a repo on GitHub named eds217-trypy-01\nClone to create a version-controlled project\nCreate some subfolder infrastructure (nbs, data, figs)\nCreate and save a new quarto in RStudio called jupyter notebook (.ipynb file) named stl-lead-yourinitials.ipynb in the nbs folder (for example, mine would be stl-lead-kc.ipynb).\nMake sure to associate the notebook with the eds217_2023 environment.\n\n\nPart 1 - Get the data\n\n\"\"\"\nCreate a new variable containing \nthe link to the .csv file on \nthe EDS_221 github repository.\n\"\"\"\nurl = 'https://raw.githubusercontent.com/'\\\n'allisonhorst/EDS_221_programming-essentials/'\\\n'main/activities/stl_blood_lead.csv'\n\n\"\"\" \npandas can read a csv file into a \ndataframe directly from a url:\n\"\"\"\nstl_lead = pd.read_csv(url)\nRead more about the data here.\n\n\nPart 2 - Explore the data\nIn your .ipynb file:\n\nCreate a code cell that imports the numpy and pandas packages and run the cell to import the packages.\nUse the code above to read the url for stl_blood_lead.csv into a pandas DataFrame called stl_lead\nDo some basic exploration of the dataset using the DataFrame info and describe commands.\nIn a new code chunk, from stl_lead create a new column called prop_white that contains the percent of each census tract identifying as white (variable white in the dataset divided by variable totalPop, times 100).\n\nHint: df['new_col'] = df['col_a'] / df['col_b'] will create a new column new_col in the dataframe df that contains the value of col_a / col_b\n\n\nPart 3 - Create a scatterplot\n\nImport matplotlib (import matplotlib.pyplot as plt)\nCreate a scatterplot graph of the percentage of children in each census tract with elevated blood lead levels (pctElevated) versus the percent of each census tract identifying as white.\n\n\n\n\n\n\n\n\nPart 4 - Create a histogram\n\nCreate a histogram of only the pctElevated column in the data frame\nCustomize the fill, color, and size aesthetics - test some stuff! Feel free to make it awful."
  },
  {
    "objectID": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#part-0.-setup-steps",
    "href": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#part-0.-setup-steps",
    "title": "TryPy 2 - For Loops and Conditionals",
    "section": "Part 0. Setup Steps",
    "text": "Part 0. Setup Steps\n\nCreate a repo on GitHub named eds217-trypy-02\nClone to create a version-controlled project\nCreate some subfolder infrastructure (docs, data)\nCreate a new python notebook."
  },
  {
    "objectID": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#part-1.-real-data",
    "href": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#part-1.-real-data",
    "title": "TryPy 2 - For Loops and Conditionals",
    "section": "Part 1. Real data",
    "text": "Part 1. Real data\nExplore this data package from EDI, which contains a ‚ÄúData file describing the biogeochemistry of samples collected at various sites near Toolik Lake, North Slope of Alaska‚Äù. Familiarize yourself with the metadata (particularly, View full metadata &gt; expand ‚ÄòData entities‚Äô to learn more about the variables in the dataset).\nCitation: Kling, G. 2016. Biogeochemistry data set for soil waters, streams, and lakes near Toolik on the North Slope of Alaska, 2011. ver 5. Environmental Data Initiative. https://doi.org/10.6073/pasta/362c8eeac5cad9a45288cf1b0d617ba7\n\nDownload the CSV containing the Toolik biogeochemistry data\nTake a look at it - how are missing values stored? Keep that in mind.\nDrop the CSV into your data folder of your project\nCreate a new notebook document in VSCode (or in a jupyter notebook server), save in docs as toolik_chem.ipynb\nImport the pandas and matplotlib libraries into your first code cell.\nRead in the data as toolik_biochem. Remember, you‚Äôll want to specify here how NA values are stored. Use the na_values argument in your pd.read_csv call to convert all column names to lower case/underscore format.\nCreate a subset of the data that contains only observations from the ‚ÄúToolik Inlet‚Äù site, and that only contains the variables (columns) for pH, dissolved organic carbon (DOC), and total dissolved nitrogen (TDN). Store this subset as inlet_biochem. Make sure to LOOK AT the subset you‚Äôve created.\nFind the mean value of each column in inlet_biochem 2 different ways:\n\n\nWrite a for loop from scratch to calculate the mean for each\nUse one other method (e.g.¬†.mean(), or .apply()) to find the mean for each column.\n\n\nSave, stage, commit, pull, push!"
  },
  {
    "objectID": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#end-activities",
    "href": "trypy/02_trypy_conditionals_and_loops/conditionals_and_loops.html#end-activities",
    "title": "TryPy 2 - For Loops and Conditionals",
    "section": "END activities",
    "text": "END activities"
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html",
    "href": "practice_sessions/practice_3-1_numpy.html",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | ‚û°Ô∏è Next Session |\nCode\n# Imports\nimport numpy as np"
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-1.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-1.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö Practice 1.",
    "text": "üìö Practice 1.\nCreate the following arrays and assign the corresponding variable names:\n\na\n\n\\begin{bmatrix}\n     4 & 5 & 0 & 12 & -1 \\\\\n     8 & -21 & -4 & 6 & 3 \\\\\n     17 & 1 & -13 & 7 & 0\n\\end{bmatrix}\n\nb\n\n\\begin{bmatrix}\n     1.0 & 2.7 & 0 & 0.188 & 4.07 & 0.24\n\\end{bmatrix}\n\nc\n\n\\begin{bmatrix}\n     0.4 \\\\\n     0.8 \\\\\n     1.2 \\\\\n     1.6 \\\\\n     2.0 \\\\\n     2.4\n\\end{bmatrix}"
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-2.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-2.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \n\n\nCreate a new array d of integers the multiples of 3 between 0 and 100.\n\n\nCreate an array f 10 evenly spaced elements between 0 and 2.\n\n\nRe-create array c from Practice 1c using a function. Assign this to variable name g."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-3.-assign-the-following-to-variables",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-3.-assign-the-following-to-variables",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 3.  Assign the following to variables:",
    "text": "üìö  Practice 3.  Assign the following to variables:\n\n\nA 5x3 array of ones.\n\n\nA one-dimensional array of 6 zeros.\n\n\nA 7x7 identity array.\n\n\nA random 10x10 array."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-4.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-4.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nUse array methods and the array you created in Practice 2a (d) to count the number of multiples of 3 between 0 and 100."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-5.-using-the-array-you-created-in-practice-3d",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-5.-using-the-array-you-created-in-practice-3d",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 5.  Using the array you created in Practice 3d,",
    "text": "üìö  Practice 5.  Using the array you created in Practice 3d,\n\n\nPrint all the elements in column 4.\n\n\nPrint all the elements in row 7.\n\n\nExtract the 4x4 subarray at the center of the array and assign it as a new variable.\n\n\nPrint the last two values in column 10."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-6.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-6.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \nCreate a blank 8x8 matrix and fill it with a checkerboard pattern of 0s and 1s using indexing."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-7.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-7.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \n\n\nCreate a 3x3 matrix with values ranging from 0 to 8.\n\n\nReverse the order of elements in your random 10x10 array from 3d."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-8.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-8.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 8. ",
    "text": "üìö  Practice 8. \nCreate two random 1-D arrays of length 10. Merge them into a 2x10 array and then a 10x2 array."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-9.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-9.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 9. ",
    "text": "üìö  Practice 9. \n\n\nSplit your random 10x10 array from 3d into two 10x5 arrays.\n\n\nCombine the first 10x5 array from (a), the 10x2 array from 8b, and the other 10x5 array from (a). In other words, recombine the 10x10 array from 3d with two new columns in index positions 5 and 6. Your final array should have 10 rows and 12 columns. Verify this by printing the shape of the resulting array."
  },
  {
    "objectID": "practice_sessions/practice_3-1_numpy.html#practice-10.",
    "href": "practice_sessions/practice_3-1_numpy.html#practice-10.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 10. ",
    "text": "üìö  Practice 10. \n\n\nRaise array b to the power of array c.\n\n\nCreate a new 5x10 array of random values. Subtract the mean of each row from every value."
  },
  {
    "objectID": "practice_sessions/practice_sessions.html",
    "href": "practice_sessions/practice_sessions.html",
    "title": "EDS 217 Practice Sessions",
    "section": "",
    "text": "Return to Course Home Page\n\n\n\n\nThis page contains links to practice sessions for EDS 217.\n\nPractice Session 1-1: Variables\n\n\nPractice Session 1-2: Lists\n\n\nPractice Session 2-1: Control Flow Statements\n\n\nPractice Session 2-2: Structured Data\n\n\nPractice Session 3-1: Numpy\n\n\nPractice Session 4-1: Pandas\n\n\nPractice Session 5-1: Matplotlib"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#part-0.-setup-steps",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#part-0.-setup-steps",
    "title": "Practice 4-1: Pandas üêº",
    "section": "Part 0. Setup Steps",
    "text": "Part 0. Setup Steps\n\nCreate a repo on GitHub named eds217-practice-4-1-pandas\nClone to create a version-controlled project\nCreate some subfolder infrastructure (nbs, data, figs)\nCreate and save a new quarto in RStudio called jupyter notebook (.ipynb file) named practice_4-1_pandas.ipynb in the nbs folder.\nOpen the notebook in VSCode or jupyter notebook/lab\nMake sure to associate the notebook with the eds217_2023 environment.\nCreate a cell that imports your essential data science libraries."
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-1.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \n\n\nUse a list of lists to construct a DataFrame named df1 containing the data in the table below.\n\n\n\n\n\nRiver\n\n\nLength (\\text{km})\n\n\nDrainage area (\\text{km}^2)\n\n\n\n\nAmazon\n\n\n6400\n\n\n7,050,000\n\n\n\n\nCongo\n\n\n4371\n\n\n4,014,500\n\n\n\n\nYangtze\n\n\n6418\n\n\n1,808,500\n\n\n\n\nMississippi\n\n\n3730\n\n\n3,202,230\n\n\n\n\n\n\nUse a dict to construct a DataFrame named df2 containing the data in the table below.\n\n\n\n\n\nRiver\n\n\nLength (\\text{km})\n\n\nDrainage area (\\text{km}^2)\n\n\n\n\nZambezi\n\n\n2574\n\n\n1,331,000\n\n\n\n\nMekong\n\n\n4023\n\n\n811,000\n\n\n\n\nMurray\n\n\n2508\n\n\n1,061,469\n\n\n\n\nRh√¥ne\n\n\n813\n\n\n98,000\n\n\n\n\nCubango\n\n\n1056\n\n\n530,000\n\n\n\n\n\n\n\n\nCode\n# 1a. Construct df1 from list of lists\ndf1 = pd.DataFrame([['Amazon', 6400, 7050000], \n                    ['Congo', 4371, 4014500],\n                    ['Yangtze', 6418, 1808500],\n                    ['Mississippi', 3730, 3202230]],\n                   columns=['RIVER', 'LENGTH_km', 'DRAINAGE_AREA_km2'])\n\n# 1b. Construct df2 from dict\ndf2 = pd.DataFrame({'RIVER': ['Zambezi', 'Mekong', 'Murray', 'Rhone', 'Cubango'],\n                    'LENGTH_km': [2574, 4023, 2508, 813, 1056],\n                    'DRAINAGE_AREA_km2': [1331000, 811000, 1061469, 98000, 530000]})"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#import-the-data-for-our-practice-session",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#import-the-data-for-our-practice-session",
    "title": "Practice 4-1: Pandas üêº",
    "section": "Import the data for our practice session",
    "text": "Import the data for our practice session\n\n\nCode\n# Import data\nbsrn = pd.read_csv('../../data/BSRN_GOB_2019-10.csv')"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-2.-using-the-dataframe-bsrn",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-2.-using-the-dataframe-bsrn",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö Practice 2. Using the DataFrame bsrn:",
    "text": "üìö Practice 2. Using the DataFrame bsrn:\n\n\nPrint a list of column names.\n\n\nHow many values are there in the entire DataFrame?\n\n\nWhat is the data type of the first column?\n\n\n\n\nCode\n# 2a. Print a list of column names\nprint(list(bsrn.columns))\n\n# 2b. Values in entire DataFrame\nprint(bsrn.size)\n\n# 2c. Retrieve data type of first column\nprint(list(bsrn.dtypes)[0]) \n\n\n['DATE', 'H_m', 'SWD_Wm2', 'STD_SWD', 'DIR_Wm2', 'STD_DIR', 'DIF_Wm2', 'STD_DIF', 'LWD_Wm2', 'STD_LWD', 'SWU_Wm2', 'LWU_Wm2', 'T_degC', 'RH', 'P_hPa']\n669600\nobject"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-3.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-3.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö Practice 3.",
    "text": "üìö Practice 3.\n\n\nCreate a new DataFrame containing the first record for each day and the following columns: the timestamp of the record, incoming shortwave radiation, direct and diffuse radiation, and incoming longwave radiation. (Hint: the BSRN station collects data every minute).\n\n\nCreate a new Series containing the temperature values every hour at the top of the hour.\n\n\n\n\nCode\n# Daily radiation data\nbsrn_day = bsrn.iloc[::1440,:9:2]\n\n# Hourly temperatures\ntemp_hr = bsrn.T_degC[::60]\n\n\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Convert bsrn.DATE column to datetime objects\nbsrn['DATE'] = pd.to_datetime(bsrn.DATE)  # Note: overwriting a column like this is NOT recommended.\n\n# Set bsrn.DATE as the DataFrame index\nbsrn.set_index('DATE',inplace=True)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-4.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 4.",
    "text": "üìö  Practice 4.\n Calculate the mean incoming shortwave, outgoing shortwave, incoming longwave, and outgoing longwave radiation over the entire month.\n\n\nCode\n# 4. Mean SW in, SW out, LW in, LW out\nprint('Mean SW incoming radiation = ', bsrn.SWD_Wm2.mean(), ' W m-2')\nprint('Mean SW outgoing radiation = ', bsrn.SWU_Wm2.mean(), ' W m-2')\nprint('Mean LW incoming radiation = ', bsrn.LWD_Wm2.mean(), ' W m-2')\nprint('Mean LW outgoing radiation = ', bsrn.LWU_Wm2.mean(), ' W m-2')\n\n\nMean SW incoming radiation =  318.0465157965494  W m-2\nMean SW outgoing radiation =  110.44500448028674  W m-2\nMean LW incoming radiation =  342.35069187467764  W m-2\nMean LW outgoing radiation =  455.0540322580645  W m-2"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-5.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-5.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \n\n\nAdd a column ‚ÄòNET_SW‚Äô to bsrn with the net shortwave radiation.\n\n\nAdd a column ‚ÄòNET_LW‚Äô to bsrn with the net longwave radiation.\n\n\nAdd a column ‚ÄòNET_RAD‚Äô to bsrn with the net total radiation.\nNet radiation is given by the following equation:\n\nR^{}_{N} \\, = \\,  R^{\\, \\downarrow}_{SW} \\, - \\,  R^{\\, \\uparrow}_{SW} \\, + \\, R^{\\, \\downarrow}_{LW} \\, - \\,  R^{\\, \\uparrow}_{LW}\nwhere R^{\\, \\downarrow}_{SW} and R^{\\, \\uparrow}_{SW} are incoming and outgoing shortwave radiation, respectively, and R^{\\, \\downarrow}_{LW} and R^{\\, \\uparrow}_{LW} are incoming and outgoing longwave radiation, respectively.\n\nCreate a new DataFrame with the day of the month and daily mean values of shortwave incoming, shortwave outgoing, longwave incoming, longwave outgoing radiation, and net total radiation. (Hint: use masking!).\n\n\n\n\nCode\n# 5a. Net SW radiation\nbsrn['NET_SW'] = bsrn.SWD_Wm2 - bsrn.SWU_Wm2\n\n# 5b. Net LW radiation\nbsrn['NET_LW'] = bsrn.LWD_Wm2 - bsrn.LWU_Wm2\n\n# 5c. Net total radiation\nbsrn['NET_RAD'] = bsrn.SWD_Wm2 - bsrn.SWU_Wm2 + bsrn.LWD_Wm2 - bsrn.LWU_Wm2\n\n\n# 5d. Mean daily SW in, SW out, LW in, LW out, R_net\n# Initialize empty list\ndaily_rad_list = []\n# Iterate through unique day values\nfor d in bsrn.index.day.unique():\n    # SW in\n    swd = bsrn.SWD_Wm2[bsrn.index.day == d].mean()\n    # SW out\n    swu = bsrn.SWU_Wm2[bsrn.index.day == d].mean()\n    # LW in\n    lwd = bsrn.LWD_Wm2[bsrn.index.day == d].mean()\n    # LW out\n    lwu = bsrn.LWU_Wm2[bsrn.index.day == d].mean()\n    # Net total\n    rnet = swd - swu + lwd - lwu\n    # Add all values to a list of lists\n    daily_rad_list.append([d, swd, swu, lwd, lwu, rnet])\n\n# Convert to DataFrame\ndaily_rad = pd.DataFrame(daily_rad_list, columns=['DAY', 'SW_in', 'SW_out', 'LW_in', 'LW_out', 'R_NET'])\ndaily_rad\n\n\n\n\n\n\n\n\n\nDAY\nSW_in\nSW_out\nLW_in\nLW_out\nR_NET\n\n\n\n\n0\n1\n325.336345\n115.334028\n321.219903\n458.834028\n72.388192\n\n\n1\n2\n322.732453\n113.939583\n318.131341\n448.486111\n78.438100\n\n\n2\n3\n298.635417\n103.261806\n330.516667\n429.979861\n95.910417\n\n\n3\n4\n323.209173\n113.222222\n314.129526\n439.990972\n84.125505\n\n\n4\n5\n296.861806\n105.461806\n324.660876\n427.359722\n88.701153\n\n\n5\n6\n292.118915\n104.219444\n330.458333\n428.665278\n89.692526\n\n\n6\n7\n339.848611\n119.959722\n303.437413\n439.002778\n84.323524\n\n\n7\n8\n332.009028\n116.752778\n313.126653\n438.550000\n89.832903\n\n\n8\n9\n290.577083\n104.436806\n342.506267\n428.110417\n100.536129\n\n\n9\n10\n310.887500\n108.638889\n331.667130\n434.941667\n98.974074\n\n\n10\n11\n312.226389\n108.406250\n350.486787\n458.562500\n95.744426\n\n\n11\n12\n313.099306\n108.276389\n375.387500\n483.829167\n96.381250\n\n\n12\n13\n292.540972\n97.745833\n389.507307\n485.947222\n98.355224\n\n\n13\n14\n210.243056\n76.329167\n390.913829\n470.870139\n53.957579\n\n\n14\n15\n294.886806\n91.408333\n399.457639\n500.201389\n102.734722\n\n\n15\n16\n322.011111\n114.262500\n400.745833\n510.212500\n98.281944\n\n\n16\n17\n306.800000\n106.773611\n390.968033\n492.745833\n98.248589\n\n\n17\n18\n298.656250\n104.536111\n364.097222\n459.456944\n98.760417\n\n\n18\n19\n314.968750\n110.327083\n365.431250\n460.609028\n109.463889\n\n\n19\n20\n329.323611\n113.339583\n357.791522\n473.039583\n100.735966\n\n\n20\n21\n338.721334\n117.433333\n340.713189\n470.612500\n91.388690\n\n\n21\n22\n338.259722\n117.554861\n325.689368\n441.588194\n104.806034\n\n\n22\n23\n354.881944\n122.917361\n306.553857\n438.565972\n99.952468\n\n\n23\n24\n344.563194\n119.732639\n319.499653\n452.019444\n92.310764\n\n\n24\n25\n261.228472\n87.575000\n344.902643\n441.439583\n77.116531\n\n\n25\n26\n345.552778\n118.828472\n337.203614\n459.212500\n104.715419\n\n\n26\n27\n356.714583\n123.323611\n309.846421\n434.491667\n108.745727\n\n\n27\n28\n358.297636\n125.206944\n303.482615\n421.080556\n115.492750\n\n\n28\n29\n352.906944\n122.894444\n322.271399\n448.573611\n103.710288\n\n\n29\n30\n357.626129\n123.736806\n331.607516\n462.778472\n102.718367\n\n\n30\n31\n323.794302\n107.959722\n356.192629\n466.917361\n105.109847"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-6.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-6.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \n\n\nConcatenate df1 and df2 into a new DataFrame with all 9 rivers.\n\n\nCreate a new DataFrame rivers with the discharge, mouth, source, and continent information and add this to your DataFrame from (a) to produce a DataFrame with all of the data in the table below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiver\nLength (\\text{km})\nDrainage area (\\text{km}^2)\nDischarge (\\text{m}^2/\\text{s})\nMouth\nSource\nContinent\n\n\n\n\nAmazon\n6400\n7,050,000\n209,000\nAtlantic Ocean\nRio Mantaro\nSouth America\n\n\nCongo\n4371\n4,014,500\n41,200\nAtlantic Ocean\nLualaba River\nAfrica\n\n\nYangtze\n6418\n1,808,500\n30,166\nEast China Sea\nJianggendiru Glacier\nAsia\n\n\nMississippi\n3730\n3,202,230\n16,792\nGulf of Mexico\nLake Itasca\nNorth America\n\n\nZambezi\n2574\n1,331,000\n3,400\nIndian Ocean\nMiombo Woodlands\nAfrica\n\n\nMekong\n4023\n811,000\n16,000\nSouth China Sea\nLasagongma Spring\nAsia\n\n\nMurray\n2508\n1,061,469\n767\nSouthern Ocean\nAustralian Alps\nOceania\n\n\nRh√¥ne\n813\n98,000\n1,710\nMediterranean Sea\nRh√¥ne Glacier\nEurope\n\n\nCubango\n1056\n530,000\n475\nOkavango Delta\nBi√© Plateau\nAfrica\n\n\n\n\n\nCode\n# 6a. Concatenate df1 and df2\nrivs = pd.concat([df1,df2],ignore_index=True)\n\n# 6b. Concatenate rivs and df3\n# Add new data to DataFrame\ndf3 = pd.DataFrame([[209000, 'Atlantic Ocean', 'Rio Mantaro', 'South America'], \n                    [41200, 'Atlantic Ocean', 'Lualaba River', 'Africa'],\n                    [30166, 'East China Sea', 'Jianggendiru Glacier', 'Asia'],\n                    [16792, 'Gulf of Mexico', 'Lake Itasca', 'North America'],\n                    [3400, 'Indian Ocean', 'Miombo Woodlands', 'Africa'],\n                    [16000, 'South China Sea', 'Lasagongma Spring', 'Asia'],\n                    [767, 'Southern Ocean', 'Australian Alps', 'Oceania'],\n                    [1710, 'Mediterranean Sea', 'Rhone Glacier', 'Europe'],\n                    [475, 'Okavango Delta', 'Bie Plateau', 'Africa']],\n                  columns=['DISCHARGE_m3s', 'MOUTH', 'SOURCE', 'CONTINENT'] )\n# Concatenate rivs + df3\nrivers = pd.concat([rivs,df3], axis=1)\nrivers\n\n\n\n\n\n\n\n\n\nRIVER\nLENGTH_km\nDRAINAGE_AREA_km2\nDISCHARGE_m3s\nMOUTH\nSOURCE\nCONTINENT\n\n\n\n\n0\nAmazon\n6400\n7050000\n209000\nAtlantic Ocean\nRio Mantaro\nSouth America\n\n\n1\nCongo\n4371\n4014500\n41200\nAtlantic Ocean\nLualaba River\nAfrica\n\n\n2\nYangtze\n6418\n1808500\n30166\nEast China Sea\nJianggendiru Glacier\nAsia\n\n\n3\nMississippi\n3730\n3202230\n16792\nGulf of Mexico\nLake Itasca\nNorth America\n\n\n4\nZambezi\n2574\n1331000\n3400\nIndian Ocean\nMiombo Woodlands\nAfrica\n\n\n5\nMekong\n4023\n811000\n16000\nSouth China Sea\nLasagongma Spring\nAsia\n\n\n6\nMurray\n2508\n1061469\n767\nSouthern Ocean\nAustralian Alps\nOceania\n\n\n7\nRhone\n813\n98000\n1710\nMediterranean Sea\nRhone Glacier\nEurope\n\n\n8\nCubango\n1056\n530000\n475\nOkavango Delta\nBie Plateau\nAfrica"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-7.",
    "href": "practice_sessions/answerkeys/practice_4-1_pandas_key.html#practice-7.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \nExport your rivers DataFrame to a CSV file in the exports folder.\n\n\nCode\n# 7. Export rivers\nrivers.to_csv('../exports/rivers.csv') # note: will be different from the practice session folder.\n# rivers.to_csv('exports/rivers.csv') # note: will be different from the practice session folder."
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "",
    "text": "Don‚Äôt forget to start your notebook with a cell containing the import statements you need for the session.\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-1.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nRecreate the plot below. You do not need to match the colors exactly, but do not rely on matplotlib defaults. Note: do not worry about the equation(s); these are included to indicate which functions to plot.\n\n\n\nCode\n# Plot y=log(x) in green\nx = np.linspace(.01, 1, 100)\ny = np.log(x)\nfig, ax = plt.subplots()\nax.plot(x, y, 'g-')\nax.set_title('y=log(x)')\nax.set_xlabel('x')\nax.set_ylabel('y')\nplt.show()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-2.",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-2.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \nRecreate the plot below. You do not need to match the colors exactly, but do not rely on matplotlib defaults. Note: do not worry about the equation(s); these are included to indicate which functions to plot.\n\n\n\nCode\n# Plot a series of three sine waves, with amplitudes 1, 10, and 5, in different colors from 0-10\n\n\n(1.0, 0.0, 0.0)\n\n\n\n\nCode\ndef rgb(r, g, b):\n    return (r/255, g/255, b/255)\n\nx = np.linspace(0, 10, 100)\ny1 = 1 * x* np.sin(2*np.pi*x)\ny2 = 10 * x * np.sin(2*np.pi*x)\ny3 = 5 * x * np.sin(2*np.pi*x)\nfig, ax = plt.subplots(figsize=(10, 6))\nax.plot(x, y1, '-', label='A=1', marker='o', color=rgb(83,127,232))\nax.plot(x, y2, '--', label='A=10', marker='*', color=rgb(97,180,186))\nax.plot(x, y3, '-.', label='A=5', marker='^', color=rgb(205,61,62))\n# add markers to the plot\nax.set_title('y=Axsin(2$\\pi$x)')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend()\nplt.show()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-3.",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-3.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \nImport the data from ./data/BSRN_data.csv and plot the temperature and relative humidity over the month of October 2019 at the BSRN station. Be sure to format the timestamps and include axis labels, a title, and a legend, if necessary.\n\n\nCode\n# Import data\nbsrn = pd.read_csv('../data/BSRN_GOB_2019-10.csv',index_col=0,parse_dates=True)\n\n\n\n\nCode\n\n# Initialize empty figure and axes\nfig = plt.figure(figsize=(8,8))\n# Create two subplots in a 1x2 grid:\n# 1. Incoming SW radiation\n# 2. Incoming LW radiation\nax1 = fig.add_subplot(2,1,1)\nax2 = fig.add_subplot(2,1,2)\n\n# Filter data for October 2019:\nbsrn = bsrn.loc['2019-10-01':'2019-10-31']\n# Plot incoming SW radiation for October 2019:\nax1.plot(bsrn.index,bsrn.SWD_Wm2)\n# Plot incoming LW radiation\nax2.plot(bsrn.index,bsrn.LWD_Wm2)\n# Label y-axes\nax1.set_ylabel(\"Incoming SW  \\n (W m$^{-2}$)\")\nax2.set_ylabel(\"Incoming LW  \\n (W m$^{-2}$)\")\n# Format timestamps\nax1.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%y'))\nax2.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%y'))\n# Format and rotate ticks\nplt.setp(ax1.get_xticklabels(), rotation=45, fontsize=10, ha='right')\nplt.setp(ax2.get_xticklabels(), rotation=45, fontsize=10, ha='right')\n# Label x-axes\nax1.set_xlabel('Date')\nax2.set_xlabel('Date')\n# Set figure title\nfig.suptitle('Incoming SW and LW radiation at BSRN station Gobabeb, Namibia')\n# Show figure\nfig.tight_layout()\nplt.show()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-4.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö Practice 4.",
    "text": "üìö Practice 4.\nSaturation vapor pressure, ( $ e^*(T_a) $ ), is the maximum pressure of water vapor that can exist in equilibrium above a flat plane of water at a given temperature. It can be calculated from the Tetens equation:\n e^{*}(T_{a}) = a \\times exp({\\frac{b \\cdot T_{a}}{T_{a} + c}}) \nwhere $ T_a $ is the air temperature in ¬∞C, $ a = 0.611 $ kPa, $ b = 17.502 $, and $ c = 240.97 ¬∞C $.\n\nCalculate ( $ e^*(T_a) $ ) in kPa for all temperatures in bsrn.\nPlot temperature vs.¬†saturation vapor pressure for the BSRN station. Be sure to format your plot appropriately and include axis labels, a title, and a legend, if necessary.\nCompare your plot to Figure 3-1 in Campbell and Norman (1998). Do they look more or less the same?\n\n\n\nCode\n\n# 1. Calculate saturation vapor pressure in kPa for a T_degC column in bsrn and assign it to a new column 'e_sat_kPa' \nimport numpy as np\nbsrn['e_sat_kPa'] = 0.611 * np.exp((17.502 * bsrn.T_degC) / (bsrn.T_degC + 240.97))\n\n# 2. Create a scatterplot of temperature versus stauration vapor pressure. Be sure to format the x-axis ticks as dates.\nfig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(1,1,1)\nplt.scatter(bsrn.T_degC,bsrn.e_sat_kPa)\n# set xlabel\nax.set_xlabel('Temperature (¬∞C)')\n# set ylabel\nax.set_ylabel('Saturation vapor pressure (kPa)')\n# set title\nax.set_title('Saturation vapor pressure as a function of temperature')\n\n# show the figure\nplt.show()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-5.",
    "href": "practice_sessions/answerkeys/practice_5-1_matplotlib_key.html#practice-5.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \nThe difference between saturation vapor pressure and ambient air pressure is called vapor pressure deficit, \\textit{VPD}. \\textit{VPD} can be calculated from saturation vapor pressure and relative humidity, h_r, as follows:  \\textit{VPD} \\, = \\, e^*(T_a) \\cdot (1 \\, - \\, h_r) where h_r is expressed as a fraction.\n\nCalculate the vapor pressure deficit for the BSRN data.\nCalculate the mean hourly RH and \\textit{VPD} over the entire month.\nPlot RH and \\textit{VPD} as a function of time of day. (for extra python points, try plotting both variables on one plot using ax.twinx())\nHow does relative humidity vary throughout the day? Why?\nCompare your plot(s) to Figure 3-3 in Campbell and Norman (1998). How do the values of e^*(T_a) and \\textit{VPD} for the BSRN station compare to those at constant vapor pressure in Figure 3-3?\n\n\n\n\ncn\n\n\n\n\nCode\n# Calulate VPD in kPa for bsrn data:\nbsrn['VPD_kPa'] = bsrn.e_sat_kPa * (1 - bsrn.RH/100)\n\n# For each hour in the day, calculate the monthly means\nbsrn_hourly = bsrn.groupby(bsrn.index.hour).mean()\n\n# plot the hourly means of VPD and e_sat_kPa. Use ax.twinx() to plot both variables on the same axes.\nfig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(1,1,1)\nax2 = ax.twinx()\nax.plot(bsrn_hourly.index,bsrn_hourly.RH/100,color='blue')\nax2.plot(bsrn_hourly.index,bsrn_hourly.VPD_kPa,color='red')\n# set xlabel\nax.set_xlabel('Hour of day')\n# set ylabel\nax2.set_ylabel('VPD (kPa)',color='red')\nax.set_ylabel('Relative Humidity [0-1]',color='blue')\n# set title\nax.set_title('Hourly means of VPD and Relative Humidity')\n# show the figure\n\n\n\n\nText(0.5, 1.0, 'Hourly means of VPD and Relative Humidity')"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-1.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nDefine a new list of floats with 8 elements called my_list.\n\nFind the 5th element in your list.\nCreate a new list containing every other value in your original list.\nUsing slicing and two different methods of indexing, remove the first and last values in your list.\n\n\n\nCode\n# Define a new list called my_list.\nmy_list = [432.0,-401.943582,3.9,0.8712054,57849.097,1.2753,-98437.0,7.78]\nprint(f\"my_list: {my_list}\")\n# Find the 5th element.\nprint(f\"my_list 5th element:{my_list[4]}\")\n# New list with every other value.\nevery_other = my_list[::2]\nprint(f\"every_other: {every_other}\")\n# Remove first and last values. \nprint(f\"first and last removed: {my_list[1:-1]}\")\n\n\nmy_list: [432.0, -401.943582, 3.9, 0.8712054, 57849.097, 1.2753, -98437.0, 7.78]\nmy_list 5th element:57849.097\nevery_other: [432.0, 3.9, 57849.097, -98437.0]\nfirst and last removed: [-401.943582, 3.9, 0.8712054, 57849.097, 1.2753, -98437.0]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-2.",
    "href": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-2.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \nUse indexing to extract the second letter of the third element (‚Äòa‚Äô) in str_list.\n\n\nCode\nstr_list = ['energy', 'water', 'carbon']\n\n\n\n\nCode\nprint(f\"str_list[2][1]: {str_list[2][1]}\")\n\n\nstr_list[2][1]: a"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-3.",
    "href": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-3.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \nCreate a copy of my_list, which you assigned above.\n\nUsing indexing or list operators, remove the first and last elements of your copied list.\nSort both the original list and the copied list in reverse order.\nUse the len() function and a boolean operator to determine which list is longer.\n\n\n\nCode\n# Create a copy of mylist.\n\nmy_list_copy = my_list.copy()\nmy_list_copy = my_list_copy[1:-1]\n\n\nprint(f\"my_list: {my_list}\")\nprint(f\"my_list_copy: {my_list_copy}\")\n\n# Sort both lists from largest to smallest.\nmy_list.sort(reverse=True)\nprint(f\"Reverse sorted my_list: {my_list}\")\n\nmy_list_copy.sort(reverse=True)\nprint(f\"Reverse sorted my_list_copy: {my_list_copy}\")\n\n# Determine which list is longer.\nif len(my_list) &gt; len(my_list_copy):\n    print(\"my_list is longer\")\nelse:\n    print(\"my_list_copy is longer\")\n\n\nmy_list: [432.0, -401.943582, 3.9, 0.8712054, 57849.097, 1.2753, -98437.0, 7.78]\nmy_list_copy: [-401.943582, 3.9, 0.8712054, 57849.097, 1.2753, -98437.0]\nReverse sorted my_list: [57849.097, 432.0, 7.78, 3.9, 1.2753, 0.8712054, -401.943582, -98437.0]\nReverse sorted my_list_copy: [57849.097, 3.9, 1.2753, 0.8712054, -401.943582, -98437.0]\nmy_list is longer"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-4.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nCreate a new list of 10 random floats between 0 and 1 called rand_list.\nAdd rand_list and my_list together in a new list called float_list.\nPrint the result.\n\n\nCode\n# Create a list of 10 random numbers between 0 and 1:\nfrom random import random\nrand_list = [random() for i in range(10)]\n\n# Add the lists together.\nfloat_list = rand_list + my_list\n\n# Print the result\nprint(float_list)\n\n\n[0.10955523298441361, 0.32572232971017967, 0.13761744658626607, 0.3203685653642424, 0.8091200680274167, 0.23342354410038746, 0.2821092128951217, 0.6901705052507255, 0.8891754795166417, 0.327553436209607, 57849.097, 432.0, 7.78, 3.9, 1.2753, 0.8712054, -401.943582, -98437.0]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-5.",
    "href": "practice_sessions/answerkeys/practice_1-2_lists_key.html#practice-5.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \nUse the range() function to construct a list of all hundreds (e.g.¬†100, 200, etc.) between 0 and 1000, inclusive.\n\n\nCode\n# Construct a list of hundreds from 0 to 1000\nhundreds = list(range(0,1001,100))\n# Print your list\nprint(hundreds)\n\n\n[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-1_variables_key.html#variables-operators",
    "href": "practice_sessions/answerkeys/practice_1-1_variables_key.html#variables-operators",
    "title": "Practice 1-1: Variables + Operators",
    "section": "Variables + Operators",
    "text": "Variables + Operators"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-1.",
    "title": "Practice 1-1: Variables + Operators",
    "section": "üìö Practice 1.",
    "text": "üìö Practice 1.\nThe laws of conservation state that in a closed system, mass, energy, and momentum can be neither created nor destroyed. Thus, the energy coming into the Earth‚Äôs surface (via solar radiation) must be equal to the energy going out from the Earth‚Äôs surface. The energy coming in via solar radiation can be written:\nR_{\\text{in}} = G_s \\pi {r_{e}}^2 (1 - \\alpha) where r_e is the radius of the Earth; \\alpha is the Earth‚Äôs albedo, a fraction correponding to the amount of incident radiation that is reflected; and G_s is the Solar Constant, or the flux density of the solar radiation at the Earth‚Äôs surface. The Solar Constant can be calculated according to the equation\nG_s = \\sigma {T_{sun}}^4 \\left( \\frac{4 \\pi {r_{sun}}^2}{4 \\pi d^2} \\right)\nwhere \\sigma is the Stefan-Boltzmann constant, T_{sun} is the temperature of the sun, r_{sun} is the radius of the sun, and d is the average distance between the sun and the Earth. The outgoing radiation from the Earth is given by the Stefan-Boltzmann law:\nR_{\\text{out}} = \\varepsilon \\sigma A_{e} {T_e}^4\nwhere \\varepsilon is the emissivity of the Earth, A_e is the surface area of the Earth approximated as a sphere, and T_e is the temperature of the Earth‚Äôs surface.\nGiven:\n\n\\sigma = 5.67 \\times 10-8 W m-2 K-4\nthe radius of the sun is 6.957 \\times 105 km,\nthe temperature of the sun is 5778 K,\nthe average distance between the sun and the Earth is 1.5 \\times 108 km,\nthe average albedo of the planet is 0.3\nand the emissivity of the Earth is 1.0,\n\n\n\n\nCalculate the Solar Constant in W m-2. Print your answer rounded to 3 decimal places.\n\n\nCalculate the temperature of the Earth‚Äôs surface in ¬∞C. Print your answer as both a float and an integer.\n\n\nThe actual global surface temperature of the Earth is about 14.6¬∞C. What accounts for the difference between the answer you calculated above in the actual surface temperature?\n\n\n\nShow your work by including comments in your code and assigning variables."
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-3.",
    "href": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-3.",
    "title": "Practice 1-1: Variables + Operators",
    "section": "üìö Practice 3.",
    "text": "üìö Practice 3.\nAssign your first and last names to variables and use the + operator to combine them into a single variable. Practice capitalizing the first letter and then the entire string. Print your answers.\n\n\nCode\n# Define variables\nfirst = 'Kelly'\nlast = 'Caylor'\n# Combine in a single string.\nfull_name = first + ' ' + last\n# Capitalize the first letter\ncap_name = full_name.capitalize()\n# Capitalize the entire string.\nupper_name = full_name.upper()\n# Print outputs.\nprint(full_name)\nprint(cap_name)\nprint(upper_name)\n\n\nKelly Caylor\nKelly caylor\nKELLY CAYLOR"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-4.",
    "title": "Practice 1-1: Variables + Operators",
    "section": "üìö Practice 4.",
    "text": "üìö Practice 4.\nRewrite your answers to practice questions 1a and 1b using formatted print statements. Each answer should include: 1. What you are solving for; 2. Your solution as an integer, float, and a float rounded to 3 decimal places; and 3. Units. For example:\n\nThe radius of the earth is 6,378 km.\n\n\n\n\nCode\n# Formatted print statement for 1a.\nprint('Solar constant = %d W m-2' % (int(g_s)))\nprint('Solar constant = %f W m-2' % (g_s))\nprint('Solar constant = %.3f W m-2' % (g_s))\n\n# Formatted print statement for 1b.\nprint(\"Temperature of the Earth's surface =  %d¬∞C\" % (int(T_e)))\nprint(\"Temperature of the Earth's surface =  %f¬∞C\" % (T_e))\nprint(\"Temperature of the Earth's surface =  %.3f¬∞C\" % (T_e))"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-5.",
    "href": "practice_sessions/answerkeys/practice_1-1_variables_key.html#practice-5.",
    "title": "Practice 1-1: Variables + Operators",
    "section": "üìö Practice 5.",
    "text": "üìö Practice 5.\nFollowing the example above, create a variable corresponding to the day on which you were born based on user input. Convert both variables to floats and assign the float versions to new variables. Lastly, use one of the boolean operators to evaluate which variable is greater ‚Äì the day or the month ‚Äì and print the result.\n\n\nCode\n# User input variable for month of birth\nmonth_in = input('Month of birth (1-12): ')\n# User input variable for day of birth\nday_in = input('Day of birth (1-31): ')\n# Convert birth day and month to floats.\nmonth = float(month_in)\nday = float(day_in)\n# Evaluate boolean operation + print result.\nprint(month &gt; day)\n\n\nNameError: name 'month_in' is not defined\n\n\n\n\n\n\nCode\n# IGNORE THIS CELL\nfrom IPython.core.display import HTML\ndef css_styling():\n    styles = open(\"./styles/exercises.css\", \"r\").read()\n    return HTML(styles)\ncss_styling()"
  },
  {
    "objectID": "practice_sessions/practice_2-2_structured_data.html",
    "href": "practice_sessions/practice_2-2_structured_data.html",
    "title": "Practice 1-4: Structured Data in Python",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | ‚û°Ô∏è Next Session |"
  },
  {
    "objectID": "practice_sessions/practice_2-2_structured_data.html#practice-1.",
    "href": "practice_sessions/practice_2-2_structured_data.html#practice-1.",
    "title": "Practice 1-4: Structured Data in Python",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nDictionaries are an extremely common data structure. Often data is easiest to store according to keys, where each row of data has a unique key.\nFor example, a dictionary of students might have a key for each student‚Äôs name or id, and then a set of values that are associated with that student.\n\nMake a dictionary of your peers.\nCome up with 3-4 questions and ask 5-6 of your peers to give answers to each one. The questions can be anything you want, but they should be questions that can be answered with a single word or number.\nFor example, you might ask: - What is your favorite color? (pretty weak question) - How many siblings do you have? (ok, but not great) - What is your favorite genre of film? (better) - On a scale of 1-10, how well do you feel that you understand python dictionaries? (better still)\nMake sure you have a key for each person, and then a set of values for each question.\nBased on each person‚Äôs responses, build a dictionary in the cell below:\n(note: You will end up with a dictionary of dictionaries)\n# Example:\nmy_dict = {\n    'person1': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n    'person2': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n    'person3': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n}"
  },
  {
    "objectID": "practice_sessions/practice_2-2_structured_data.html#dictionary-to-dataframe",
    "href": "practice_sessions/practice_2-2_structured_data.html#dictionary-to-dataframe",
    "title": "Practice 1-4: Structured Data in Python",
    "section": "Dictionary to dataframe",
    "text": "Dictionary to dataframe\nNow that you have a dictionary, you can convert it to a dataframe.\n\nConvert your dictionary to a dataframe\nUse the pd.DataFrame() function to convert your dictionary to a dataframe.\nimport pandas as pd\n\n# Convert a dictionary to a dataframe\ndf = pd.DataFrame(my_dict)\n\n\nInvestigate your dataframe using the following functions:\n\ndf.head()\ndf.tail()\ndf.info()\n\nIs your dataframe what you expected? If not, what is different? Why?? How would you need to change your data structure to get the dataframe you expected?\ndf.transpose() might be helpful here. What does it do? create a new dataframe that is a transposed version of your original dataframe.\n# Transpose a dataframe\ndf_transposed = df.transpose()\n\n\nCode\n# Transpose your dataframe so that the people are the rows and the questions are the columns.\n\n\n\n\n\nVisualize/summarize your dataframe using one or more of the following functions:\n\ndf.describe()\ndf.plot()\ndf.hist()"
  },
  {
    "objectID": "practice_sessions/practice_2-2_structured_data.html#practice-2.",
    "href": "practice_sessions/practice_2-2_structured_data.html#practice-2.",
    "title": "Practice 1-4: Structured Data in Python",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \n\nStructured data search: Find structured data on the internet and convert it to a dataframe.\nYou‚Äôre looking for data that is in a table format, like a spreadsheet, but not available as an easy to download .csv or .excel file. This turns out to describe a lot of data!\nOften you can find this kind of data on wikipedia, or on government websites, or in research articles that contain tables of results.\n\n\nConvert your data to a dataframe"
  },
  {
    "objectID": "practice_sessions/practice_2-2_structured_data.html#explore-your-dataframe-using-the-following-functions",
    "href": "practice_sessions/practice_2-2_structured_data.html#explore-your-dataframe-using-the-following-functions",
    "title": "Practice 1-4: Structured Data in Python",
    "section": "Explore your dataframe using the following functions:",
    "text": "Explore your dataframe using the following functions:\n\ndf.describe()\ndf.plot()\ndf.hist()"
  },
  {
    "objectID": "practice_sessions/practice_1-1_variables.html",
    "href": "practice_sessions/practice_1-1_variables.html",
    "title": "Practice 1-1: Variables & Operators",
    "section": "",
    "text": "üè† Course Home | ‚û°Ô∏è Next Session |"
  },
  {
    "objectID": "practice_sessions/practice_1-1_variables.html#practice-3.",
    "href": "practice_sessions/practice_1-1_variables.html#practice-3.",
    "title": "Practice 1-1: Variables & Operators",
    "section": "üìö Practice 3.",
    "text": "üìö Practice 3.\nAssign your first and last names to variables and use the + operator to combine them into a single variable. Practice capitalizing the first letter and then the entire string. Print your answers.\n###\n\nüìö Practice 4 Use the code below to write a formatted string that prints the sentence My name is [YOUR FIRST NAME]. I am [YOUR AGE] years old., inputing your name and age. Replace first with the name of the variable you assigned to your first name in the previous question. Replace age with your age as an integer.\n\n###\n\nüìö Practice 5.\nCollect some facts about your classroom neighbor. Assign these facts to variables and create 3-4 print statements using format strings.\n\nprint(f‚Äù{name} has traveled to {country} {this_many} times‚Äù)"
  },
  {
    "objectID": "practice_sessions/practice_1-1_variables.html#practice-6.",
    "href": "practice_sessions/practice_1-1_variables.html#practice-6.",
    "title": "Practice 1-1: Variables & Operators",
    "section": "üìö Practice 6.",
    "text": "üìö Practice 6.\nUse the input function to create two variables: one corresponding to the day on which you were born based on user input and one corresponding to the month you were born.\nConvert both variables to floats and assign the float versions to new variables. Lastly, use one of the boolean operators to evaluate which variable is greater ‚Äì the day or the month ‚Äì and print the result."
  },
  {
    "objectID": "index.html#eds217-stoplight---let-us-know-how-thinks-are-going-in-real-time",
    "href": "index.html#eds217-stoplight---let-us-know-how-thinks-are-going-in-real-time",
    "title": "EDS 217 - Python for Environmental Data Science",
    "section": "üö¶ EDS217 Stoplight - Let us know how thinks are going in real time!",
    "text": "üö¶ EDS217 Stoplight - Let us know how thinks are going in real time!\n\nCourse Repository\nEDS217_2023 on GitHub"
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "EDS 217 - Python for Environmental Data Science",
    "section": "Learning Goals",
    "text": "Learning Goals\n(what you will be able to do)\n\nSetup a python environment for data science using conda.\nConduct reproducible analyses within interactive jupyter notebook environments\nUse the VSCode IDE to write and execute python notebooks as well as scripts.\nRead and write basic-to-intermediate scripts and programs in the Python programming language\nPerform analyses on structured data using numpy\nLoad, explore, aggregate, analyze, and display data using pandas.\nLearn to visualize data using matplotlib and friends.\nApply all of these tools to analyze environmental datasets\nDevelop a short tutorial on how to use a python data science library for environmental analysis"
  },
  {
    "objectID": "index.html#course-activities",
    "href": "index.html#course-activities",
    "title": "EDS 217 - Python for Environmental Data Science",
    "section": "Course Activities",
    "text": "Course Activities\nOur time together will be spent in a combination of lecture, interactive sessions, paired practice sessions, and group work.\n\nLectures\nLectures will be used to introduce general concepts and principles of the python language. We won‚Äôt have too many of these, but they will be used to introduce new concepts and provide context for the interactive sessions.\n\n\nInteractive Sessions\nInteractive sessions will be used to demonstrate the use of python syntax, libraries, and other tools essential to the environmental data science workflow. These sessions will generally be conducted in jupyter notebooks, and will be available for you to download and use as a reference. We will also use these sessions to work through example code and computations related to the major course topics.\n\n\nPractice Sessions\nPractice sessions will be used to provide opportunities to using the concepts, tools, and libraries presented during interactive sessions to solve more open-ended programming problems. While the goal is to develop independent confidence in python programming, we will work through these problems in paired/collaborative coding. Example solutions to these practice problems will always be available.\n\n\nTryPy Sessions\nTryPy sessions are designed to allow you to develop your own reproducible workflows based on core data science principles. We will often structure these sessions in a similar way to prior activities from EDS221. This will allow you to get a better understanding of the differences between python and R as well as the strengths and weaknesses of each.\n\n\nGroup Work\nYour group project is a ‚ÄúData Science Show-and-Tell‚Äù that will extend the skills you develop during the first week of the course through the creation of collaborative presentations focused on datasets and libraries of your choosing. Working in teams, you will develop a short, reproducible tutorial on how to use a python data science library with examples using datasets relevant to environmental analysis. These tutorials will be presented to the class during the final week of the course and shared with the class via a github repository."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "EDS 217 - Python for Environmental Data Science",
    "section": "Course Outline",
    "text": "Course Outline\n\nTuesday, September 5\n\nDay[0] - Ready, Set, Python!\nThe materials for our first day are designed to introduce the basics of working with Python and getting your local machines setup for the course.\n\n\nMorning Session\nEntry Survey\nIntro to Python Data Science\nInteractive Session 0-1 - Ready, Set, Python!\n\n\nAfternoon Session\nGetting Help\nInteractive Session 0-2 - Hello, Python Data Science\n\n\n\nWednesday, September 6\n\nDay[1] - Do you speak Python?\nToday we will explore variables and learn the basic syntax of the python programming language.\n\n\nMorning Session\nInteractive Session 1-1 - Variables & Operators\nPractice Session 1-1 - Variables & Operators\nInteractive Session 1-2 - Lists and Indexing\n\n\nAfternoon Session\nPractice Session 1-2 - Lists and Indexing\nTryPy 01 - St.¬†Louis Lead Data\n\n\n\nThursday, September 7\n\nDay[2] - Going with the flow\nToday we complete our quick tour of the core python language as we learn the fundamentals of controlling the flow of programs in python. We will also prepare ourselves for the data science packages to come by learning how to use python to work with structured data.\n\n\nMorning Session\nInteractive Session 2-1 - Ifs or Elses\nPractice Session 2-1 - Ifs or Elses\nInteractive Session 2-2 - Structured Data\n\n\nAfternoon Session\nThe Zen of Python\nPractice Session 2-2 - Structured Data\nTryPy02 - Conditionals and Loops\n\n\n\nFriday, September 8\n\nDay[3] - Numpy üßÆ (Hooray for Arrays!)\n\n\nMorning Session\nSession 3-1 - NumPy\n\n\nAfternoon Session\nDebugging (Anna) [COMING SOON]\nPractice Session 3-1 - NumPy\n\n\n\nMonday, September 11\n\nDay[4] - Pandas üêº\nOur journey into Python‚Äôs Data Science toolkit begins with NumPy, a library designed to perform advanced calculations on matrices.\nWe end our first week with arguably the most important library in the Python data science ecosystem: pandas.\nNow that we‚Äôve learned how to import, manage, and analyze data using pandas, it‚Äôs time to make some graphs!\n\n\nMorning Session\nSession 4-1 - Pandas\n\n\nAfternoon Session\nCo-Pilot [COMING SOON]\nPractice Session 4-1 - Pandas\n\n\n\nTuesday, September 12\n\nDay[5] - Matplotlib üìà\nMatplotlib is the primary libary used for plotting data in Python (although there are some great alternatives), so we will start there.\n\n\nMorning Session\nSession 5-1 - Matplotlib\n\n\nAfternoon Session\nPractice Session 5-1 - Matplotlib\n\n\n\nWednesday September 13 - Friday, September 15\n\nDay[6:] - Group Project Work ‚úèÔ∏è\nOur final activity will be a group project in which you work with a team of 3-4 of your classmates to create a brief tutorial introducting one of the many other libraries available to conduct environmental data science in Python.\nGroup Project\nYou will develop your tutorial using the same Jupyter Notebook structures that we‚Äôve been using throughout the class and by incorporating examples using a dataset of your choosing.\nThe goal of this excercise is to collaboratively develop a set of data, notebooks, and visualizations that are entirely reproducible, shared on github, and used by others to learn how to use the library you‚Äôve chosen.\nOn our last day (Day[-1]), we‚Äôll spend the afternoon conducting a Python Data Science Show and Tell"
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html",
    "href": "practice_sessions/practice_5-1_matplotlib.html",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home\nDon‚Äôt forget to start your notebook with a cell containing the import statements you need for the session.\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates"
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html#practice-1.",
    "href": "practice_sessions/practice_5-1_matplotlib.html#practice-1.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nRecreate the plot below. You do not need to match the colors exactly, but do not rely on matplotlib defaults. Note: do not worry about the equation(s); these are included to indicate which functions to plot."
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html#practice-2.",
    "href": "practice_sessions/practice_5-1_matplotlib.html#practice-2.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \nRecreate the plot below. You do not need to match the colors exactly, but do not rely on matplotlib defaults. Note: do not worry about the equation(s); these are included to indicate which functions to plot."
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html#practice-3.",
    "href": "practice_sessions/practice_5-1_matplotlib.html#practice-3.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \nImport the data from ./data/BSRN_data.csv and plot the temperature and relative humidity over the month of October 2019 at the BSRN station. Be sure to format the timestamps and include axis labels, a title, and a legend, if necessary."
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html#practice-4.",
    "href": "practice_sessions/practice_5-1_matplotlib.html#practice-4.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö Practice 4.",
    "text": "üìö Practice 4.\nSaturation vapor pressure, ( $ e^*(T_a) $ ), is the maximum pressure of water vapor that can exist in equilibrium above a flat plane of water at a given temperature. It can be calculated from the Tetens equation:\n e^{*}(T_{a}) = a \\times exp({\\frac{b \\cdot T_{a}}{T_{a} + c}}) \nwhere $ T_a $ is the air temperature in ¬∞C, $ a = 0.611 $ kPa, $ b = 17.502 $, and $ c = 240.97 ¬∞C $.\n\nCalculate ( $ e^*(T_a) $ ) in kPa for all temperatures in bsrn.\nPlot temperature vs.¬†saturation vapor pressure for the BSRN station. Be sure to format your plot appropriately and include axis labels, a title, and a legend, if necessary.\nCompare your plot to Figure 3-1 in Campbell and Norman (1998), included below. Do they look more or less the same?\n\n\n\n\ncn"
  },
  {
    "objectID": "practice_sessions/practice_5-1_matplotlib.html#practice-5.",
    "href": "practice_sessions/practice_5-1_matplotlib.html#practice-5.",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \nThe difference between saturation vapor pressure and ambient air pressure is called vapor pressure deficit, \\textit{VPD}. \\textit{VPD} can be calculated from saturation vapor pressure and relative humidity, h_r, as follows:  \\textit{VPD} \\, = \\, e^*(T_a) \\cdot (1 \\, - \\, h_r) where h_r is expressed as a fraction.\n\nCalculate the vapor pressure deficit for the BSRN data.\nCalculate the mean hourly RH and \\textit{VPD} over the entire month.\nPlot RH and \\textit{VPD} as a function of time of day. (for extra python points, try plotting both variables on one plot using ax.twinx())\nHow does relative humidity vary throughout the day? Why?\nCompare your plot(s) to Figure 3-3 in Campbell and Norman (1998). How do the values of e^*(T_a) and \\textit{VPD} for the BSRN station compare to those at constant vapor pressure in Figure 3-3?\n\n\n\n\ncn"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-1.",
    "title": "Exercise 2-1: Control Flow Statements",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nIn programs, if statements are useful for catching errors due to user input. Define two new variables based on user input: the first prompting for a temperature value and the second prompting for the units as ‚ÄúF‚Äù or ‚ÄúC‚Äù. Using the equation below, write an if statement that converts the temperature input to ¬∞C if it was given in ¬∞F or to ¬∞F if given in ¬∞C. Recall that all variables assigned based on user input are strings. Be sure to comment your code.\nFormula for conversion between ¬∞F and ¬∞C:  T_{^{\\circ} C} = (T_{^{\\circ} F} - 32) \\times 5/9"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-2.",
    "href": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-2.",
    "title": "Exercise 2-1: Control Flow Statements",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \nUsing nested if statements and your code from Practice question #1, convert the user input temperature to the opposite units (¬∞F to ¬∞C or vice versa), print a statement to the user that reports the temperature in the converted units and indicates whether or not the temperature below freezing.\nYour print statement should look something like,\nThe temperature is __¬∞C/F. It is (not) below freezing.\n\n\nCode\n# User input variables\ntemp_in = float(input(\"Temperature: \"))\nunits_in = input(\"Temperature units (F or C): \")\n\n# Convert temperature units\nif units_in == 'F':\n    temp = (temp_in - 32) * (5/9)\n    if temp &lt; 0:\n        print(\"The temperature is %d¬∞C. It is below freezing.\" % (temp))\n    elif temp == 0:\n        print(\"The temperature is %d¬∞C. It is freezing.\" % (temp))\n    else:\n        print(\"The temperature is %d¬∞C. It is not below freezing.\" % (temp))\nelse:\n    temp = (temp_in * (9/5)) + 32\n    if temp &lt; 32:\n        print(\"The temperature is %d¬∞F. It is below freezing.\" % (temp))\n    elif temp == 32:\n        print(\"The temperature is %d¬∞F. It is freezing.\" % (temp))\n    else:\n        print(\"The temperature is %d¬∞F. It is not below freezing.\" % (temp))"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-3.",
    "href": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-3.",
    "title": "Exercise 2-1: Control Flow Statements",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \n\nCreate a list of the six organic elements sorted in alphabetical order and then print each element in the list.\nGiven your sorted org_elements list and the corresponding list of atomic masses given in the cell below, use enumerate() in a for loop to print a formatted statement that expresses the atomic mass of of each element.\n\nYour formatted print statement should include the name of the element, the atomic mass rounded to 2 decimal places, and units.\n\n\nCode\n# Define org_elements\norg_elements = ['carbon', 'oxygen', 'hydrogen','phosphorous', 'sulfur','nitrogen']\n\norg_elements.sort()\n\n# Print each element in org_elements\nfor element in org_elements:\n    print(element)\n\n# Define list of atomic masses of 6 organic elements\natomic_mass = [12.011, 1.00784, 14.0067, 15.999, 30.97376, 32.065]  # g/mol\n\n# Iterate through org_elements + print the atomic mass of each element\nfor i,element in enumerate(org_elements):\n    mass = atomic_mass[i]\n    print('The atomic mass of %s is %.2f g/mol.' % (element,mass))\n\n\ncarbon\nhydrogen\nnitrogen\noxygen\nphosphorous\nsulfur\nThe atomic mass of carbon is 12.01 g/mol.\nThe atomic mass of hydrogen is 1.01 g/mol.\nThe atomic mass of nitrogen is 14.01 g/mol.\nThe atomic mass of oxygen is 16.00 g/mol.\nThe atomic mass of phosphorous is 30.97 g/mol.\nThe atomic mass of sulfur is 32.06 g/mol.\n\n\nAnother solution using zip() is given in the cell below.\n\n\nCode\nfor element,mass in zip(org_elements,atomic_mass):\n    print('The atomic mass of %s is %.2f g/mol.' % (element,mass))\n\n\nThe atomic mass of carbon is 12.01 g/mol.\nThe atomic mass of hydrogen is 1.01 g/mol.\nThe atomic mass of nitrogen is 14.01 g/mol.\nThe atomic mass of oxygen is 16.00 g/mol.\nThe atomic mass of phosphorous is 30.97 g/mol.\nThe atomic mass of sulfur is 32.06 g/mol."
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-4.",
    "title": "Exercise 2-1: Control Flow Statements",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nThe cell below contains monthly global land-ocean surface temperature in ¬∞F for each month during the years 2015-2022.\nUsing enumerate(), zip(), a nested for loop, or some combination of the three:\n\n\nCalculate the monthly global land-ocean surface temperature anomalies (deviation from the mean) in ¬∞C for 2015-2018. The mean global land-ocean surface temperature calculated over the 20th century was 15.6¬∞C.\n\n\nCreate a new list with the mean monthly global surface temperature anomalies in ¬∞C for 2015-2023 (i.e.¬†calculate the mean temperature anomaly for each month and put these values in a list). Use the command np.mean() to calculate mean values.\n\n\nPrint each monthly mean value with the name of the month and units.\n\n\n\n\n\nCode\n# Import numpy for mean calculations\nimport numpy as np\n\ntempF_2015 = [61.628, 61.7, 61.808, 61.448, 61.52, 61.538, 61.394, 61.52, 61.61, 62.042, 61.988, 62.168]\ntempF_2016 = [62.186, 62.546, 62.528, 62.06, 61.79, 61.52, 61.61, 61.916, 61.718, 61.682, 61.736, 61.628]\ntempF_2017 = [61.916, 62.132, 62.168, 61.772, 61.718, 61.376, 61.556, 61.646, 61.466, 61.7, 61.664, 61.754]\ntempF_2018 = [61.556, 61.61, 61.664, 61.682, 61.556, 61.466, 61.556, 61.448, 61.52, 61.916, 61.556, 61.718]\ntempF_2019 = [61.754, 61.79, 62.186, 61.898, 61.61, 61.7, 61.772, 61.79, 61.754, 61.898, 61.862, 62.042]\ntempF_2020 = [62.186, 62.312, 62.186, 62.114, 61.898, 61.736, 61.7, 61.646, 61.862, 61.664, 62.06, 61.538]\ntempF_2021 = [61.538, 61.232, 61.664, 61.43, 61.484, 61.592, 61.736, 61.556, 61.736, 61.88, 61.772, 61.61]\n\n# List of yearly lists (may or may not be useful)\ntempF_list = [tempF_2015, tempF_2016, tempF_2017, tempF_2018, tempF_2019, tempF_2020, tempF_2021]\n\n# List of years (probably useful)\nyears = [2015, 2016, 2017, 2018, 2019, 2020, 2021]\n\n\n\n\nCode\n# 4a. Monthly temperature anomalies\nprint('Practice 4a')\n# Empty list of lists\ntempC_list = []\nanomC_list = []\n# Iterate through yearly lists\nfor tempsF,year in zip(tempF_list,years):\n    # Empty list for a single year\n    tempsC = []\n    anomsC = []\n    # Iterate through a single year\n    for tempF in tempsF:\n        # Convert temp from F to C\n        tempC = (tempF - 32.0) * (5/9)\n        # Append to tempsC\n        tempsC.append(round(tempC,2))\n        # Calculate temp anomaly in ¬∞C\n        anomC = tempC - 15.6\n        # Append to anomsC\n        anomsC.append(round(anomC,2))\n    # Add list of ¬∞C temps to tempC_list (list of lists)\n    tempC_list.append(tempsC)\n    # Add list of anomalies in ¬∞C to anomC_list (list of lists)\n    anomC_list.append(anomsC)\nfor anom_list,year in zip(anomC_list,years):\n    print(f\"{year} anomalies: {anom_list}\")\n\n\n# 4b. Mean monthly temperature anomaly, 2015-2018\nprint('Practice 4b')\n# Empty list for monthly mean temperature anomalies\nmonthly_means = []\n# Set up generic counter loop with 12 iterations\nfor i in range(12):\n    # Generate list of temperature anomalies for each month by extracting the ith value from each sublist.\n    monthly = [anom[i] for anom in anomC_list]\n    # Calculate mean for month i\n    monthly_mean = np.mean(monthly)\n    # Add mean for month i to list of means\n    monthly_means.append(round(monthly_mean,4))\n# Print list of mean monthly temperature anomalies, 2015-2018.\nprint(f\"monthly_means: {monthly_means}\")\n\n\nPractice 4a\n2015 anomalies: [0.86, 0.9, 0.96, 0.76, 0.8, 0.81, 0.73, 0.8, 0.85, 1.09, 1.06, 1.16]\n2016 anomalies: [1.17, 1.37, 1.36, 1.1, 0.95, 0.8, 0.85, 1.02, 0.91, 0.89, 0.92, 0.86]\n2017 anomalies: [1.02, 1.14, 1.16, 0.94, 0.91, 0.72, 0.82, 0.87, 0.77, 0.9, 0.88, 0.93]\n2018 anomalies: [0.82, 0.85, 0.88, 0.89, 0.82, 0.77, 0.82, 0.76, 0.8, 1.02, 0.82, 0.91]\n2019 anomalies: [0.93, 0.95, 1.17, 1.01, 0.85, 0.9, 0.94, 0.95, 0.93, 1.01, 0.99, 1.09]\n2020 anomalies: [1.17, 1.24, 1.17, 1.13, 1.01, 0.92, 0.9, 0.87, 0.99, 0.88, 1.1, 0.81]\n2021 anomalies: [0.81, 0.64, 0.88, 0.75, 0.78, 0.84, 0.92, 0.82, 0.92, 1.0, 0.94, 0.85]\nPractice 4b\nmonthly_means: [0.9686, 1.0129, 1.0829, 0.94, 0.8743, 0.8229, 0.8543, 0.87, 0.8814, 0.97, 0.9586, 0.9443]\n\n\n\n\nCode\n# Alternative:\nmonthly_means = []\nfor anomC_15,anomC_16,anomC_17,anomC_18,anomC_19,anomC_20,anomC_21 in zip(*anomC_list):\n# Note: * is an \"unpacking\" operator that extracts each sublist of anomC_list making them iterables.\n# for i,(anomC_15,anomC_16,anomC_17,anomC_18) in enumerate(zip(anomC_list[0],\n#                                                              anomC_list[1],\n#                                                              anomC_list[2],\n#                                                              anomC_list[3])):\n    # Put month i values in a list\n    monthly = [anomC_15, anomC_16, anomC_17, anomC_18, anomC_19, anomC_20, anomC_21]\n    # Calculate mean for month i\n    monthly_mean = np.mean(monthly)\n    # Add mean for month i to list of means\n    monthly_means.append(round(monthly_mean,4))\n# Print list of mean monthly temperature anomalies, 2015-2021.\nprint(f\"Monthly means (alternative approach): {monthly_means}\")\n\n\n\nMonthly means (alternative approach): [0.9686, 1.0129, 1.0829, 0.94, 0.8743, 0.8229, 0.8543, 0.87, 0.8814, 0.97, 0.9586, 0.9443]\n\n\n\n\nCode\n# 4c. Print mean temperature anomalies by month\nprint('Practice 4c')\n\nmonths = ['January', 'February', 'March', 'April', 'May', 'June', \n          'July', 'August', 'September', 'October', 'November', 'December']\n\nfor month,mean in zip(months,monthly_means):\n    print(f'Mean {month} temperature anomaly, {min(years)}-{max(years)}: {mean:.4f}¬∞C')\n\n\nPractice 4c\nMean January temperature anomaly, 2015-2021: 0.9686¬∞C\nMean February temperature anomaly, 2015-2021: 1.0129¬∞C\nMean March temperature anomaly, 2015-2021: 1.0829¬∞C\nMean April temperature anomaly, 2015-2021: 0.9400¬∞C\nMean May temperature anomaly, 2015-2021: 0.8743¬∞C\nMean June temperature anomaly, 2015-2021: 0.8229¬∞C\nMean July temperature anomaly, 2015-2021: 0.8543¬∞C\nMean August temperature anomaly, 2015-2021: 0.8700¬∞C\nMean September temperature anomaly, 2015-2021: 0.8814¬∞C\nMean October temperature anomaly, 2015-2021: 0.9700¬∞C\nMean November temperature anomaly, 2015-2021: 0.9586¬∞C\nMean December temperature anomaly, 2015-2021: 0.9443¬∞C"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-5.",
    "href": "practice_sessions/answerkeys/practice_2-1_control_flow_statements_key.html#practice-5.",
    "title": "Exercise 2-1: Control Flow Statements",
    "section": "üìö Practice 5.",
    "text": "üìö Practice 5.\nUse a list comprehension to print a list of all months that had an anomaly above the average monthly anomaly.\nSome helpful code is provided below:\nmonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\naverage_anomaly = np.mean(mean_monthly_anomalies)\nRecall that list comprehensions can contain if statements. For example:\n[item for item in list if item &gt; value]\nAnd they can also contain enumerate statements:\n[item for index,item in enumerate(list) if other_list[index] &gt; value]\n\n\nCode\nmonths = ['January', 'February', 'March', 'April', \n          'May', 'June', 'July', 'August', 'September', \n          'October', 'November', 'December']\n\navg_anomaly = np.mean(monthly_means)\n\nprint(\"Months with above average temperature anomalies:\")\n[\n print(month) for i,month in enumerate(months) \n if monthly_means[i] &gt; avg_anomaly\n]\n\n\nMonths with above average temperature anomalies:\nJanuary\nFebruary\nMarch\nApril\nOctober\nNovember\nDecember\n\n\n[None, None, None, None, None, None, None]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "",
    "text": "Code\n# Imports\nimport numpy as np"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-1.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö Practice 1.",
    "text": "üìö Practice 1.\nCreate the following arrays and assign the corresponding variable names:\n\na\n\n\\begin{bmatrix}\n     4 & 5 & 0 & 12 & -1 \\\\\n     8 & -21 & -4 & 6 & 3 \\\\\n     17 & 1 & -13 & 7 & 0\n\\end{bmatrix}\n\nb\n\n\\begin{bmatrix}\n     1.0 & 2.7 & 0 & 0.188 & 4.07 & 0.24\n\\end{bmatrix}\n\nc\n\n\\begin{bmatrix}\n     0.4 \\\\\n     0.8 \\\\\n     1.2 \\\\\n     1.6 \\\\\n     2.0 \\\\\n     2.4\n\\end{bmatrix}\n\n\n\n\nCode\n# Create 3x5 array of integers\na = np.array([[4, 5, 0, 12, -1], [8, -21, -4, 6, 3], [17, 1, -13, 7, 0]])\n\n# Create a 1x6 array of floats\nb = np.array([[1.0, 2.7, 0, 0.188, 4.07, 0.24]])\n\n# Create a one-d array with 6 elements\nc = np.array([0.4, 0.8, 1.2, 1.6, 2.0, 2.4])"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-2.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-2.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \n\n\nCreate a new array d of integers the multiples of 3 between 0 and 100.\n\n\nCreate an array f 10 evenly spaced elements between 0 and 2.\n\n\nRe-create array c from Practice 1c using a function. Assign this to variable name g.\n\n\n\n\nCode\n# a.\nd = np.arange(1,100,3)\n# b. \nf = np.linspace(0,2,10)\n# c.\ng = np.linspace(0.4,2.4,6)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-3.-assign-the-following-to-variables",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-3.-assign-the-following-to-variables",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 3.  Assign the following to variables:",
    "text": "üìö  Practice 3.  Assign the following to variables:\n\n\nA 5x3 array of ones.\n\n\nA one-dimensional array of 6 zeros.\n\n\nA 7x7 identity array.\n\n\nA random 10x10 array.\n\n\n\n\nCode\n# a. \nones = np.ones((5,3))\n# b.\nzeros6 = np.zeros(6)\n# c.\neye = np.eye(7)\n# d.\nrand100 = np.random.rand(10,10)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-4.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-4.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nUse array methods and the array you created in Practice 2a (d) to count the number of multiples of 3 between 0 and 100.\n\n\nCode\n# Print size of d\nd.size\n\n\n33"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-5.-using-the-array-you-created-in-practice-3d",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-5.-using-the-array-you-created-in-practice-3d",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 5.  Using the array you created in Practice 3d,",
    "text": "üìö  Practice 5.  Using the array you created in Practice 3d,\n\n\nPrint all the elements in column 4.\n\n\nPrint all the elements in row 7.\n\n\nExtract the 4x4 subarray at the center of the array and assign it as a new variable.\n\n\nPrint the last two values in column 10.\n\n\n\n\nCode\n# a. Print all the elements in column 4\nprint(rand100[:,3])\n\n# b. Print all the elements in row 7\nprint(rand100[6])\n\n# c. Extract the 4x4 subarray at the center of the array and assign it as a new variable.\nprint(rand100[3:7,3:7])\n\n# d. Print the last two values in column 10.\nprint(rand100[-2:,9])\n\n\n[0.47355526 0.16640376 0.48631518 0.42032605 0.12026176 0.35326962\n 0.70223167 0.45058564 0.921611   0.26428948]\n[0.12746749 0.86608784 0.35305607 0.70223167 0.85187631 0.7585961\n 0.21004781 0.54591833 0.06646384 0.74774   ]\n[[0.42032605 0.37801466 0.83169814 0.26346432]\n [0.12026176 0.22708852 0.72144037 0.0987514 ]\n [0.35326962 0.10750686 0.88008533 0.43263521]\n [0.70223167 0.85187631 0.7585961  0.21004781]]\n[0.70838202 0.41093916]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-6.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-6.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \nCreate a blank 8x8 matrix and fill it with a checkerboard pattern of 0s and 1s using indexing.\n\n\nCode\n# Blank 8x8 array\nq = np.zeros((8,8))\n\n# Fill with checkerboard pattern\nq[::2,1::2] = 1\nq[1::2,::2] = 1\nq\n\n\narray([[0., 1., 0., 1., 0., 1., 0., 1.],\n       [1., 0., 1., 0., 1., 0., 1., 0.],\n       [0., 1., 0., 1., 0., 1., 0., 1.],\n       [1., 0., 1., 0., 1., 0., 1., 0.],\n       [0., 1., 0., 1., 0., 1., 0., 1.],\n       [1., 0., 1., 0., 1., 0., 1., 0.],\n       [0., 1., 0., 1., 0., 1., 0., 1.],\n       [1., 0., 1., 0., 1., 0., 1., 0.]])"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-7.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-7.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \n\n\nCreate a 3x3 matrix with values ranging from 0 to 8.\n\n\nReverse the order of elements in your random 10x10 array from 3d.\n\n\n\n\nCode\n# a. Create a 3x3 matrix with values ranging from 0 to 8\nw = np.arange(0,9)\nv = w.reshape(3,3)\n\n# b. Reverse the order of elements in your random 10x10 array from 3d.\nrand100_rev = np.flip(rand100)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-8.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-8.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 8. ",
    "text": "üìö  Practice 8. \nCreate two random 1-D arrays of length 10. Merge them into a 2x10 array and then a 10x2 array.\n\n\nCode\n# 2 random 1-D arrays\nj = np.random.rand(10)\nk = np.random.rand(10)\n\n# Concat as 2x10 array\nvert = np.vstack((j,k))\n# Concat as 10x2 array\nhoriz = vert.T # or np.column_stack((j,k)).shape"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-9.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-9.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 9. ",
    "text": "üìö  Practice 9. \n\n\nSplit your random 10x10 array from 3d into two 10x5 arrays.\n\n\nCombine the first 10x5 array from (a), the 10x2 array from 8b, and the other 10x5 array from (a). In other words, recombine the 10x10 array from 3d with two new columns in index positions 5 and 6. Your final array should have 10 rows and 12 columns. Verify this by printing the shape of the resulting array.\n\n\n\n\nCode\n# Split into equal 10x5 arrays.\nx,y = np.hsplit(rand100,[5])\n\n# Concatenate x, y, and horiz\nrand120 = np.concatenate((x,y,horiz), axis=1)\n\n# Print dimensions\nprint(rand120.shape)\n\n\n(10, 12)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-10.",
    "href": "practice_sessions/answerkeys/practice_3-1_numpy_key.html#practice-10.",
    "title": "Practice 3-1: Introduction to NumPy",
    "section": "üìö  Practice 10. ",
    "text": "üìö  Practice 10. \n\n\nRaise array b to the power of array c.\n\n\nCreate a new 5x10 array of random values. Subtract the mean of each row from every value.\n\n\n\n\nCode\n# a. \nb ** c\n\n# b. \n# Random 5x10 array\nrand50 = np.random.rand(5, 10)\n\n# Calculate mean of each row\nm = np.array([rand50.mean(axis=1)])\n# Subtract mean from each element\nl = rand50 - m.T\nprint(l)\n\n\n[[-0.41170877  0.15229157  0.34946892  0.2381375  -0.0113315   0.13161321\n  -0.1760515  -0.36044148 -0.12893971  0.21696174]\n [ 0.40968579  0.15228368  0.20724049 -0.33369976 -0.02910147 -0.4137152\n   0.06196756  0.17497702 -0.33630459  0.10666647]\n [-0.37876503  0.19540316  0.41508675 -0.39110682  0.25720744  0.11413381\n  -0.26093547 -0.22328425 -0.10556412  0.37782455]\n [ 0.21099536 -0.14109065  0.19566946  0.11854273 -0.44249867 -0.1864767\n   0.04331053 -0.16904161  0.06026488  0.31032467]\n [ 0.38219275  0.1848438   0.00265078  0.33216692 -0.39019945  0.02188796\n   0.01753881 -0.28219403 -0.24254002 -0.02634752]]"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#practice-1.",
    "href": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#practice-1.",
    "title": "Practice 2-2: Structured Data in Python",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nDictionaries are an extremely common data structure. Often data is easiest to store according to keys, where each row of data has a unique key.\nFor example, a dictionary of students might have a key for each student‚Äôs name or id, and then a set of values that are associated with that student.\n\nMake a dictionary of your peers.\nCome up with 3-4 questions and ask 5-6 of your peers to give answers to each one. The questions can be anything you want, but they should be questions that can be answered with a single word or number.\nFor example, you might ask: - What is your favorite color? (pretty weak question) - How many siblings do you have? (ok, but not great) - What is your favorite genre of film? (better) - On a scale of 1-10, how well do you feel that you understand python dictionaries? (better still)\nMake sure you have a key for each person, and then a set of values for each question.\nBased on each person‚Äôs responses, build a dictionary in the cell below:\n(note: You will end up with a dictionary of dictionaries)\n# Example:\nmy_dict = {\n    'person1': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n    'person2': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n    'person3': {\n        'question1': 'answer1',\n        'question2': 'answer2',\n        'question3': 'answer3',\n        'question4': 'answer4',\n    },\n}"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#dictionary-to-dataframe",
    "href": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#dictionary-to-dataframe",
    "title": "Practice 2-2: Structured Data in Python",
    "section": "Dictionary to dataframe",
    "text": "Dictionary to dataframe\nNow that you have a dictionary, you can convert it to a dataframe.\n\nConvert your dictionary to a dataframe\nUse the pd.DataFrame() function to convert your dictionary to a dataframe.\nimport pandas as pd\n\n# Convert a dictionary to a dataframe\ndf = pd.DataFrame(my_dict)\n\n\nInvestigate your dataframe using the following functions:\n\ndf.head()\ndf.tail()\ndf.info()\n\nIs your dataframe what you expected? If not, what is different? Why?? How would you need to change your data structure to get the dataframe you expected?\ndf.transpose() might be helpful here. What does it do? create a new dataframe that is a transposed version of your original dataframe.\n# Transpose a dataframe\ndf_transposed = df.transpose()\n\n\nCode\n# Transpose your dataframe so that the people are the rows and the questions are the columns.\n\n\n\n\n\nVisualize/summarize your dataframe using one or more of the following functions:\n\ndf.describe()\ndf.plot()\ndf.hist()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#practice-2.",
    "href": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#practice-2.",
    "title": "Practice 2-2: Structured Data in Python",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \n\nStructured data search: Find structured data on the internet and convert it to a dataframe.\nYou‚Äôre looking for data that is in a table format, like a spreadsheet, but not available as an easy to download .csv or .excel file. This turns out to describe a lot of data!\nOften you can find this kind of data on wikipedia, or on government websites, or in research articles that contain tables of results.\n\n\nConvert your data to a dataframe"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#explore-your-dataframe-using-the-following-functions",
    "href": "practice_sessions/answerkeys/practice_2-2_structured_data_key.html#explore-your-dataframe-using-the-following-functions",
    "title": "Practice 2-2: Structured Data in Python",
    "section": "Explore your dataframe using the following functions:",
    "text": "Explore your dataframe using the following functions:\n\ndf.describe()\ndf.plot()\ndf.hist()"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html",
    "href": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html",
    "title": "Exercise 1.5: Functions & Classes",
    "section": "",
    "text": "In order to effecitvely use Python, we need to learn how to use functions and classes. Functions are a fundamental part of almost any programming language, and Python is no different. We have already been introduced to many of the excellent builtin functions that are part of the standard Python library. However, as you develop your own analyses, you will need to be able to author your own functions. These functions will allow you to create stand-alone pieces of code that perform consistent operations on input data. Classes are even more versatile than functions. They are present in almost all object-oriented programming languages and provide a means to bundle functions and data together. Defining a new class creates a new type of object (recall that objects are the fundamental building block of Python), allowing new instances of that object type to be made."
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#functions",
    "href": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#functions",
    "title": "Exercise 1.5: Functions & Classes",
    "section": "Functions",
    "text": "Functions\nA function is simply a set of instructions that you wish to use repeatedly on varying data. Sometimes a function is used to group a complex set of instructions that allows you to compartmentalize your code in ways that improve its readability. There are three types of functions in Python: builtin functions, user-defined functions, and anonymous functions. We have already seen many builtin functions, and you will meet many more in the coming weeks. This exercise focuses on user-defined and anonymous functions, both of which are important for advanced data analysis.\n\nUser-defined Functions (UDFs)\nA UDF is created using some very specific syntax. First, a function is delcared using the def keyword. The name of the function - and any arguments it takes - follows the def keyword, followed by a :. The combination of def and : is a similar construction to other control statements in Python that you‚Äôve already seen, such as for + :, and if + :. The code block below is the simplest possible function.\ndef my_function():\n    pass\nThe pass keyword means ‚Äúdo nothing‚Äù. Therefore, we have defined a function that: (1) does not take any arguments; (2) does nothing, and then (3) returns nothing.\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Technically, a function that lacks a &lt;code&gt;return&lt;/code&gt; statement will still return a value. But the value it returns is &lt;a href=\"https://docs.python.org/3/c-api/none.html\"&gt;&lt;code&gt;None&lt;/code&gt;&lt;/a&gt;, which is python-ese for nothing. Just like the concept of &lt;a href=https://www.amazon.com/Zero-Biography-Dangerous-Charles-Seife/dp/0140296476&gt;`0`&lt;/a&gt;, the concept of &lt;code&gt;None&lt;/code&gt; will turn out to be quite useful!\n\nThe next function below still does not take any arguments and it still doesn‚Äôt do anything. It does, however, include a return statement. As the note above indicates, the return statement isn‚Äôt necessary in Python functions; they will just automatically return None if you don‚Äôt specify otherwise. However, using the return statement is required if you ever want to work with any output from your functions.\ndef my_function():\n    return True\nNext, we can take a look at an example of a function that takes an argument (a) and returns a value (also a)‚Ä¶ but it still doesn‚Äôt actually do anything!\ndef my_function(a):\n    return a\nHopefully your functions will be more useful than the ones above that do nothing. However, we‚Äôve introduced these three ‚Äúdo-nothing functions‚Äù in order to highlight three important aspects of all functions. The ability to (1) pass an argument into a function, (2) transform data within - or based on - the value of a function argument, and (3) return some new data or result based on those manipulations. These three factors combine to make functions extremely useful. Finally the code below provides an example of a function that has all three components and does something that should be quite familiar to you at this point.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Define a simple function\ndef convert_F_to_C(temp_F):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\n\nThe function above takes a Temperature in Fahrenheit and converts it to Celsius. It then returns this new value.\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nCall the &lt;code&gt;convert_F_to_C()&lt;/code&gt; function with the value 98.6 (¬∞F). It should return 37.0.\n\n\n\nCode\n# Convert 98.6¬∞F to ¬∞C\nconvert_F_to_C(98.6)\n\n\n\n\nFunction Arguments & Parameters\nWhen we define a function, we specify the parameters the function requires. The definition of convert_F_to_C contains a single parameter, temp_F. When we call a function, we supply arguments to the function which are then mapped to the function parameters. Providing the argument 98.6 to the function maps this number to the temp_F parameter. So wherever temp_F appears in the function, 98.6 is used instead. What happens if we call a function without supplying arguments for the parameters?\n\nconvert_F_to_C() # Uh-oh... we didn't provide an argument for the temp_F parameter.\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-3-60e83d2545ed&gt; in &lt;module&gt;\n----&gt; 1 convert_F_to_C()\n\nTypeError: convert_F_to_C() missing 1 required positional argument: 'temp_F'\nIn the error above, we see that not providing a required argument raises a TypeError, and provides some additional detail regarding what went wrong. In this case, we are told that we are mssing one required positional argument, which needs to be assigned to the temp_F parameter.\n\nSpecifying default parameters\nWhen defining a function, it is possible to set a default value for any parameter. This is done by assigning the parameter the default value right inside the parameter list:\ndef convert_F_to_C(temp_F=0):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Functions are no different than variables (or any other object in Python). Therefore, any function you create in a notebook can be re-defined by simply editing the function and re-running the cell! \n\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nRe-define the &lt;code&gt;convert_F_to_C()&lt;/code&gt; function so that the default value of &lt;code&gt;temp_F&lt;/code&gt; is 0. Test what happens if you call this re-defined function without an argument. \n\n\n\nCode\n# Redefine convert_F_to_C() with default temp_F=0\ndef convert_F_to_C(temp_F=0):\n    temp_C = (temp_F-32)*5./9.\n    return temp_C\n\n# Call function\nconvert_F_to_C()\n\n\n\n\nRequired arguments\nArguments that are included in the parameter list and do not have default values are called required arguments. In the convert_temp_to_C function below, both temp and unit are required parameters.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\ndef convert_temp_to_C(temp, unit):\n    \"\"\" Converts a temperature to Celsius\n    \n    Parameters\n    ----------\n        temp : float\n            Temperature value to convert\n        unit : str\n            temp units ('K' or 'F')\n       \n    Returns\n    -------\n        temp_C : float\n            The value of temp converted to Celsius\n    \"\"\"\n    if unit == 'K':\n        temp_C = temp - 273.15\n    elif unit == 'F':\n        temp_C = (temp-32)*5./9.\n    return temp_C\n\n\nYou can also see that we have added some comments to the function right below the definition. These commments are known as Docstrings, and they are critical to allow users to understand what your program is doing. The use of \"\"\" to begin and end the docstrings signifies we are writing a multi-line comment (as opposed to # which specifys a single line comment in Python). The first line of a function‚Äôs docstrings should always be a short description of what the function does. The rest of the docstrings should specify the required arguments that the function needs and what values it returns, if any.\n\nüêç &lt;b&gt;The ABC of Python:&lt;/b&gt; Always. Be. Commenting.\n\n\nüêç &lt;b&gt;Note.&lt;/b&gt; You can see the function definition and &lt;b&gt;docstrings&lt;/b&gt; for any function (if they exist) by using the builtin &lt;code&gt;help()&lt;/code&gt; function.\n\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nUse the &lt;code&gt;help()&lt;/code&gt; function to see the function definition and docstrings for the &lt;code&gt;convert_temp_to_C&lt;/code&gt; function.\n\n\n\nCode\nhelp(convert_temp_to_C)\n\n\n\nüìö  &lt;b&gt; Practice 1. &lt;/b&gt; \nCreate a new function, &lt;code&gt;convert_temp_to_K&lt;/code&gt; that converts a temperature to Kelvin from either Fahrenheit or Celsius, depending on user-supplied arguments. \n\n\n\nCode\n# Define a new function\ndef convert_temp_to_K(temp, unit):\n    \"\"\" Converts a temperature to Celsius\n    \n    Parameters\n    ----------\n        temp : float\n            Temperature value to convert\n        unit : str\n            temp units ('C' or 'F')\n       \n    Returns\n    -------\n        temp_K : float\n            The value of temp converted to Celsius\n    \"\"\"\n    if unit == 'C':\n        temp_K = temp + 273.15\n    elif unit == 'F':\n        temp_K = ((temp-32)*5./9.) + 273.15\n    return temp_K\n\n\n\n\nKeyword arguments\nIn both convert_temp_to_C and convert_temp_to_K, the order of parameters is very important. If we tried calling the convert_temp_to_C function like this: convert_temp_to_C('F', 212.0) we would get an error! The reason we get an error is because the function definition assumes that the first argument should be mapped to the first parameter temp and the second argument should be mapped to the second parameter unit. That‚Äôs why the TypeError refered to temp_Fas a required positional argument in the section above. This assumption that arguments be mapped to parameters in a specific order can make working with complicated functions that have many parameters almost impossible. For this reason, Python provides the ability to pass keyword arguments to functions.\nRather than making assumptions about how arguments map to parameters based on their order, keyword arguments specify exactly how arguments are mapped to parameters within a function. This is done by assigning an argument to a specific parameter within the function call.\nFor example, instead of writing convert_temp_to_C('F', 212.0), we can instead call the same function using convert_temp_to_C(unit='F', temp=212.0).\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Python doesn't require you to change anything about a function's definition to take advantage of keyword arguments. For this reason, it's good practice to use keyword arguments whenever possible.\n\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt; \nCall the &lt;code&gt;convert_temp_to_K&lt;/code&gt; function that you created using keyword arguments.\n\n\n\nCode\nconvert_temp_to_K(unit='F',temp=98.6)\n\n\nAn important consideration when using keyword arguments is that they must all follow any positional arguments that are passed to a function. In other words, if you are calling a function with a mix of positional arguments and keyword arguments, the positional arguments need to all be listed first. So, using our simple temperature conversion function as an example, convert_temp_to_C(212.0, unit='F') is valid, but convert_temp_to_C(temp=212.0, 'F') is not.\n\n\nAnonymous functions\nSometimes we may just want to create a very simple function without having to go through all the trouble of using def to define the function, writing docstrings and adding a return statement. For these ‚Äúone-liners‚Äù Python has the concept of anonymous functions. Instead of using def, these functions are declared using lambda notation, so they are often refered to as lambda functions. Because they are meant to be simple, a lambda function declaration is always contained in a single line:\nQ = lambda T: 5.67e-8 * T**4\nThe function above calculates the Energy Flux, Q [W/m^2], for a blackbody object at a specified temperature, T [Kelvin], assuming an emissivity of 1:\nQ = 5.67x10^{-8} \\times T^4\nWe can use this lambda function just like any other function:\nQ(50+273.15)\n&gt;&gt;&gt; 618.3006455416394\n\nüìö  &lt;b&gt; Practice 2. &lt;/b&gt; \nCreate a &lt;code&gt;lambda&lt;/code&gt; function in the cell below that converts a Celsius temperature to Kelvin.&lt;/div&gt;\n\n\n\nCode\n# Create function to convert C to K\ntemp_K = lambda temp_C: temp_C + 273.15\n# Test function\ntemp_K(40)\n\n\n\n\n\nDocumenting Functions\nAs we saw above, the use of docstrings can greatly improve your ability to understand what a program requires in terms of arguments and what the function returns. There is no standard for docstrings, but there are some best practices. A good docstring should contain:\n\nA brief description of what the function does.\nA more detailed explanation of how the functions works, if necessary.\nInformation on any arguments - both required and optional - that may be passed into the function.\nInformation on any parameter default values.\nInformation on any exceptions that the function raises.\nAny information about side effects the function may cause, or restrictions on when the function can be used.\n\nThe last couple of items on the list above aren‚Äôt very common, but the first four are essential components of all function docstrings. While it is fine to develop your own docstring style, here‚Äôs another example of what a docstring should look like:\ndef Q(T, epsilon=1, unit='C'):\n    \"\"\" Calculates energy emitted by an object with temperature T\n\n    Uses the Stefan-Bolzmann Law to calculate total radiative \n    emmittance in W/m^2 based on temperature and emissivity:\n    \n    Q = epsilon * sigma * T**4\n    \n    where sigma is the Stefan-Boltzmann constant (5.67e-8 W/m^2/K^4),\n    epsilon is the emissitivity (0-1), and T is temperature in Kelvin.\n\n    Parameters\n    ----------\n        T: float\n            Temperature of object\n        epsilon: float, optional\n            emissivity of object [0-1] (default is 1)\n        unit: str, optional\n            units of T, either 'F', 'C', or 'K' (default is 'C')\n    \n    Returns\n    -------\n        Q: float\n            Energy emitted by object [W/m^2]\n    \"\"\"\n\n    # Set Stefan-Boltzmann constant:\n    SIGMA = 5.67e-8 # W/m2/K^4                    \n                \n    # If T is in Fahrenheit, convert to C:\n    if unit == 'F':\n        T = (T - 32) * (5./9.)\n        unit = 'C' # Re-assign unit to C\n        \n    # If T is in Celsius, convert to Kelvin\n    if unit == 'C':\n        T = T + 273.15\n    \n    # Calculate Q and return the value\n    Q = epsilon * SIGMA * T**4\n    return Q\n\nüìö  &lt;b&gt; Practice 3. &lt;/b&gt; \nWrite a complete set of docstrings for your function a &lt;code&gt;convert_temp_to_K&lt;/code&gt;. Check to make sure they work using the &lt;code&gt;help()&lt;/code&gt; function.&lt;/div&gt;\n\n\n\nCode\n# Define function with docstrings\ndef convert_temp_to_K(temp, unit):\n    \"\"\" Converts a temperature to Celsius\n    \n    Parameters\n    ----------\n        temp : float\n            Temperature value to convert\n        unit : str\n            temp units ('C' or 'F')\n       \n    Returns\n    -------\n        temp_K : float\n            The value of temp converted to Celsius\n    \"\"\"\n    # If unit is in Celsius, conveert to K\n    if unit == 'C':\n        temp_K = temp + 273.15\n    # If unit is in Fahrenheit, convert to K\n    elif unit == 'F':\n        temp_K = ((temp-32)*5./9.) + 273.15\n    # Return temp in Kelvin\n    return temp_K\n\n# Check out docstring\nhelp(convert_temp_to_K)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#classes",
    "href": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#classes",
    "title": "Exercise 1.5: Functions & Classes",
    "section": "Classes",
    "text": "Classes\nClasses are Python objects that contain both attributes (i.e.¬†data) and methods (i.e.¬†functions). Classes are the essence of any object-oriented programming (OOP) language. A Class is created using the class keyword:\n\nclass Temperature:\n    value = 74.0\n    unit = 'F'\n    \nThe above code defines a new class called Temperature. It then assigns two attributes to the class, value and unit. This simple class has no methods. We will get to those next!\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nclass Temperature:\n    value = 74.0\n    unit = 'F'\n\n\n\nCreating an Instance of a Class\nWe create an instance of the class by calling it (like we call a function) and assigning the output of the call to a new variable:\nmy_temp = Temperature()\n\n\nAccessing Class Data\nClass objects are mutable, so it‚Äôs possible to change the data in a class. We can access ‚Äì and alter ‚Äì the attributes of a class using . notation:\nprint(my_temp.value) # Use . notation to access attributes of a class.\n&gt;&gt;&gt; 74.0\n\nmy_temp.value = 83.2  # Assign a new value to this instance of Temperature.\nprint(my_temp.value)  # Check to see if the value has been changed...\n&gt;&gt;&gt; 83.2\n\nüìö  &lt;b&gt; Practice 4. &lt;/b&gt; \nCreate an instance of the &lt;code&gt;Temperature&lt;/code&gt; class and print out the string: &lt;code&gt;\"The temperature is 74 ¬∞F\"&lt;/code&gt;.\n\n\n\nCode\n# Create instance of Temperature\nmy_temp = Temperature()\n\n# Print temperature as formatted print statement.\nprint('The temperature is %d ¬∞%s.' % (int(my_temp.value),my_temp.unit))\n\n\n\n\nClass Initialization\nIn the example above, we saw how to create an instance of a Temperature. But you probably noticed that every instance of our class will have the same temperature and unit: 74.0 degress F. While it‚Äôs possible to change these values later (in python parlance, we‚Äôd say ‚Äúafter the object is instanced‚Äù), it‚Äôd be better if we could initialize our class instances with the values we want. To do this, we will create our first class method, the __init__ method.\n\n\n__init__() method\nThe __init__() method is a special function that we create for classes that tells python how to create a new instance of the class. This function is included as part of a class‚Äôs definition, and usually should be the very first method that appears in the class.\n\nüêç &lt;b&gt;Note.&lt;/b&gt; Python uses the \"double underscore + name + double underscore\" syntax (&lt;code&gt;__&lt;/code&gt; + &lt;code&gt;init&lt;/code&gt; + &lt;code&gt;__&lt;/code&gt;) to define a suite of \"magic\" functions. The exact way to pronounce these strange functions isn't settled, but most people use \"dunder\" to refer to the double underscore, so &lt;code&gt;__init__()&lt;/code&gt; is referred to as the \"dunder init dunder\" function, or \"dunder init\" for short.\n\nThe __init__() function is the initializer method for a Class. It gets passed whatever arguments are provided when a class is created. For example, if we called T = Temperature(10, 'F'), the __init__() method would automatically be passed these two arguments.\nWe define the __init__ method just like any other function, with one difference: It always includes self as its first argument:\n\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n\nWhy self?\nIt‚Äôs not at all obvious why we need to add an extra parameter (which, by convention is always called self ) to the initializer method. Even weirder is the fact that we need to add this extra parameter, self to every class method! To beginning Pythonistas, the concept of self is deeply strange. However, there is a fairly straight-foward reason for its existence.\nPython functions ‚Äì like functions in most programming languages ‚Äì can only manipulate data that exist within the function itself. Speaking generally, Python functions aren‚Äôt supposed to manipulate data that they haven‚Äôt been passed via argument. The consequences of this ‚Äúseparation of namespaces‚Äù is that ‚Äì paradoxically ‚Äì a class method can‚Äôt operate on class data unless the class data itself is passed into the method!\nBy convention, we use the self parameter to allow us to work with the properties of a class within our class methods. If we didn‚Äôt include this extra parameter, the functions that we write inside of a class wouldn‚Äôt even be able to access the attributes of the class that they were inside of!\nEssentially, you can think of self as a placeholder for a class instance. In fact, Python automatically passes a class instance into any class function whenever that class function is called. The class instance argument is inserted by Python before any other arguments. Therefore, we include the self parameter at the beginning of every class method (remember methods and functions are the same thing), knowing that Python will pass a class instance into our function first, and all of the attributes of that instance will get assigned to the self parameter.\nThere are many, many other explanations out there about the need for the self parameter in class methods. Because the use of self in Python is such a confusing concept, there have also been formal proposals to get rid of self and warnings about its misuse in popular culture. There is even a blog post about the necessity self from the creator of self‚Ä¶ himself.\n\nüêç &lt;b&gt;Bottom Line.&lt;/b&gt; Whenever you write a class function, you will need to include &lt;code&gt;self&lt;/code&gt; as the first positional parameter in the function definition. In addition, whenever you want to access class attributes within a class method, you will need to use &lt;code&gt;self&lt;/code&gt; as the object that contains the data.\n\n\nUsing the __init__() function\nWe almost never call the __init__() function directly. Instead, the Class constructor function calls it for us. We already saw that a class instance is created using the constructor function like my_temp = Temperature(). With our new __init__() function defined for the Temperature class, we can now create Temperature instances with any data we want:\nT = Temperature(83.2, 'F')\nprint(T.value)\n&gt;&gt;&gt; 83.2\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;  \nCopy the example code above to create an new &lt;code&gt;Temperature&lt;/code&gt; class that contains an &lt;code&gt;__init__&lt;/code&gt; method that sets the value and units. Create a few new &lt;code&gt;Temperature&lt;/code&gt; instances with different values and units.\n\n\n\nCode\n# Create Temperature class with __init__ method\nclass Temperature:\n\n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n# Temperature instances\ntemp1 = Temperature(40.3, 'C')\ntemp2 = Temperature(-14.8, 'F')\n\n\n\n\n\nUser Defined Class Methods\nWe often want to create our own methods that allow us to manipulate and work with class data. For example, now that we have a Temperature class, we might want to create a method that allows us to get the value of temperature in any unit. We can add this functionality by defining a class method. The class method is just the same as every other Python function, except, like __init__(), it has self as its first argument:\n\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n        self.temp_K = self.get_K()\n\n    def get_K(self):\n        \n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n            unit = 'C' # Re-assign unit to C\n        \n        # If T is in Celsius, convert to Kelvin\n        if unit == 'C':\n            T = T + 273.15\n\n        return T\n    \nIn this example, we‚Äôve added a class function called get_K that always returns the Temperature object‚Äôs value in degrees Kelvin. You will notice that we can even use this function inside the __init__() function. This means that after creating an instance of an object, we will end up with the temp_K property of the object set for us automatically.\nWe can also run any class methods by calling it directly. Just as we used . notation to access class data, we use . notation to access class methods:\n\nmy_temp = Temperature(50,'C')\nmy_temp.get_K()\n&gt;&gt;&gt; 323.15\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;  \nCopy the example code above to create an new &lt;code&gt;Temperature&lt;/code&gt; class that contains the &lt;code&gt;get_K&lt;/code&gt; method, which is used to set the value of &lt;code&gt;temp_K&lt;/code&gt; during intialization. Create a few new &lt;code&gt;Temperature&lt;/code&gt; instances with different values and units and test to make sure &lt;code&gt;temp_K&lt;/code&gt; is being set correctly. \n\n\n\nCode\n# Create Temperature class with get_K method\nclass Temperature:\n\n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n        self.temp_K = self.get_K()\n\n    def get_K(self):\n\n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n            unit = 'C' # Re-assign unit to C\n\n        # If T is in Celsius, convert to Kelvin\n        if unit == 'C':\n            T = T + 273.15\n\n        return T\n    \n    \n# A few instances\ntemp1 = Temperature(40.3, 'C')\ntemp2 = Temperature(-14.8, 'F')\n\nprint('The temperature is %.1f¬∞%s or %.2f K.' % (temp1.value,temp1.unit,temp1.get_K()))\nprint('The temperature is %.1f¬∞%s or %.2f K.' % (temp2.value,temp2.unit,temp2.get_K()))\n\n\n\nüìö  &lt;b&gt; Practice 4. &lt;/b&gt; \nUse the cell below to create a new &lt;code&gt;Temperature&lt;/code&gt; class that contains a user-defined class function of your own design. This function can do anything you want. It doesn't need to be fancy or even useful, just make sure you test your function by creating an instance of &lt;code&gt;Temperature&lt;/code&gt; class and running the function.\n\n\n\nCode\n# Create Temperature class with get_K method\nclass Temperature:\n\n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n        self.temp_K = self.get_K()\n\n    def get_K(self):\n\n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n            unit = 'C' # Re-assign unit to C\n\n        # If T is in Celsius, convert to Kelvin\n        if unit == 'C':\n            T = T + 273.15\n\n        return T\n\n    def get_C(self):\n\n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n        # If T is in Celsius, do nothing\n        if unit == 'C':\n            T = T\n\n        return T\n\n    def get_F(self):\n\n        unit = self.unit\n        T = self.value\n\n        # If T is in Celsius, convert to F:\n        if unit == 'C':\n            T = (T * (9./5.)) + 32\n\n        # If T is in Fahrenheit, do nothing\n        if unit == 'F':\n            T = T\n\n        return T\n    \n    \n    \n# A few instances\ntemp1 = Temperature(40.3, 'C')\ntemp2 = Temperature(-14.8, 'F')\n\n# Print temperature in all units\nprint('The temperature is %.2f¬∞%s (%.2f¬∞F or %.2f K).' % (temp1.value,temp1.unit,temp1.get_F(),temp1.get_K()))\nprint('The temperature is %.2f¬∞%s (%.2f¬∞C or %.2f K).' % (temp2.value,temp2.unit,temp2.get_C(),temp2.get_K()))\n\n\n\n\nTwo additional - and very useful - Class ‚ÄúMagic‚Äù Methods\nIn addition to the __init__() function, there are some other useful ‚Äúmagic‚Äù class methods. The first, __repr__ is a function that allows you to define how a Class object represents itself. For example, check out this example for a string (str) variable:\n\nSIGMA = 5.67e-8 # Create a variable that contains the Stefan-Boltzmann constant\nSIGMA               # What happens if you just execute a line that contains the variable? \n&gt;&gt;&gt; 5.67e-08\nYou see that when the variable SIGMA is invoked, the Python interpreter returns 5.67e-08, which is not exactly what you wrote when you assigned SIGMA. That‚Äôs because what is happening ‚Äúbehind the scenes‚Äù is that Python is calling the __repr__() function for the object SIGMA:\nSIGMA.__repr__()\n&gt;&gt;&gt; 5.67e-08\nThere is a similar magic function, __str__() that is called whenever print() is invoked on an object:\nprint(SIGMA)\n&gt;&gt;&gt; 5.67e-08\n\nSIGMA.__str__()\n&gt;&gt;&gt; 5.67e-08\nIn the case of float variables (type(SIGMA) is float), __repr__() and __str__() return the same thing. But they don‚Äôt have to. Look at this example, using a datetime object, which is part of the standard Python library and the primary object for dealing with time/date information in Python:\nfrom datetime import datetime\n\ncurrent_time = datetime.now()\n\ncurrent_time\n&gt;&gt;&gt; datetime.datetime(2020, 4, 17, 12, 50, 52, 778357) # Your time will be different!\n\nprint(current_time)\n&gt;&gt;&gt; 2020-04-17 12:51:38.750213\nWe see that the representation of a datetime object (created by the class‚Äôs __repr__() function) is different than the class‚Äôs __str__() function.\nYou can create these functions inside a class in the same way you created the __init__() function:\nclass Temperature:\n    \n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n    def __repr__(self):\n        return \"Temperature({value},¬∞{unit})\".format(value=self.value,unit=self.unit)\n\n    def __str__(self):\n        return \"The temperature is {value} ¬∞{unit}\".format(value=self.value, unit=self.unit)\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;  \nUse the example above to define a new &lt;code&gt;Temperature&lt;/code&gt; class that adds &lt;code&gt;__repr__&lt;/code&gt; and &lt;code&gt;__str__&lt;/code&gt; methods. Test out the &lt;code&gt;__str__()&lt;/code&gt; method by creating an instance and using the &lt;code&gt;print()&lt;/code&gt; command. \n\n\n\nCode\n# Define new Temperature class with __repr__ and __str__ methods\nclass Temperature:\n\n    def __init__(self, value=74.0, unit='F'):\n        self.value = value\n        self.unit = unit\n\n    def __repr__(self):\n        return \"Temperature({value},¬∞{unit})\".format(value=self.value,unit=self.unit)\n\n    def __str__(self):\n        return \"The temperature is {value} ¬∞{unit}\".format(value=self.value, unit=self.unit)\n\n# Create an instance\ntemp1 = Temperature(40.3, 'C')\n    \n# Test __sstr__() method\nprint(temp1)\n\n\n\n\nDocumenting Classes\nJust like functions, classes should contain docstrings. The format and content of docstrings is similar to a function, but there is a need for even more description. This is because the docstrings should include information about all of the attributes of the class as well as any class methods that are defined. So for a simple Weather class we might have something like this:\nclass Weather:\n    \"\"\"\n    A class used to represent the weather\n\n    Attributes\n    ----------\n    \n    temperature : float\n        air temperature, in deg-C\n        \n    relative_humidity : float\n        relative humidity, in %\n    \n    pressure : float\n        air pressure, in kPa\n    \n    Methods\n    -------\n    \n    sat_vap_pressure()\n        returns the saturation vapor pressure for the current weather condition\n        \n    \"\"\"\n    \n    def __init__(self, temp, RH, P):\n        \"\"\" \n        Parameters\n        ----------\n        temp : float\n            air temperature, in ¬∞C\n        \n        RH : float\n            relative humidity, in %\n        \n        P : float\n            pressure, in kPa\n        \"\"\"\n        \n        self.temperature = temp\n        self.relative_humidity = RH\n        self.pressure = P \n        \n    def sat_vap_pressure(self):\n        \"\"\" Determines Saturation Vapor Pressure\n        \n        Uses the Tetens equation to estimate saturation vapor pressure (svp) given air Temp.\n        \n        P = 0.61078 * exp((17.27 * T)/(T + 237.3))\n        \n        where P is svp in kPa and T is air temperature in ¬∞C.\n        \n        \n        Returns:\n        --------\n        \n        P, saturation vapor pressure, in kPa\n        \n        \"\"\"\n        from math import exp\n        \n        P = 0.61078 * exp(17.27*self.C)/(self.T + 237.3)\n        \n        return P\n\nüêç &lt;b&gt;ABC!&lt;/b&gt; Notice how there are more docstrings in this definition than there is code! This is because the concept of abstraction ‚Äì creating classes and functions that represent general concepts and methods ‚Äì requires a high degree of documentation in order for the abstractions to be used correctly. The same code written in a notebook cell (without abstraction) would be easier to read and require much less documentation.\n\n\nüìö  &lt;b&gt; Practice 5. &lt;/b&gt; \nUse the cell below to create a final version of your &lt;code&gt;Temperature&lt;/code&gt; class that includes docstrings. Check to see if your docstrings are working using the &lt;code&gt;help()&lt;/code&gt; function.\n\n\n\nCode\n# Create Temperature class with get_K method\nclass Temperature:\n    \"\"\"\n    A class used to represent the temperature\n\n    Attributes\n    ----------\n\n    temperature : float\n        temperature, in ¬∞F or ¬∞C\n\n    unit : str\n        units of temperature\n\n    Methods\n    -------\n\n    get_K()\n        returns temperature in K\n        \n    get_C()\n        returns temperature in ¬∞C\n    \n    get_F()\n        returns temperature in ¬∞F\n\n    \"\"\"\n    def __init__(self, value=74.0, unit='F'):\n        '''\n        PARAMETERS:\n        ----------\n        value : int or float\n            temperature (default is 74.0)\n        \n        unit : str\n            units of temperature (default is F)\n        '''\n        self.value = value\n        self.unit = unit\n        self.temp_K = self.get_K()\n\n    def get_K(self):\n        \"\"\" Converts temperature to K\n\n        Converts temperature to K using the equation\n        \n            T_K = T_C + 273.15\n        \n        where T_K is the temperature in K and T_C is the temperature in ¬∞C. If necessary, the temperature is\n        first converted from ¬∞F to ¬∞C according to the equation\n        \n            T_C = (T_F - 32) * (5./9.)\n\n        where T_F is the temperature in ¬∞F.\n\n        Returns:\n        --------\n\n        T : temperature in K\n\n        \"\"\"\n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n            unit = 'C' # Re-assign unit to C\n\n        # If T is in Celsius, convert to Kelvin\n        if unit == 'C':\n            T = T + 273.15\n\n        return T\n\n    def get_C(self):\n        \"\"\" Converts temperature to C\n\n        Converts temperature to C using the equation\n        \n            T_C = (T_F - 32) * (5./9.)\n        \n        where T_F is the temperature in Fahrenheit and T_C is the temperature in ¬∞C. \n\n        Returns:\n        --------\n\n        T : temperature in C\n\n        \"\"\"\n        unit = self.unit\n        T = self.value\n\n        # If T is in Fahrenheit, convert to C:\n        if unit == 'F':\n            T = (T - 32) * (5./9.)\n        # If T is in Celsius, do nothing\n        if unit == 'C':\n            T = T\n\n        return T\n\n    def get_F(self):\n        \"\"\" Converts temperature to F\n\n        Converts temperature to F using the equation\n        \n            T_F = (T_C * (9./5.)) + 32\n        \n        where T_F is the temperature in Fahrenheit and T_C is the temperature in ¬∞C. \n\n        Returns:\n        --------\n\n        T : temperature in F\n\n        \"\"\"\n        unit = self.unit\n        T = self.value\n\n        # If T is in Celsius, convert to F:\n        if unit == 'C':\n            T = (T * (9./5.)) + 32\n\n        # If T is in Fahrenheit, do nothing\n        if unit == 'F':\n            T = T\n\n        return T\n    \n    \n    \n# A few instances\ntemp1 = Temperature(40.3, 'C')\ntemp2 = Temperature(-14.8, 'F')\n\n\nhelp(temp1)"
  },
  {
    "objectID": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#loading-functions-and-classes",
    "href": "practice_sessions/answerkeys/practice_99_functions_objects_classes_key.html#loading-functions-and-classes",
    "title": "Exercise 1.5: Functions & Classes",
    "section": "Loading functions and classes",
    "text": "Loading functions and classes\nIn the last practice cell, you probably noticed that your class definition is getting pretty large. While it‚Äôs nice to be able to edit this code easily in your notebook, once you have settled on a function or class definition, it is often helpful to move the definitions out of your notebook and just load them when you need them. Python uses the import function to load objects from external libraries and files.\n\nMoving your class definition to a new file\n\nüìö  &lt;b&gt; Practice 6. &lt;/b&gt; \nFollow the directions below to save your final &lt;code&gt;Temperature&lt;/code&gt; class definition into a new file called &lt;code&gt;temperature.py&lt;/code&gt;\n\n\nGo to the JupyterLab File menu and click New -&gt; Text File\n\n\n\nCopy the entire Temperature class definition you created during Practice 5 and paste it into the text file.\nRename the text file temperature.py. You can do this easily by right-clicking on the filename in the file‚Äôs tab (see the image below)\n\n\n\nüêç &lt;b&gt;Note:&lt;/b&gt;Make sure you save your file with the &lt;code&gt;.py&lt;/code&gt; extension and not &lt;code&gt;.txt&lt;/code&gt;. You will know if you saved it correctly if the file appears with python code formating as in the image below:\n\n\n\nSave the new file. This will create a file called temperature.py in your current directory.\n\n\n\nImporting your class from the temperature.py file.\nAssuming you were able to save your file correctly, and that your Temperature class definition doesn‚Äôt have any errors in it, you can import the Temperature class into your notebook like this:\n\nfrom temperature import Temperature\n\nT = Temperature(98.6, unit='F')\n\n‚úèÔ∏è &lt;b&gt; Try it. &lt;/b&gt;  \nLoad your &lt;code&gt;Temperature&lt;/code&gt; class from the &lt;code&gt;temperature.py&lt;/code&gt; file using the &lt;code&gt;import&lt;/code&gt; command. Make some new Temperature instances to ensure that your class loaded correctly and works okay.\n\n\n\nCode\n# Import Temperature class\nfrom temperature import Temperature\n\n# A few instances\ntemp1 = Temperature(32.3, 'C')\ntemp2 = Temperature(104.8, 'F')\n\n# Print temperature in all units\nprint('The temperature is %.2f¬∞%s (%.2f¬∞F or %.2f K).' % (temp1.value,temp1.unit,temp1.get_F(),temp1.get_K()))\nprint('The temperature is %.2f¬∞%s (%.2f¬∞C or %.2f K).' % (temp2.value,temp2.unit,temp2.get_C(),temp2.get_K()))"
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#part-0.-setup-steps",
    "href": "practice_sessions/practice_4-1_pandas.html#part-0.-setup-steps",
    "title": "Practice 4-1: Pandas üêº",
    "section": "Part 0. Setup Steps",
    "text": "Part 0. Setup Steps\n\nCreate a repo on GitHub named eds217-practice-4-1-pandas\nClone to create a version-controlled project\nCreate some subfolder infrastructure (nbs, data, figs)\nCreate and save a new quarto in RStudio called jupyter notebook (.ipynb file) named practice_4-1_pandas.ipynb in the nbs folder.\nOpen the notebook in VSCode or jupyter notebook/lab\nMake sure to associate the notebook with the eds217_2023 environment.\nCreate a cell that imports your essential data science libraries."
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-1.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-1.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \n\nUse a list of lists to construct a DataFrame named df1 containing the data in the table below.\n\n\n\n\n\nRiver\nLength (\\text{km})\nDrainage area (\\text{km}^2)\n\n\n\n\nAmazon\n6400\n7,050,000\n\n\nCongo\n4371\n4,014,500\n\n\nYangtze\n6418\n1,808,500\n\n\nMississippi\n3730\n3,202,230\n\n\n\n\nUse a dict to construct a DataFrame named df2 containing the data in the table below.\n\n\n\n\n\nRiver\nLength (\\text{km})\nDrainage area (\\text{km}^2)\n\n\n\n\nZambezi\n2574\n1,331,000\n\n\nMekong\n4023\n811,000\n\n\nMurray\n2508\n1,061,469\n\n\nRh√¥ne\n813\n98,000\n\n\nCubango\n1056\n530,000"
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#import-the-data-for-our-practice-session",
    "href": "practice_sessions/practice_4-1_pandas.html#import-the-data-for-our-practice-session",
    "title": "Practice 4-1: Pandas üêº",
    "section": "Import the data for our practice session",
    "text": "Import the data for our practice session\nUse panda‚Äôs read_csv() function to import the data from github and create a new DataFrame named bsrn\ndata_url = \"https://raw.githubusercontent.com/environmental-data-science\" \\\n            \"/eds217_2023/main/data/BSRN_GOB_2019-10.csv\""
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-2.-using-the-dataframe-bsrn",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-2.-using-the-dataframe-bsrn",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö Practice 2. Using the DataFrame bsrn:",
    "text": "üìö Practice 2. Using the DataFrame bsrn:\n\n\nPrint a list of your DataFrame‚Äôs column names.\n\n\nHow many values are there in the entire DataFrame?\n\n\nWhat is the data type of the first column?"
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-3.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-3.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö Practice 3.",
    "text": "üìö Practice 3.\n\nCreate a new DataFrame containing the first record for each day and the following columns: the timestamp of the record, incoming shortwave radiation, direct and diffuse radiation, and incoming longwave radiation. (Hint: the BSRN station collects data every minute).\nCreate a new Series containing the temperature values every hour at the top of the hour.\nConvert the DATE column to datetime using the pd.to_datetime() function.\nSet the DATE column as the index of the DataFrame using the set_index() method."
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-4.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-4.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 4.",
    "text": "üìö  Practice 4.\n Calculate the mean incoming shortwave, outgoing shortwave, incoming longwave, and outgoing longwave radiation over the entire month."
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-5.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-5.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \n\n\nAdd a column ‚ÄòNET_SW‚Äô to bsrn with the net shortwave radiation.\n\n\nAdd a column ‚ÄòNET_LW‚Äô to bsrn with the net longwave radiation.\n\n\nAdd a column ‚ÄòNET_RAD‚Äô to bsrn with the net total radiation.\nNet radiation is given by the following equation:\n\nR^{}_{N} \\, = \\,  R^{\\, \\downarrow}_{SW} \\, - \\,  R^{\\, \\uparrow}_{SW} \\, + \\, R^{\\, \\downarrow}_{LW} \\, - \\,  R^{\\, \\uparrow}_{LW}\nwhere R^{\\, \\downarrow}_{SW} and R^{\\, \\uparrow}_{SW} are incoming and outgoing shortwave radiation, respectively, and R^{\\, \\downarrow}_{LW} and R^{\\, \\uparrow}_{LW} are incoming and outgoing longwave radiation, respectively.\n\nCreate a new DataFrame with the day of the month and daily mean values of shortwave incoming, shortwave outgoing, longwave incoming, longwave outgoing radiation, and net total radiation. (Hint: use masking!)."
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-6.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-6.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \n\n\nConcatenate df1 and df2 into a new DataFrame with all 9 rivers.\n\n\nCreate a new DataFrame rivers with the discharge, mouth, source, and continent information and add this to your DataFrame from (a) to produce a DataFrame with all of the data in the table below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiver\nLength (\\text{km})\nDrainage area (\\text{km}^2)\nDischarge (\\text{m}^2/\\text{s})\nMouth\nSource\nContinent\n\n\n\n\nAmazon\n6400\n7,050,000\n209,000\nAtlantic Ocean\nRio Mantaro\nSouth America\n\n\nCongo\n4371\n4,014,500\n41,200\nAtlantic Ocean\nLualaba River\nAfrica\n\n\nYangtze\n6418\n1,808,500\n30,166\nEast China Sea\nJianggendiru Glacier\nAsia\n\n\nMississippi\n3730\n3,202,230\n16,792\nGulf of Mexico\nLake Itasca\nNorth America\n\n\nZambezi\n2574\n1,331,000\n3,400\nIndian Ocean\nMiombo Woodlands\nAfrica\n\n\nMekong\n4023\n811,000\n16,000\nSouth China Sea\nLasagongma Spring\nAsia\n\n\nMurray\n2508\n1,061,469\n767\nSouthern Ocean\nAustralian Alps\nOceania\n\n\nRh√¥ne\n813\n98,000\n1,710\nMediterranean Sea\nRh√¥ne Glacier\nEurope\n\n\nCubango\n1056\n530,000\n475\nOkavango Delta\nBi√© Plateau\nAfrica"
  },
  {
    "objectID": "practice_sessions/practice_4-1_pandas.html#practice-7.",
    "href": "practice_sessions/practice_4-1_pandas.html#practice-7.",
    "title": "Practice 4-1: Pandas üêº",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \n\nExport your rivers DataFrame to a CSV file in your repository‚Äôs data folder.\nExport your bsrn DataFrame to a CSV file in your repository‚Äôs data folder."
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html",
    "href": "practice_sessions/practice_1-2_lists.html",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | ‚û°Ô∏è Next Session |"
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html#practice-1.",
    "href": "practice_sessions/practice_1-2_lists.html#practice-1.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \nDefine a new list of floats with 8 elements called my_list.\n\nFind the 5th element in your list.\nCreate a new list containing every other value in your original list.\nUsing slicing and two different methods of indexing, remove the first and last values in your list."
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html#practice-2.",
    "href": "practice_sessions/practice_1-2_lists.html#practice-2.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 2. ",
    "text": "üìö  Practice 2. \nCreate the variable str_list and assign it to the list [‚Äòenergy‚Äô, ‚Äòwater‚Äô, ‚Äòcarbon‚Äô]. Use indexing to extract the second letter of the third element (‚Äòa‚Äô) in str_list.\nstr_list = ['energy', 'water', 'carbon']"
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html#practice-3.",
    "href": "practice_sessions/practice_1-2_lists.html#practice-3.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \nCreate a copy of my_list, which you assigned above.\n\nUsing indexing or list operators, remove the first and last elements of your copied list.\nSort both the original list and the copied list in reverse order.\nUse the len() function and a boolean operator to determine which list is longer."
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html#practice-4.",
    "href": "practice_sessions/practice_1-2_lists.html#practice-4.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \n\nCreate a new list of 10 random floats between 0 and 1 called rand_list.\nAdd rand_list and my_list together in a new list called float_list.\nPrint the result."
  },
  {
    "objectID": "practice_sessions/practice_1-2_lists.html#practice-5.",
    "href": "practice_sessions/practice_1-2_lists.html#practice-5.",
    "title": "Practice 1-2: Lists + Indexing",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \nUse the range() function to construct a list of all hundreds (e.g.¬†100, 200, etc.) between 0 and 1000, inclusive."
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | ‚û°Ô∏è Next Session |"
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html#practice-1",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html#practice-1",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "üìö Practice 1",
    "text": "üìö Practice 1\nIn programs, if statements are useful for catching errors due to user input.\nDefine two new variables based on user input: the first prompting for a temperature value and the second prompting for the units as ‚ÄúF‚Äù or ‚ÄúC‚Äù.\nUsing the equation below, write an if statement that converts the temperature input to ¬∞C if it was given in ¬∞F or to ¬∞F if given in ¬∞C. Recall that all variables assigned based on user input are strings. Be sure to comment your code.\nFormula for conversion between ¬∞F and ¬∞C: T_{^{\\circ} C} = (T_{^{\\circ} F} - 32) \\times 5/9\nDescribe your strategy here:\n\n\nCode\n# Add your code here:"
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html#practice-2.",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html#practice-2.",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "üìö Practice 2.",
    "text": "üìö Practice 2.\nUsing nested if statements and your code from Practice question #1, convert the user input temperature to the opposite units (¬∞F to ¬∞C or vice versa), print a statement to the user that reports the temperature in the converted units and indicates whether or not the temperature below freezing.\nYour print statement should look something like:\nThe temperature is {__}¬∞C/F. It is (not) below freezing.\nDescribe your strategy here:\n\n\nCode\n# Add your code here:"
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html#practice-3.",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html#practice-3.",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "üìö  Practice 3. ",
    "text": "üìö  Practice 3. \n\nCreate a list of the six organic elements sorted in alphabetical order and then print each element in the list.\n\nGiven your sorted org_elements list and the corresponding list of atomic masses given in the cell below, use enumerate() in a for loop to print a formatted statement that expresses the atomic mass of of each element.\nYour formatted print statement should include the name of the element, the atomic mass rounded to 2 decimal places, and units.\nDescribe your strategy here:\n\n\nCode\natomic_mass = [12.011, 1.00784, 14.0067, 15.999, 30.97376, 32.065]  # g/mol"
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html#practice-4.",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html#practice-4.",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nThe cell below contains monthly global land-ocean surface temperature in ¬∞F for each month during the years 2015-2022.\nUsing enumerate(), zip(), a nested for loop, or some combination of the three:\n\n\nCalculate the monthly global land-ocean surface temperature anomalies (deviation from the mean) in ¬∞C for 2015-2018. The mean global land-ocean surface temperature calculated over the 20th century was 15.6¬∞C.\n\n\nCreate a new list with the mean monthly global surface temperature anomalies in ¬∞C for 2015-2021 (i.e.¬†calculate the mean temperature anomaly for each month and put these values in a list). Use the command np.mean() to calculate mean values.\n\n\nPrint each monthly mean value with the name of the month and units."
  },
  {
    "objectID": "practice_sessions/practice_2-1_control_flow_statements.html#practice-5.",
    "href": "practice_sessions/practice_2-1_control_flow_statements.html#practice-5.",
    "title": "Practice 2-1: Control Flow Statements",
    "section": "üìö Practice 5.",
    "text": "üìö Practice 5.\nUse a list comprehension to print a list of all months that had an anomaly above the average monthly anomaly.\nSome helpful code is provided below:\nimport numpy as np\n\nmonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n# np.mean can take the average of a list:\naverage_anomaly = np.mean(mean_monthly_anomalies)\nRecall that list comprehensions can contain if statements. For example:\n[item for item in list if item &gt; value]\nAnd they can also contain enumerate statements:\n[item for index,item in enumerate(list) if other_list[index] &gt; value]\nDescribe your strategy here:\n\n\nCode\n# Add your code here:"
  },
  {
    "objectID": "trypy/99_trypy_data_types/data_types_exercise.html#part-0.-setup-steps",
    "href": "trypy/99_trypy_data_types/data_types_exercise.html#part-0.-setup-steps",
    "title": "TryPy 2 - Data Types, Indexing, Imports and Plotting",
    "section": "Part 0. Setup Steps",
    "text": "Part 0. Setup Steps\n\nCreate a repo on GitHub named eds217-trypy-02\nClone to create a version-controlled project\nCreate some subfolder infrastructure (docs, data)\nCreate a new quarto in RStudio new .ipynb file called eds217-trypy-02.ipynb in VSCode. If working on your local machine, make sure to associate the notebook with the eds217_2023 environment."
  },
  {
    "objectID": "trypy/99_trypy_data_types/data_types_exercise.html#part-1.-checking-data-types",
    "href": "trypy/99_trypy_data_types/data_types_exercise.html#part-1.-checking-data-types",
    "title": "TryPy 2 - Data Types, Indexing, Imports and Plotting",
    "section": "Part 1. Checking data types",
    "text": "Part 1. Checking data types\n\nCreate some data, check the classes, index!\n\nVectors, lists & data frames\nIn your notebook (or quarto) document:\n\nCreate a list called vec_1containing the following:\n\n[2, 5, 9, 10, 8, 12, 1, 0]\nCheck the following for that list:\n\nWhat is the type of the list? type()\nAccess the 3rd element and store as vec_1_e3\nAccess the 1st element and store as vec_1_e1\nAccess the 5th through 7th elements and store as vec_1_e5to7\nReassign each element in vec_1 as a string and store the new list as vec_1_char. What does the output look like?\n\n\n\n&lt;class 'list'&gt;\n['2', '5', '9', '10', '8', '12', '1', '0']\n\n\n\nCreate a dictionary called dict_1\n\ndict_1 should contained named elements, where town = \"Santa Barbara, location = \"Rincon\", `swell = ‚Äúsouth‚Äù\n\nTake a look at what you‚Äôve made\nWhat is the type of dictionary values? type()\nWhat is the length of dict_1?\nAccess the ‚Äòlocation‚Äô value and store as dict_1_v2\n\n\nCreate a data frame in pandas\n\nWrite code to create a data frame called df_1 that looks like this:\n(Note: translate the R code below into python‚Ä¶ don‚Äôt forget to import pandas as pd)\n{r, echo = FALSE} df_1 &lt;- data.frame(     region = c(\"A\", \"B\", \"A\", \"D\"),     species = c(\"otter\", \"great white\", \"sea lion\", \"gray whale\"),     count = c(12, 2, 36, 6)     ) df_1 max_count &lt;- max(df_1$count)\n\nFind the maximum value of the count column, store as max_count\n\n\n\n36"
  },
  {
    "objectID": "trypy/99_trypy_data_types/data_types_exercise.html#part-2.-wild-data",
    "href": "trypy/99_trypy_data_types/data_types_exercise.html#part-2.-wild-data",
    "title": "TryPy 2 - Data Types, Indexing, Imports and Plotting",
    "section": "Part 2. Wild data",
    "text": "Part 2. Wild data\n\nSet-up\n\nThe first CSV listed (AS00601.csv) take a look at it (outside of python is fine as a first step, e.g.¬†you can open the CSV in Excel.)\nSave the AS00601.csv in the data folder of your repo.\n\n\n\nRead in the data\n\nRead in the data using pd.read_csv(), store as mack_verts\nLook at what you‚Äôve read in\n\n\n\nA bit of wrangling & exploring\n\nIn a new code chunk, practice accessing individual pieces of the data frame (there is no real functionality to this, but just to reinforce stuff we learned in our interactive session):\n\nStore the 5th value in column \"WEIGHT\" as mc_wt_5. Check by looking at your data frame to confirm.\nStore the 8th - 20th value in the \"LENGTH1\" column as mc_length_8_20. Check by looking at your data frame to confirm.\nStore everything in column SAMPLEDATE as a pd.Series called mc_dates\n\n\n\n\nMake a salamander subset\n\nCreate a subset that only contains observations for Pacific Giant Salamanders (species Dicamptodon tenebrosus, stored in SPECIES as DITE). Store the subset as mc_salamanders.\n\nHint: use a logical operator to filter for the rows you want.\nFor example, the following code block creates a new dataframe df_new containing only the rows in df_old where the value of column named ID is equal to Batman.\n    df_new = df_old[df_old['ID'] == 'Batman']\n\n\nMake a scatterplot of salamander length x weight\n\nCreate a scatterplot of LENGTH1 (snout-vent length in millimeters) versus WEIGHT (grams) for all salamanders in the subset you created above, mc_salamanders. Update axis labels, title, subtitle, and add a caption with the data source. Customize point color and size, possibly opacity, and the style.\n\n\n\n/Users/kellycaylor/mambaforge/envs/eds217_2023/lib/python3.10/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\nExport your scatterplot as salamander_size.png to your figs folder using the fig.savefig() command.\n\n\n\nMake a cutthroat plot\n\nSimilar to above, make a subset called mc_trout that only contains observations for cutthroat trout (species ‚ÄúONCL‚Äù)\n\nNote: In the following, it is way easier to make use of the sns.relplot() command in the seaborn library than matplotlib\n\nCreate a scatterplot of \"LENGHTH1\" by \"WEIGHT\" for all trout in the dataset\nCustomize so that the point color depends on reach\n\nhue=\"REACH\" in sns.relplot()\n\nFacet your plot by creek reach\n\ncol=\"REACH\" in sns.relplot()\n\nstore the output of sns.relplot() as ax\nUpdate facet plot axis labels and title\n\nax.set_axis_labels(xlabel,ylabel)\nax.fig.suptitle(title)\n\nExport your graph as cutthroat_size.png to the figs folder (fig.savefig())\n\n\n\n/Users/kellycaylor/mambaforge/envs/eds217_2023/lib/python3.10/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;"
  },
  {
    "objectID": "trypy/trypy.html#trypy-exercises",
    "href": "trypy/trypy.html#trypy-exercises",
    "title": "TryPy - Re-examining R exercises through Python",
    "section": "TryPy Exercises",
    "text": "TryPy Exercises\n\nTryPy 01 - St.¬†Louis Lead data exercise (reading csv, dataframe calculations, simple plots)\n\n\nTryPy 02 - Conditionals and Loops"
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#installing-conda",
    "href": "interactive_sessions/conda_setup.html#installing-conda",
    "title": "conda installation and usage",
    "section": "Installing conda",
    "text": "Installing conda\n\nInstalling Miniconda on Windows:\n\nDownload Miniconda Installer:\n\nGo to the Miniconda download page.\nDownload the Miniconda installer for Windows. Make sure to choose the appropriate version (Python 3.x) based on your preference.\n\nRun the Installer:\n\nLocate the downloaded installer and double-click on it to start the installation process.\nFollow the on-screen instructions. Here are some recommendations for the installation:\n\nChoose ‚ÄúJust Me‚Äù unless you‚Äôre sure about the ‚ÄúAll Users‚Äù option.\nUse the default installation location unless you have a specific need to change it.\nIt‚Äôs recommended to check the box ‚ÄúAdd Miniconda to my PATH environment variable‚Äù for easier command-line use. However, be aware that this can interfere with other Python installations.\n\n\nVerify Installation:\n\nOpen the Command Prompt (you can search for cmd in the Windows search bar).\nType conda --version and press Enter. This should display the version of conda installed, confirming that the installation was successful.\n\n\n\n\nInstalling Miniconda on MacOS:\n\nDownload Miniconda Installer:\n\nGo to the Miniconda download page.\nDownload the Miniconda installer for MacOS. Make sure to choose the appropriate version (Python 3.x) based on your preference.\n\nRun the Installer:\n\nOpen a terminal.\nNavigate to the directory where the installer was downloaded.\nMake the installer executable with the command:\nchmod +x Miniconda3-latest-MacOSX-x86_64.sh\nStart the installation process with:\n./Miniconda3-latest-MacOSX-x86_64.sh\nFollow the on-screen instructions to complete the installation.\n\nVerify Installation:\n\nIn the terminal, type:\nconda --version\nThis should display the version of conda installed, confirming that the installation was successful.\n\n\n\n\nInstalling Miniconda on Linux:\n\nDownload Miniconda Installer:\n\nGo to the Miniconda download page.\nDownload the Miniconda installer for Linux. Make sure to choose the appropriate version (Python 3.x) based on your preference.\n\nRun the Installer:\n\nOpen a terminal.\nNavigate to the directory where the installer was downloaded.\nMake the installer executable with the command:\nchmod +x Miniconda3-latest-Linux-x86_64.sh\nStart the installation process with:\n./Miniconda3-latest-Linux-x86_64.sh\nFollow the on-screen instructions to complete the installation.\n\nVerify Installation:\n\nIn the terminal, type:\nconda --version\nThis should display the version of conda installed, confirming that the installation was successful."
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#initializing-conda-for-your-shell",
    "href": "interactive_sessions/conda_setup.html#initializing-conda-for-your-shell",
    "title": "conda installation and usage",
    "section": "Initializing Conda for Your Shell:",
    "text": "Initializing Conda for Your Shell:\nOnce you‚Äôve identified your shell, you can initialize conda for it:\nconda init &lt;shell_name&gt;\nReplace &lt;shell_name&gt; with the name of the shell (bash, zsh, cmd, powershell, etc.)\nNote: If for any reason conda is not recognized as a command, it‚Äôs possible the conda binary path isn‚Äôt in your system‚Äôs PATH variable. You‚Äôll need to add it manually, and the process will depend on which OS and shell you‚Äôre using.\n\nUpdating conda\nYou won‚Äôt need to do this very often, but it‚Äôs a good idea to update conda periodically to ensure you have the latest version.\n\nWindows:\n\nOpen the a PowerShell from the Start Menu.\nRun the following command to update conda:\nconda update conda\n\nMacOS/Linux:\n\nOpen the Terminal.\nRun the following command to update conda:\nconda update conda"
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#creating-a-new-conda-environment",
    "href": "interactive_sessions/conda_setup.html#creating-a-new-conda-environment",
    "title": "conda installation and usage",
    "section": "Creating a new conda environment",
    "text": "Creating a new conda environment\nConda can create new environments using a markup language specification called yaml. We will use an environment file created for our course to create an eds217_2023 environment on your local machine.\nYou can create a new environment using the following command:\n    conda create -n my_cool_environment\nThis will create a new environment named my_cool_environment\nOften you will want to specify the python that you‚Äôd like the environment to use. You do that by adding a python=&lt;version&gt;. Here is a command that would create an environment that had the python 3.10 interpreter installed:\n    conda create -n my_py310_environment python=3.10\nFinally, you probably noticed that conda prompts you for permission before installing new packages. Sometimes you need to pay attention to these prompts, especially when you are adding packages to very complex environments. But on creation, you may want to speed things up. The --yes flag allows you to bypass approval and go straight to installation:\n    conda create --yes -n my_py310_environment python=3.10"
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#activating-an-environment",
    "href": "interactive_sessions/conda_setup.html#activating-an-environment",
    "title": "conda installation and usage",
    "section": "Activating an environment",
    "text": "Activating an environment\nYou can activate an environment using the following command:\n    conda activate my_cool_environment"
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#deactivating-an-environment",
    "href": "interactive_sessions/conda_setup.html#deactivating-an-environment",
    "title": "conda installation and usage",
    "section": "Deactivating an environment",
    "text": "Deactivating an environment\nYou can deactivate an environment using the following command:\n    conda deactivate\nThere is no need to deactivate an environment before activating a different environment."
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#removing-an-environment-generally-you-wont-want-to-do-this",
    "href": "interactive_sessions/conda_setup.html#removing-an-environment-generally-you-wont-want-to-do-this",
    "title": "conda installation and usage",
    "section": "Removing an environment (generally, you won‚Äôt want to do this!)",
    "text": "Removing an environment (generally, you won‚Äôt want to do this!)\nYou can remove an environment using the following command:\n    conda env remove -n my_cool_environment"
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#listing-all-available-environments",
    "href": "interactive_sessions/conda_setup.html#listing-all-available-environments",
    "title": "conda installation and usage",
    "section": "Listing all available environments",
    "text": "Listing all available environments\nEventually you are going to have a lot of different environments, and you may not remember all of them, or the exact name of the one you are looking to activate. In this case, conda env list (or conda info --envs) is your friend.\n    conda env list\nThis will display a list of all the conda environments you have created. The currently active environment (if any) will be marked with an asterisk (*) next to its name."
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#prerequisites",
    "href": "interactive_sessions/conda_setup.html#prerequisites",
    "title": "conda installation and usage",
    "section": "Prerequisites:",
    "text": "Prerequisites:\n\nEnsure you have already installed conda (see above)."
  },
  {
    "objectID": "interactive_sessions/conda_setup.html#instructions",
    "href": "interactive_sessions/conda_setup.html#instructions",
    "title": "conda installation and usage",
    "section": "Instructions:",
    "text": "Instructions:\n\n1. Fork the eds217_2023 Repository:\nGo to the eds217_2023 repository and click the ‚ÄúFork‚Äù button in the upper right corner of the page. This will create a copy of the repository in your GitHub account.\n\n\n1. Clone Your Forked Repository:\nOpen a terminal (Command Prompt on Windows, Terminal on MacOS/Linux) and navigate to the directory where you want to clone the repository.\ngit clone https://github.com/YOUR_USERNAME/eds217_2023.git\ncd eds217_2023\nReplace YOUR_USERNAME with your GitHub username.\n\n\n2. Create the Conda Environment:\n\nWindows:\nconda env create -f environment.yml\nconda activate eds217_2023\n\n\nMacOS/Linux:\nconda env create -f environment.yml\nsource activate eds217_2023\n\n\n\n3. Set Up the eds217_2023 Environment as an ipykernel:\nIn order to make sure our python environment is used when running code within an interactive editor such as a Jupyter notebook or in an IDE, you need ensure that the correct kernel is used to run our code. A python kernel is a program that runs and introspects the user‚Äôs code. Interactive tools such as Jupyter and IDEs use the kernel to execute code when you run a cell in the editor. `ipykernel`` is a tool that allows you to use specific python kernels when running code interactively within Jupyter notebooks and IDEs.\nAfter activating the eds217_2023 environment, run the following command:\npython -m ipykernel install --user --name eds217_2023 --display-name \"Python (eds217_2023)\"\nThis will allow you to select the eds217_2023 environment as a kernel in Jupyter or in your IDE, which we will install next."
  },
  {
    "objectID": "interactive_sessions/interactive_sessions.html",
    "href": "interactive_sessions/interactive_sessions.html",
    "title": "Interactive Sessions",
    "section": "",
    "text": "Return to Course Home Page\n\n\n\n\n\n0-1 - Ready, Set, Python!\n\n\nEntry Survey Responses\n\n\n0-2 - Hello, Data Science\n\n\n1-1 - Variables and Operators\n\n\n1-2 - Lists and Indexing\n\n\n2-1 - Control Flow Statements\n\n\n2-2 - Structured Data\n\n\n3-1 - Numpy\n\n\n4-1 - Pandas\n\n\n5-1 - Matplolib"
  },
  {
    "objectID": "interactive_sessions/99_seaborn.html",
    "href": "interactive_sessions/99_seaborn.html",
    "title": "Seaborn üìà",
    "section": "",
    "text": "Return to Course Home Page\n\n\n\n\n\n\n\nseaborn\n\n\nThis session provides a brief introduction to the Seaborn visualization library.\nSeaborn helps you explore and understand your data. Its plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots. Its dataset-oriented, declarative API lets you focus on what the different elements of your plots mean, rather than on the details of how to draw them.\nHere‚Äôs an example of seaborne‚Äôs capabilities.\n\n\nCode\n%matplotlib inline\n# Import seaborn\nimport seaborn as sns\n\n# Apply the default theme\nsns.set_theme()\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\n\n# Create a visualization\nsns.relplot(\n    data=tips,\n    x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"sex\", style=\"smoker\", size=\"size\",\n)\n\ntips.head()\n\n\nBehind the scenes, seaborn uses matplotlib to draw its plots. The plot above shows the relationship between five variables in the built-in tips dataset using a single call to the seaborn function relplot().\nNotice that you only need to provide the names of the variables and their roles in the plot.\nThis interface is different from matplotlib, in that you do not need to specify attributes of the plot elements in terms of the color values or marker codes.\nBehind the scenes, seaborn handled the translation from values in the dataframe to arguments that matplotlib understands. This declarative approach lets you stay focused on the questions that you want to answer, rather than on the details of how to control matplotlib.\n\nSeaborn relplot()\nThe function relplot() is named that way because it is designed to visualize many different statistical relationships. While scatter plots are often effective, relationships where one variable represents a measure of time are better represented by a line. The relplot() function has a convenient kind parameter that lets you easily switch to this alternate representation:\n\n\nCode\ndots = sns.load_dataset(\"dots\")\nsns.relplot(\n    data=dots, kind=\"line\",\n    x=\"time\", y=\"firing_rate\", col=\"align\",\n    hue=\"choice\", size=\"coherence\", style=\"choice\",\n    facet_kws=dict(sharex=False),\n)\n\n\nIf you compare the two calls to relplot() in the two examples so far, you will see that the size and style parameters are used in both the scatter plots (first example) and line plots (second example). However, they affect the two visualizations differently.\nIn a scatter plot, the size and style arguments affect marker area and symbol representation.\nIn a line plot, the size and style arguments alter the line width and dashing.\nAllowing the same arguments (syntax) to change meaning (semantics) across different contexts is more characteristic of natural languages than formal ones. In this case, seaborn is attempting to allow you to write in a ‚Äúgrammar of graphics‚Äù, which is the same concept underlying ggplot created by Hadley Wickham.\nThe benefit of adopting this less formal specification is that you do not need to worry about as many syntax details and instead can focus more on the overall structure of the plot and the information you want it to convey.\n\n\nComparing matplotlib to seaborn\nA focus of today‚Äôs activities is translation, so let‚Äôs look at translating some of the examples from yesterday‚Äôs matplotlib exercise into seaborn.\nFirst, as always, let‚Äôs import our important packages:\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nBasic line plots (sns.lineplot)\nYesterday we used a few functions, y_{\\sin} = \\sin{(x)} and y_{\\cos} = \\cos{(x)}:\n# Generate a 1D array with 300 points between -5 and 5\nx = np.linspace(-5,5,300)\n# Generate sine wave\nysin = np.sin(x)\n# Generate cosine wave\nycos = np.cos(x)\n\n# Now let's make a dataframe from these arrays:\ndf = pd.DataFrame({\n    'x': x,\n    'ysin': ysin,\n    'ycos': ycos\n    })\nWe can plot these on the same figure without instancing plt.figure() as follows:\n# Plot sine wave\nplt.plot(x,ysin)\n# Plot cosine wave\nplt.plot(x,ycos)\nSeaborn uses the lineplot command to plot line plots:\nsns.lineplot(data=df,x='x',y='ysin')\nsns.lineplot(data=df,x='x',y='ycos')\n\n\nCode\n# Generate a 1D array with 300 points between -5 and 5\nx = np.linspace(-5,5,300)\n# Generate sine wave\nysin = np.sin(x)\n# Generate cosine wave\nycos = np.cos(x)\n\n# Now let's make a dataframe from these arrays:\ndf = pd.DataFrame({\n    'x': x,\n    'ysin': ysin,\n    'ycos': ycos\n    })\n\nsns.lineplot(data=df,x='x',y='ysin')\nsns.lineplot(data=df,x='x',y='ycos')\nplt.ylabel('Add a title')\nplt.savefig('output.png')\n\n\nüìö Practice 2. 1. Load the flights dataset using the sns.load_dataset(\"flights\") command. 1. Explore the dataframe (it contains passenger data by month and year). 1. Use sns.lineplot() to plot the number of passengers throughout the data set. 1. Create a new dataset that contains data on a specific month (your choice) to see how monthly passengers have changed over time. 1. Create a plot that shows the average and range of passengers by year. (Hint: This is much easier than it sounds in seaborn!)\n\n\nCode\nflights = sns.load_dataset(\"flights\")\n\n\n\n\n\n\n\nWorking with real data\n\n\nAs we learned in the previous exercise, working with real-world data usually complicates things, and plotting is no exception. In particular, working with time series can get a bit messy. Let‚Äôs take a look at our BSRN data as an example.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Import data\nbsrn = pd.read_csv('../data/BSRN_GOB_2019-10.csv',index_col=0,parse_dates=True)\n\nbsrn.head()\n\n# Some species data \nmack_verts = pd.read_csv(\"../data/AS00601.csv\")\n\n\nNow that we‚Äôve imported our data, let‚Äôs make a quick plot of incoming shortwave radiation over time.\n\n‚ñ∂Ô∏è &lt;b&gt; Translate the cell below into seaborn. &lt;/b&gt;\n\n\n\nCode\n# # Initialize empty figure\n# fig = plt.figure()\n# # Plot incoming SW radiation\n# plt.plot(bsrn.index,bsrn.SWD_Wm2)\n# # Label y-axis\n# plt.ylabel(r'Incoming SW radiation (W m$^{-2}$)')\n\n\n\n\nThe x-axis looks rather messy because the tick labels are timestamps, which are, by nature, very long. Luckily, matplotlib has a module called dates for dealing with datetime objects.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nimport matplotlib.dates as mdates\n\n\nWithout going into too much detail, we can use some of the more advanced Axes settings to format and rotate the tick labels such that they no longer overlap, and we can use matplotlib.dates to format the timestamps. In short, we will use the mdates.DateFormatter() function to format the timestamps according to C formatting codes.\nThe following example demonstrates this, and includes a good code chunk for formatting timestamps to add to your repertoire. It is important to note that the formatting methods employed here are Axes methods, which means that we must operate on an Axes object, rather than the Figure.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure and axes\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n# Plot incoming SW radiation\nax.plot(bsrn.index,bsrn.SWD_Wm2)\n# Label y-axis\nax.set_ylabel(r'Incoming SW radiation (W m$^{-2}$)')\n\n# Format timestamps\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%y'))\n# Format and rotate ticks\nplt.setp(ax.get_xticklabels(), rotation=45, fontsize=10, ha='right')\nax.get_xticklabels()\n\n\n\nüìö  &lt;b&gt; Practice 3. &lt;/b&gt; \nPlot temperature and relative humidity (ideally using subplots) over the month of October 2019 at the BSRN station. Be sure to format the timestamps and include axis labels, a title, and a legend, if necessary."
  },
  {
    "objectID": "interactive_sessions/vscode_setup.html#prerequisites",
    "href": "interactive_sessions/vscode_setup.html#prerequisites",
    "title": "Installing and configuring VSCode for Python development",
    "section": "Prerequisites:",
    "text": "Prerequisites:\n\nEnsure you have Visual Studio Code installed.\nInstall the Python extension for VSCode from the Visual Studio Code Marketplace.\nFollow the previous instructions to set up the eds217_2023 environment on your machine."
  },
  {
    "objectID": "interactive_sessions/vscode_setup.html#instructions",
    "href": "interactive_sessions/vscode_setup.html#instructions",
    "title": "Installing and configuring VSCode for Python development",
    "section": "Instructions:",
    "text": "Instructions:\n\n1. Open the eds217_2023 Directory in VSCode:\nLaunch VSCode, then go to File &gt; Open Folder (or File &gt; Open on MacOS) and select the eds217_2023 directory that you cloned from GitHub.\n\n\n2. Selecting the Python Interpreter:\nOnce the folder is open in VSCode:\n\nClick on the Python version in the corner of the VSCode window.\nA list of available Python interpreters will appear at the top. Look for the one that corresponds to the eds217_2023 environment. It should look something like this: Python (eds217_2023).\nClick on it to select it. This ensures that any Python file or Jupyter notebook you open in VSCode will use the eds217_2023 environment.\n\n\n\n3. Verify the Jupyter Kernel:\nIf you‚Äôre working with Jupyter notebooks in VSCode:\n\nOpen or create a new Jupyter notebook (.ipynb file).\nIn the top-right corner of the notebook editor, you‚Äôll see the kernel that the notebook is using. Ensure it says Python (eds217_2023). If not, click on it and select Python (eds217_2023) from the dropdown list.\n\n\n\n4. Troubleshooting:\nIf you don‚Äôt see the eds217_2023 environment in the list of available interpreters or kernels:\n\nEnsure you‚Äôve activated the environment in your terminal and installed the Jupyter kernel as described in the previous instructions.\nRestart VSCode.\n\nThere are a ton of great tutorials that can help you make the most of VSode. Here are some of our favorites:\n\n\nCode\nfrom IPython.display import YouTubeVideo\n\ntutorial_ids = [\"h1sAzPojKMg\",\"E9U-EBG8jVk\", \"zulGMYg0v6U\"]\nfor tutorial in tutorial_ids:\n    display(YouTubeVideo(tutorial))"
  },
  {
    "objectID": "interactive_sessions/99_hello_world.html",
    "href": "interactive_sessions/99_hello_world.html",
    "title": "Interactive Session 0-2: Hello, World!",
    "section": "",
    "text": "Python is a general-purpose, open-source programming language with diverse capabilities. While it is often used for high-level applications and complex tasks, Python‚Äôs object-oriented structure and clean syntax make it straightforward to learn.\nIn addition to Python scripts (.py files), many data scientists use Jupyter Notebooks (.ipynb files) for experimentation and visualization.\nNotebooks allow for rapid code evaluation and ease of use. For this reason, sessions have been designed in Jupyter Notebook format, though you are encouraged to explore Python scripts as well.\nThis first session will briefly introduce a few basic Python features."
  },
  {
    "objectID": "interactive_sessions/99_hello_world.html#introduction-to-python",
    "href": "interactive_sessions/99_hello_world.html#introduction-to-python",
    "title": "Interactive Session 0-2: Hello, World!",
    "section": "Introduction to Python",
    "text": "Introduction to Python\n\n\n\nPrint statements\nThe most basic function in Python is the print() function, which simply prints out a line.\nprint( 'This is a print statement.' )\n\n &gt;&gt;&gt;  This is a print statement.\n\n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\nprint( 'This is a print statement.' )\n\n\nThis is a print statement.\n\n\n\nüìö Practice 1. In the following cell, use the print() command to print the line ‚ÄúHello, World!‚Äù)\n\n\n\n\n\nUser input\nThe input() command is an important Python function that can be used in a program to prompt for user input."
  },
  {
    "objectID": "interactive_sessions/99_hello_world.html#try-it.",
    "href": "interactive_sessions/99_hello_world.html#try-it.",
    "title": "Interactive Session 0-2: Hello, World!",
    "section": "‚úèÔ∏è Try it.",
    "text": "‚úèÔ∏è Try it.\nRun the following cell to see how the input() function works, inputing your first name when prompted.\n\n\nCode\nname = input( 'What is your first name? ' )\nprint(name)\n\n\n\n\n\n\n\n\nComments\nIn programming, a comment is a piece of text that the computer ignores when running the program. Comments are usually used at the top of a program to provide a description of the program, name and information of the author, dependencies, etc., as well as throughout the script to explain lines of code. Commenting is a critical element of proper coding etiquette.\nThere are two types of comments: in-line comments and block comments. In-line comments are used to provide context at the end of a line of code, while block comments come before a ‚Äúblock‚Äù or chunk of code.\n\nüêç &lt;b&gt;Note.&lt;/b&gt;\nIn Python, there are two ways of writing comments. For in-line comments and most short comments, the &lt;span style=\"font-weight:bold\"&gt; # &lt;/span&gt; character is used. For large block comments, such as those at the beginning of a file or function, three quotations &lt;span style=\"font-weight:bold\"&gt;  '''  &lt;/span&gt; are used to enclose comments. Both single and double quotations are interpreted the same, as long as they are not used together.\n\nThe following example is a function (a type of Python object we will cover later on) that uses both methods of commenting. As you can see, without the comments, it would be difficult to understand what the function does, what parameters it takes, and what the intermediate steps are to reach the end.\ndef homo_affine_matrix(p, p_prime):\n    '''\n    Finds the unique homogeneous affine transformation that \n    transforms a set of 3 points from one coordinate system \n    to that of a second set of points in 3-D space\n    \n    Parameters\n    ----------\n    p : array\n        original set of points as a row vector: ((p1, p2, p3))\n    p_prime : array\n        Transformed points as a row vector: ((p1_prime, p2_prime, p3_prime))\n    \n    Returns\n    -------\n    array\n        4 x 3 affine transformation matrix.\n        \n    Source: Adapted by B. Morgan from https://math.stackexchange.com/a/222170 (robjohn)\n    '''\n    \n    # Construct intermediate matrix\n    Q       = p[1:]       - p[0]\n    Q_prime = p_prime[1:] - p_prime[0]\n\n    # Calculate rotation matrix\n    R = np.dot(np.linalg.inv(np.row_stack((Q, np.cross(*Q)))),\n               np.row_stack((Q_prime, np.cross(*Q_prime))))\n\n    # Calculate translation vector\n    t = p_prime[0] - np.dot(p[0], R)\n\n    # Calculate affine transformation matrix\n    return np.column_stack((np.row_stack((R, t)),\n                            (0, 0, 0, 1)))\n \n\n‚ñ∂Ô∏è Run the cell below.\n\n\n\nCode\n# This comment will not be read by the computer.\n2 + 2 \n\n\n4"
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html",
    "href": "interactive_sessions/0-1_ready_set_python.html",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "",
    "text": "üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |"
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#general-plan",
    "href": "interactive_sessions/0-1_ready_set_python.html#general-plan",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "General Plan",
    "text": "General Plan\nThere are many ways to set up your local machine to run maintainable python data science code. In addition to the usual need to build your code using version control (e.g.¬†GitHub), any strategy for local computation requires three critical components:\n\nA system for managing computing environments to ensure that code runs in a consistent environment.\nA system for managing python packages to ensure that code runs with consistent dependencies.\nA system for managing python code, which is usually an integrated development environment (IDE) in which editing and running code occur interactively.\n\nIn the past, these three components were often managed separately, but in recent years, there has been a trend towards integrating these components into a single system. For example, the RStudio IDE is a single system that manages all three components for R code. Similarly, the Data Spell IDE is a single system that manages all three components for python code.\nIn this class, we will use a combination of tools to manage these three components. We will use conda to manage computing environments and python packages, and we will use Visual Studio Code as our IDE.\nThese are both very popular tools in the python data science community, and they are both free and open source. However, there are many other options for managing computing environments, python packages, and code execution. We will discuss some of these options below, or you can skip ahead to the instructions for setting up your local machine."
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#managing-computing-environments-libraries-and-dependencies",
    "href": "interactive_sessions/0-1_ready_set_python.html#managing-computing-environments-libraries-and-dependencies",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Managing Computing Environments, Libraries, and Dependencies",
    "text": "Managing Computing Environments, Libraries, and Dependencies\nThere are many options for managing computing environments. These days, a common method is to use containers, in which an entire computational system (including processes, memory, disk space) is spun up as an isolated service on your local (or remote) machine. Tools such as docker or python-specific shiv allow for isolated packaging and execution of python programs. Generally, these are better-suited for deployment of code on remote servers, but they can be used locally too. In this class, we‚Äôre not going to use containers. Instead we will use a more traditional approach to managing computing environments and packages.\nMore traditional approaches to managing computing environments and/or packages and dependencies include a suite of diverse tools. Some of these focus only on managing computing environments, while others focus on managing python packages. Some are designed to work with python only (e.g venv, conda), while others are designed to work with any programming language (e.g virtualenv). A few of the most popular options in each category are listed below.\n\nPackage management tools for python\npip is the standard package management tool for python. It is included with the standard python distribution, and it is the most widely used package management tool for python. However, it does not manage computing environments, so it is not as widely used as other tools below.\npipx is a tool developed by Brett Cannon that is designed to manage python packages. It has the advantage of being able to install any package hosted on PyPI, as well as packages hosted on github and even packages you‚Äôve made on your local machine. However, it does not manage computing environments, and it does not manage package dependencies.\n\n\nEnvironment management tools for python\nvirtualenv is a is a tool to create isolated Python environments. Since Python 3.3, a subset of it has been integrated into the standard library under the venv. While venv is sufficient to create virtual environments, it does not manage package dependencies, so it is also not as widely used as other tools below.\n\n\nTools that manage both environments and packages\nconda is a tool developed by Anaconda that is designed to manage computing environments. However, it also allows you to install packages, and even install binaries of packages directly without the need for local compilation. It also manages package dependencies, ensuring libraries are inter-operable.\nmamba is a new tool developed by the QuantStack team that is designed to be a drop-in replacement for conda. It allows you to create new environments, install packages, and even install binaries of packages directly without the need for local compilation. It also manages package dependencies, ensuring libraries are inter-operable. It is designed to be faster than conda and to use fewer resources. It is also designed to be more compatible with pip than conda. However, it is not as widely used as conda and it is not as well-supported by IDEs.\npoetry is another new tool developed by the Python Packaging Authority team that is designed to manage computing environments and python packages. Advantages of poetry include a simplified approach to dependency management and a simplified approach to building and packaging your own code for distribution. Disadvantages include a lack of support for conda environments and a lack of support for pip packages that are not hosted on PyPI (although this may change in the future)."
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#forking-the-course-repository.",
    "href": "interactive_sessions/0-1_ready_set_python.html#forking-the-course-repository.",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Forking the course repository.",
    "text": "Forking the course repository.\nTo fork the course repository, you must go to the course repository on GitHub and click the ‚ÄúFork‚Äù button. This will add the repository to your own GitHub account, and allow you to make changes to the repository without affecting the original repository."
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#cloning-the-course-repository.",
    "href": "interactive_sessions/0-1_ready_set_python.html#cloning-the-course-repository.",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Cloning the course repository.",
    "text": "Cloning the course repository.\nOnce you have forked the repository (added it to your Github account), you need to clone the course repository to create a copy on your local machine.\nYou can clone the repo on the github site by going to your local account version of the repository on GitHub:\nhttps://github.com/[your-github-username]/eds217_2023\nClick on the green ‚ÄúCode‚Äù button and copy the URL that appears in the dropdown menu. Then use that url to clone the repository on your local machine:\ngit clone https://github.com/environmental-data-science/eds217_2023.git\nMake sure you put the course repository in a location where you can find it again. For example, you might want to put it in a folder called dev or meds or code or projects or something like that. Hopefully you already have organization from your prior work, but if not, now is a good time to start."
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#configuring-the-course-repository.",
    "href": "interactive_sessions/0-1_ready_set_python.html#configuring-the-course-repository.",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Configuring the course repository.",
    "text": "Configuring the course repository.\n\nSetting Up the Repository for Clean Jupyter Notebooks\nTo ensure the integrity and consistency of your Jupyter notebooks, it‚Äôs helpful to strip outputs before committing them. This keeps notebooks lightweight and avoids accidentally committing potentially sensitive information. It also makes it easier to collaborate on notebooks, because output changes won‚Äôt be flagged as changes in the Git history.\nTo setup the repository for clean Jupyter notebooks, you‚Äôll need to add a filter to your local Git configuration.\nBecause filters are scripts that run code on your local machine, we do this installation manually, so you can be sure you aren‚Äôt accidentally running malicious code.\ngit config --local filter.strip-notebook-output.clean \"jupyter nbconvert --stdin --stdout --to notebook --ClearOutputPreprocessor.enabled=True\"\ngit config --local filter.strip-notebook-output.smudge cat\ngit config --local filter.strip-notebook-output.required true\nThese commands set up a filter only for this repository. They tell Git how to process .ipynb files before commit and checkout.\nWith the filter set up, you can now add and commit Jupyter notebooks to the repository. The filter will automatically strip outputs from the notebooks during the commit process."
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#instructions-installing-configuring-conda",
    "href": "interactive_sessions/0-1_ready_set_python.html#instructions-installing-configuring-conda",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Instructions: Installing & configuring conda",
    "text": "Instructions: Installing & configuring conda"
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#instruction-launching-jupyter-and-testing-your-environment",
    "href": "interactive_sessions/0-1_ready_set_python.html#instruction-launching-jupyter-and-testing-your-environment",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Instruction: Launching Jupyter and testing your environment",
    "text": "Instruction: Launching Jupyter and testing your environment"
  },
  {
    "objectID": "interactive_sessions/0-1_ready_set_python.html#instructions-installing-and-confuguring-vscode",
    "href": "interactive_sessions/0-1_ready_set_python.html#instructions-installing-and-confuguring-vscode",
    "title": "Interactive Session 0-1: Getting ready to Python",
    "section": "Instructions: Installing and confuguring VSCode",
    "text": "Instructions: Installing and confuguring VSCode"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html",
    "href": "interactive_sessions/4-1_pandas.html",
    "title": "Session 4-1: Pandas üêº",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session |\nPandas (‚ÄúPython Data Analysis Library‚Äù) is arguably the most important tool for data scientists using Python. As the central component of the Python data science toolkit, pandas is essentially where your data will ‚Äúlive‚Äù when you‚Äôre working in Python. Pandas is built on NumPy, which means that many of the data structures of NumPy are used in pandas. Data stored in pandas DataFrames are often analysed statistically in SciPy, visualized using plotting functions from Matplotlib, and fed into machine learning algorithms in scikit-learn.\nThis session will cover the basics of pandas, including DataFrame construction, importing data with pandas, DataFrame attributes, working with datetime objects, and data selection and manipulation. While this tutorial is designed to give you an overview of pandas, the docs should the first place you look for more detailed information and additional pandas functionality. The pandas documentation is particularly well-written, making it easy to find methods and functions with numerous examples. Make the docs your best friend! üêº\nThe Pandas library was originally developed by Wes McKinney, who is the author of the excellent Python for Data Analysis book, which is now its third edition."
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#introduction-to-pandas",
    "href": "interactive_sessions/4-1_pandas.html#introduction-to-pandas",
    "title": "Session 4-1: Pandas üêº",
    "section": "Introduction to pandas",
    "text": "Introduction to pandas\n\nAs always, we must begin by importing the pandas library. The standard import statement for pandas is:\nimport pandas as pd\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nimport pandas as pd\n\n\n\nSeries and DataFrame objects\n\n\nThe core components of pandas are the Series and the DataFrame objects. Both of these are essentially enhanced versions of the NumPy array, with a few key differences: 1) pandas DataFrames can be heterogeneous, meaning that the columns can contain different data types; and 2) the rows and columns of DataFrames can be identified with labels (usually strings) in addition to standard integer indexing.\nA Series is essentially a column of data, while a DataFrame is a multidimensional table made up of many Series, not unlike a spreadsheet:\n\nSeries and DataFrames are similar in many respects ‚Äì most common operations can be performed on both objects, though Series are more limited, as they can only ever contain a single column (i.e.¬†you cannot turn a Series into a DataFrame by adding a column).\nBoth Series and DataFrame objects contain an Index object similar to the row index of the ndarray or the index of a list. The pandas Index object can be conceptualized as an immutable array or an ordered multiset. Unless explicitly defined otherwise, the Index of a Series or DataFrame is initialized as the ordered set of positive integers beginning at 0 (see figure above).\n\nCreating Series and DataFrame objects from scratch\nA Series can be easily created from a list or array as follows:\n# Create a Series from a list\nseries = pd.Series([25.8, 16.2, 17.9, 18.8, 23.6, 29.9, 23.6, 22.1])\n\nseries\n\n\n\n\n\n0    25.8\n1    16.2\n2    17.9\n3    18.8\n4    23.6\n5    29.9\n6    23.6\n7    22.1\ndtype: float64\n\n\n\n\nThere are many ways to create a DataFrame, but the most common are to use a list of lists or a dictionary. First, let‚Äôs use a list of lists (or an array):\n# Create a df from a list of lists\ndf = pd.DataFrame([[25.8, 28.1, 16.2, 11.0],[17.9, 14.2, 18.8, 28.0],\n                   [23.6, 18.4, 29.9, 27.8],[23.6, 36.2, 22.1, 14.5]],\n                 columns=['A','B','C','D'])\ndf\n\n\n\n\n\n      A     B     C     D\n0  25.8  28.1  16.2  11.0\n1  17.9  14.2  18.8  28.0\n2  23.6  18.4  29.9  27.8\n3  23.6  36.2  22.1  14.5\n\n\n\n\nMuch like with NumPy arrays, each inner list element in the outer list corresponds to a row. Using the optional columns keyword argument, we can specify the name of each column. If this parameter is not passed, the columns would be displayed with integer index values (like the rows).\nNext, let‚Äôs create a DataFrame from a dict object:\n# Create a df from a dictionary\ndf = pd.DataFrame({'A': [25.8, 17.9, 23.6, 23.6],\n                   'B': [28.1, 14.2, 18.4, 36.2],\n                   'C': [16.2, 18.8, 29.9, 22.1],\n                   'D': [11.0, 28.0, 27.8, 14.5]})\n\ndf\n\n\n\n\n\n      A     B     C     D\n0  25.8  28.1  16.2  11.0\n1  17.9  14.2  18.8  28.0\n2  23.6  18.4  29.9  27.8\n3  23.6  36.2  22.1  14.5\n\n\n\n\nUsing this method, each key corresponds to a column name, and each value is a column."
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-1.",
    "href": "interactive_sessions/4-1_pandas.html#practice-1.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö  Practice 1. ",
    "text": "üìö  Practice 1. \n\n\nUse a list of lists to construct a DataFrame named df1 containing the data in the table below.\n\n\n\n\n\nRiver\n\n\nLength (\\text{km})\n\n\nDrainage area (\\text{km}^2)\n\n\n\n\nAmazon\n\n\n6400\n\n\n7,050,000\n\n\n\n\nCongo\n\n\n4371\n\n\n4,014,500\n\n\n\n\nYangtze\n\n\n6418\n\n\n1,808,500\n\n\n\n\nMississippi\n\n\n3730\n\n\n3,202,230\n\n\n\n\n\n\n\nUse a dict to construct a DataFrame named df2 containing the data in the table below.\n\n\n\n\n\nRiver\n\n\nLength (\\text{km})\n\n\nDrainage area (\\text{km}^2)\n\n\n\n\nZambezi\n\n\n2574\n\n\n1,331,000\n\n\n\n\nMekong\n\n\n4023\n\n\n811,000\n\n\n\n\nMurray\n\n\n2508\n\n\n1,061,469\n\n\n\n\nRh√¥ne\n\n\n813\n\n\n98,000\n\n\n\n\nCubango\n\n\n1056\n\n\n530,000"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-2.-using-the-dataframe-bsrn",
    "href": "interactive_sessions/4-1_pandas.html#practice-2.-using-the-dataframe-bsrn",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö Practice 2. Using the DataFrame bsrn:",
    "text": "üìö Practice 2. Using the DataFrame bsrn:\n\n\nPrint a list of column names.\n\n\nHow many values are there in the entire DataFrame?\n\n\nWhat is the data type of the first column?\n\n\n\nDataFrame indexing + data selection\n\n\nBecause DataFrames can contain labels as well as indices, indexing in pandas DataFrames is a bit more complicated than we‚Äôve seen with strings, lists, and arrays. Generally speaking, pandas allows indexing by either the integer index or the label, but the syntax is a bit different for each.\nThe index operator, which refers to the square brackets following an object [], does not work quite like we might expect it to.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\nInstead of a value, we get a KeyError. This is because the Index object in pandas is essentially a dictionary, and we have not passed proper keys.\nInstead, pandas uses df.iloc[] for integer-based indexing to select data by position:\nbsrn.iloc[1434,12]\n\n &gt;&gt;&gt;  19.6\n\ndf.iloc acts just like the index operator works with arrays. In addition to indexing a single value, df.iloc can be used to select multiple rows and columns via slicing: df.iloc[row_start:row_end:row_step, col_start:col_end:col_step].\n# Select 6 rows, last 3 columns\nbsrn.iloc[1434:1440,12:]\n\n\n\n\n\n      T_degC    RH  P_hPa\n1434    19.6  17.6    965\n1435    19.5  17.5    965\n1436    19.4  17.4    965\n1437    19.1  17.5    965\n1438    19.4  17.6    965\n1439    19.3  17.5    965\n\n\n\n\n# First 5 columns, every 40th row\nbsrn.iloc[::40,:5]\n\n\n\n\n\n DATE H_m SWD_Wm2 STD_SWD DIR_Wm2 0 2019-10-01 00:00:00 2 -3.0 0.0 0.0 40 2019-10-01 00:40:00 2 -3.0 0.0 0.0 80 2019-10-01 01:20:00 2 -3.0 0.0 0.0 120 2019-10-01 02:00:00 2 -3.0 0.0 0.0 160 2019-10-01 02:40:00 2 -2.0 0.0 0.0 ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ 44440 2019-10-31 20:40:00 2 -2.0 0.0 0.0 44480 2019-10-31 21:20:00 2 -2.0 0.0 0.0 44520 2019-10-31 22:00:00 2 -2.0 0.0 0.0 44560 2019-10-31 22:40:00 2 -2.0 0.0 0.0 44600 2019-10-31 23:20:00 2 -2.0 0.0 0.0\n\n\n\n[1116 rows x 5 columns] \n\n\nRow indexing\nIn addition to df.iloc, rows of a DataFrame can be accessed using df.loc, which ‚Äúlocates‚Äù rows based on their labels. Unless you have set a custom index (which we will see later), the row ‚Äúlabels‚Äù are the same as the integer index.\nWhen indexing a single row, df.loc (like df.iloc) transforms the row into a Series, with the column names as the index:\n# Classic indexing\nbsrn[1434]\n\n\n\n\n\nDATE       2019-10-01 23:54:00\nH_m                          2\nSWD_Wm2                     -2\nSTD_SWD                      0\nDIR_Wm2                      0\nSTD_DIR                      0\nDIF_Wm2                     -2\nSTD_DIF                      0\nLWD_Wm2                    307\nSTD_LWD                    0.1\nSWU_Wm2                      0\nLWU_Wm2                    385\nT_degC                    19.6\nRH                        17.6\nP_hPa                      965\nName: 1434, dtype: object\n\n\n\n\n\nüêç &lt;b&gt;DataFrames + data types.&lt;/b&gt;  Notice that the &lt;code&gt;dtype&lt;/code&gt; of the Series is an &lt;code&gt;object&lt;/code&gt;. This is because the column contains mixed data types ‚Äì floats, integers, and an &lt;code&gt;object&lt;/code&gt; in the first row. Unlike NumPy, pandas allows both rows and columns to contain mixed data types. However, while it is perfectly fine (and, in fact, almost always necessary) to have multiple data types within a single &lt;b&gt;&lt;i&gt;row&lt;/i&gt;&lt;/b&gt;, it is best if each &lt;b&gt;&lt;i&gt;column&lt;/i&gt;&lt;/b&gt; is comprised of a &lt;b&gt;&lt;i&gt;single data type&lt;/i&gt;&lt;/b&gt;.\n\nSlicing using df.loc is similar to df.iloc, with the exception that the stop value is inclusive:\n# Using .loc\nbsrn.loc[1434:1440]\n\n\n\n\n\n DATE H_m SWD_Wm2 STD_SWD DIR_Wm2 ‚Ä¶ SWU_Wm2 LWU_Wm2 T_degC RH P_hPa 1434 2019-10-01 23:54:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 385 19.6 17.6 965 1435 2019-10-01 23:55:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 385 19.5 17.5 965 1436 2019-10-01 23:56:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 386 19.4 17.4 965 1437 2019-10-01 23:57:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 386 19.1 17.5 965 1438 2019-10-01 23:58:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 386 19.4 17.6 965 1439 2019-10-01 23:59:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 386 19.3 17.5 965 1440 2019-10-02 00:00:00 2 -2.0 0.0 0.0 ‚Ä¶ 0 386 19.1 17.5 965\n\n\n\n[7 rows x 15 columns] \n\n\n\nColumn indexing\nIn addition to integer indexing with df.iloc, columns can be accessed in two ways: dot notation . or square brackets []. The former takes advantage of the fact that the columns are effectively ‚Äúattributes‚Äù of the DataFrame and returns a Series:\nbsrn.SWD_Wm2\n\n\n\n\n\n0       -3.0\n1       -3.0\n2       -3.0\n3       -3.0\n4       -3.0\n...\n44635   -2.0\n44636   -2.0\n44637   -2.0\n44638   -2.0\n44639   -2.0\nName: SWD_Wm2, Length: 44640, dtype: float64\n\n\n\n\nThe second way of extracting columns is to pass the column name as a string in square brackets, i.e.¬†df['col']:\nbsrn['SWD_Wm2']\n\n\n\n\n\n0       -3.0\n1       -3.0\n2       -3.0\n3       -3.0\n4       -3.0\n...\n44635   -2.0\n44636   -2.0\n44637   -2.0\n44638   -2.0\n44639   -2.0\nName: SWD_Wm2, Length: 44640, dtype: float64\n\n\n\n\nUsing single brackets, the result is a Series. However, using double brackets, it is possible to return the column as a DataFrame:\nbsrn[['SWD_Wm2']]\n\n\n\n\n\n SWD_Wm2 0 -3.0 1 -3.0 2 -3.0 3 -3.0 4 -3.0 ‚Ä¶ ‚Ä¶ 44635 -2.0 44636 -2.0 44637 -2.0 44638 -2.0 44639 -2.0\n\n\n\n[44640 rows x 1 columns] \n\nThis allows you to add additional columns, which you cannot do with a Series object. Furthermore, with the double bracket notation, a list is being passed to the index operator (outer brackets). Thus, it is possible to extract multiple columns by adding column names to the list:\nbsrn[['SWD_Wm2','LWD_Wm2']]\n\n\n\n\n\n SWD_Wm2 LWD_Wm2 0 -3.0 300.0 1 -3.0 300.0 2 -3.0 300.0 3 -3.0 300.0 4 -3.0 300.0 ‚Ä¶ ‚Ä¶ ‚Ä¶ 44635 -2.0 380.0 44636 -2.0 380.0 44637 -2.0 380.0 44638 -2.0 381.0 44639 -2.0 381.0\n\n\n\n[44640 rows x 2 columns] \n\nWhen accessing a single column, the choice between using dot notation and square brackets is more or less a matter of preference. However, there are occasions when the bracket notation proves particularly useful. For example, you could access each column in a DataFrame by iterating through df.columns, which returns an Index object containing the column names as str objects that can be directly passed to the index operator. Additionally, you may find it useful to use the double bracket syntax to return a DataFrame object, rather than a Series, which can only ever contain a single column of data."
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-3.",
    "href": "interactive_sessions/4-1_pandas.html#practice-3.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö Practice 3.",
    "text": "üìö Practice 3.\n\n\nCreate a new DataFrame containing the first record for each day and the following columns: the timestamp of the record, incoming shortwave radiation, direct and diffuse radiation, and incoming longwave radiation. (Hint: the BSRN station collects data every minute).\n\n\nCreate a new Series containing the temperature values every hour at the top of the hour.\n\n\n\nDatetime objects\n\n\nLike the BSRN data we are working with in this session, many environmental datasets include timed records. Python has a few different libraries for dealing with timestamps, which are referred to as datetime objects. The standard datetime library is the primary way of manipulating dates and times in Python, but there are additional third-party packages that provide additional support. A few worth exploring are dateutil, an extension of the datetime library useful for parsing timestamps, and pytz, which provides a smooth way of tackling time zones.\nThough we will not review datetime objects in depth here, it is useful to understand the basics of how to deal with datetime objects in Python as you will no doubt encounter them in the future. For now, we will focus on a few pandas functions built on the datetime library to handle datetime objects.\nThe pd.date_range() function allows you to build a DatetimeIndex with a fixed frequency. This can be done by specifying a start date and an end date as follows:\npd.date_range('4/1/2017','4/30/2017')\n\n&gt;&gt;&gt; DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n                   '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n                   '2017-01-09', '2017-01-10',\n                   ...\n                   '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25',\n                   '2020-12-26', '2020-12-27', '2020-12-28', '2020-12-29',\n                   '2020-12-30', '2020-12-31'],\n                  dtype='datetime64[ns]', length=1461, freq='D')\nBecause it was not specified otherwise, the frequency was set as the default, daily. To return a different frequency, we could use the freq parameter:\n# Specify start and end, minute-ly frequency\npd.date_range('1/1/2017','12/31/2020', freq='min')\n\n&gt;&gt;&gt; DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 00:01:00',\n                   '2017-01-01 00:02:00', '2017-01-01 00:03:00',\n                   '2017-01-01 00:04:00', '2017-01-01 00:05:00',\n                   '2017-01-01 00:06:00', '2017-01-01 00:07:00',\n                   '2017-01-01 00:08:00', '2017-01-01 00:09:00',\n                   ...\n                   '2020-12-30 23:51:00', '2020-12-30 23:52:00',\n                   '2020-12-30 23:53:00', '2020-12-30 23:54:00',\n                   '2020-12-30 23:55:00', '2020-12-30 23:56:00',\n                   '2020-12-30 23:57:00', '2020-12-30 23:58:00',\n                   '2020-12-30 23:59:00', '2020-12-31 00:00:00'],\n                  dtype='datetime64[ns]', length=2102401, freq='T')\n\n# Specify start and end, monthly frequency\npd.date_range('1/1/2017','12/31/2020', freq='M')\n\n&gt;&gt;&gt; DatetimeIndex(['2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30',\n                   '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31',\n                   '2017-09-30', '2017-10-31', '2017-11-30', '2017-12-31',\n                   '2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n                   '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31',\n                   '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31',\n                   '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30',\n                   '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31',\n                   '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31',\n                   '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30',\n                   '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31',\n                   '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31'],\n                  dtype='datetime64[ns]', freq='M')\nThere are many other parameters for the pd.date_range() function, as well as other pandas functions. More useful to us, however, are the functions for dealing with existing timestamps, such as those in our bsrn DataFrame.\n\nParsing dates in pandas\nLet‚Äôs start by taking a look at bsrn.DATE, which contains the timestamps for each record of our BSRN data.\nbsrn.DATE\n\n\n\n\n\n0        2019-10-01 00:00:00\n1        2019-10-01 00:01:00\n2        2019-10-01 00:02:00\n3        2019-10-01 00:03:00\n4        2019-10-01 00:04:00\n...\n44635    2019-10-31 23:55:00\n44636    2019-10-31 23:56:00\n44637    2019-10-31 23:57:00\n44638    2019-10-31 23:58:00\n44639    2019-10-31 23:59:00\nName: DATE, Length: 44640, dtype: object\n\n\n\n\nWhile the values certainly resemble datetime objects, they are stored in pandas as ‚Äúobjects,‚Äù which basically means that pandas doesn‚Äôt recognize the data type ‚Äì¬†it doesn‚Äôt know how to handle them. Using the pd.to_datetime() function, we can convert this column to datetime objects:\npd.to_datetime(bsrn.DATE)\n\n\n\n\n\n0       2019-10-01 00:00:00\n1       2019-10-01 00:01:00\n2       2019-10-01 00:02:00\n3       2019-10-01 00:03:00\n4       2019-10-01 00:04:00\n...\n44635   2019-10-31 23:55:00\n44636   2019-10-31 23:56:00\n44637   2019-10-31 23:57:00\n44638   2019-10-31 23:58:00\n44639   2019-10-31 23:59:00\nName: DATE, Length: 44640, dtype: datetime64[ns]\n\n\n\n\nNotice that ostensibly nothing has changed, but the dtype is now a datetime object, making it much easier to manipulate not only this column, but the entire DataFrame. For instance, now that we‚Äôve told pandas that this column contains timestamps, we can set this column as the index using df.set_index().\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Convert bsrn.DATE column to datetime objects\nbsrn = pd.read_csv('../data/BSRN_GOB_2019-10.csv')\nbsrn['DATE'] = pd.to_datetime(bsrn.DATE)  # Note: overwriting a column like this is NOT recommended.\n# Set bsrn.DATE as the DataFrame index\nbsrn.set_index('DATE', inplace=True)\n\n\nAs noted in the comment in the cell above, reseting the values in a column as we did in the first line of code is generally not recommended, but in this case, since we knew exactly what the result would be, it‚Äôs acceptable. Also, notice the inplace=True argument passed to df.set_index(). This prevented us from having to copy the DataFrame to a new variable, instead performing the operation in-place.\nLet‚Äôs take a look at our DataFrame again:\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nbsrn.info()\n\n\nAs expected, the index has been changed to a DatetimeIndex, and there is no longer a 'DATE' column. Had we wanted to keep the timestamps as a column as well, we could have passed drop=False to df.set_index(), telling pandas not to drop (or delete) the 'DATE' column. We can look at the DatetimeIndex just as before using df.index.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nbsrn.describe()\n\n\nNow that we have a DatetimeIndex, we can access specific attributes of the datetime objects like the year, day, hour, etc. To do this, we add the desired time period using dot notation: df.index.attribute. For a full list of attributes, see the pd.DatetimeIndex documentation. For example:\n# Get the hour of each record\nbsrn.index.hour\n\n\n\n\n\nInt64Index([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n...\n23, 23, 23, 23, 23, 23, 23, 23, 23, 23],\ndtype='int64', name='DATE', length=44640)\n\n\n\n\nThe result is a pandas Index object with the same length as the original DataFrame. To return only the unique values, we use the Series.unique() function, which can be used on any Series object (including a column of a DataFrame):\n# Get the unique hour values\nbsrn.index.hour.unique()\n\n\n\n\n\nInt64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n17, 18, 19, 20, 21, 22, 23],\ndtype='int64', name='DATE')\n\n\n\n\n\nüêç &lt;b&gt;Method chaining.&lt;/b&gt;  This process of stringing multiple methods together in a single line of code is called &lt;b&gt;method chaining&lt;/b&gt;, a hallmark of object-oriented programming. Method chaining is a means of concatenating functions in order to quickly complete a series of data transformations. In pandas, we often use method chaining in aggregation processes to perfrom calculations on groups or selections of data. Methods are appended using dot notation to the end of a command. Any code that is expressed using method chaining could also be written using a series of commands (and vice versa). Method chaining is common in JavaScript, and while it is not widely used in Python, it is commonly applied in pandas.\n\nDealing with datetime objects can be tricky and often requires a bit of trial and error before the timestamps are in the desired format. If you know the format of your dataset and its timestamp records, you can parse the datetimes and set the index when reading in the data. For example, we could have imported our data as follows:\nbsrn = pd.read_csv('../data/BSRN_GOB_2019-10.csv',index_col=0,parse_dates=True)\nThis would have accomplished what we ultimately did in three lines in a single line of code. But remember, working with most raw datasets is rarely this straightforward ‚Äì¬†even the file we are using in this session was preprocessed to streamline the import process!\n\n\n\nA few useful operations\n\n\nNow that our DataFrame is a bit cleaner ‚Äì each of the columns contains a single, numeric data type ‚Äì we are ready to start working with our data. Next, we‚Äôll explore DataFrame reduction operations, how to add and delete data, and concatenation in pandas.\n\nDataFrame reduction\nMuch like NumPy, pandas has several useful methods for reducing data to a single statistic. These are intuitively named and include: df.mean(), df.median(), df.sum(), df.max(), df.min(), and df.std(). Unlike array reduction, however, these basic statistical methods in pandas operate column-wise, returning a Series containing the statistic for each column indexed by column name. For example:\n# Calculate median of each column\nbsrn.median()\n\n\n\n\n\nH_m          2.0\nSWD_Wm2     27.0\nSTD_SWD      0.3\nDIR_Wm2      0.0\nSTD_DIR      0.0\nDIF_Wm2     19.0\nSTD_DIF      0.1\nLWD_Wm2    340.0\nSTD_LWD      0.1\nSWU_Wm2     11.0\nLWU_Wm2    432.0\nT_degC      22.4\nRH          33.1\nP_hPa      965.0\ndtype: float64\n\n\n\n\nTo retrieve the value for just a single column, you can use indexing to call the column as a Series:\n# Calculate median incoming shortwave radiation\nbsrn.SWD_Wm2.median()\n\n &gt;&gt;&gt;  27.0\n\nFurthermore, while it is not apparent in this example, pandas default behaviour is to ignore NaN values when performing computations. This can be changed by passing skipna=False to the reduction method (e.g.¬†df.median(skipna=False)), though skipping NaNs is often quite useful!"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-4.",
    "href": "interactive_sessions/4-1_pandas.html#practice-4.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö  Practice 4. ",
    "text": "üìö  Practice 4. \nCalculate the mean incoming shortwave, outgoing shortwave, incoming longwave, and outgoing longwave radiation over the entire month.\n\nAdding data\nMuch like when we converted bsrn.DATE to datetime objects, a column can be added to a DataFrame using square bracket notation with a new column label as a string. The data for the new column can come in the form of a list, Series, or a single value:\ndf = pd.DataFrame([[25.8, 28.1, 16.2, 11.0],\n                   [17.9, 14.2, 18.8, 28.0],\n                   [23.6, 18.4, 29.9, 27.8],\n                   [23.6, 36.2, 22.1, 14.5]],\n                 columns=['A','B','C','D'])\n\n# Add a column from a list\ndf['E'] = [13.0, 40.1, 39.8, 28.2]\n\n# Add a column from a Series\ndf['F'] = pd.Series([18, 22, 30, 24])\n\n# Propagate a single value through all rows\ndf['G'] = 'blue'\n\ndf\n\n\n\n\n\n      A     B     C     D     E   F     G\n0  25.8  28.1  16.2  11.0  13.0  18  blue\n1  17.9  14.2  18.8  28.0  40.1  22  blue\n2  23.6  18.4  29.9  27.8  39.8  30  blue\n3  23.6  36.2  22.1  14.5  28.2  24  blue\n\n\n\n\nNew columns can also be added as the result of an arithmetic operation (e.g.¬†sum, product, etc.) performed on one or more existing columns:\n# Add a new column by converting values in df.A from ¬∞C to ¬∞F\ndf['A_degF'] = (df['A'] * (9/5)) + 32\n\n# Add a new column representing the difference between df.B and df.C\ndf['BC_diff'] = df.B - df.C\n\ndf\n\n\n\n\n\n      A     B     C     D     E   F     G  A_degF  BC_diff\n0  25.8  28.1  16.2  11.0  13.0  18  blue   78.44     11.9\n1  17.9  14.2  18.8  28.0  40.1  22  blue   64.22     -4.6\n2  23.6  18.4  29.9  27.8  39.8  30  blue   74.48    -11.5\n3  23.6  36.2  22.1  14.5  28.2  24  blue   74.48     14.1\n\n\n\n\nFinally, you can use a Boolean expression to add a column, which contains Boolean objects (True or False) based on the condition. For example:\n# Add a column with Booleans for values in df.D greater than or equal to 20.0\ndf['D_20plus'] = df.D &gt;= 20.0\n\ndf\n\n\n\n\n\n      A     B     C     D     E   F     G  A_degF  BC_diff  D_20plus\n0  25.8  28.1  16.2  11.0  13.0  18  blue   78.44     11.9     False\n1  17.9  14.2  18.8  28.0  40.1  22  blue   64.22     -4.6      True\n2  23.6  18.4  29.9  27.8  39.8  30  blue   74.48    -11.5      True\n3  23.6  36.2  22.1  14.5  28.2  24  blue   74.48     14.1     False\n\n\n\n\nThese conditional expressions can also be used to create Boolean masks, which allow you to ‚Äúmask‚Äù the values in the DataFrame that do not meet a condition, only extracting those that do. For example, let‚Äôs use a Boolean mask to apply an mathematical expression on only certain values in column 'D':\n# Subtract 20 from all values in dfD greater than or equal to 20\ndf['D_less20'] = df.D[df.D &gt;= 20.0] - 20.0\n\ndf\n\n\n\n\n\n      A     B     C     D     E   F     G  A_degF  BC_diff  D_20plus  D_less20\n0  25.8  28.1  16.2  11.0  13.0  18  blue   78.44     11.9     False       NaN\n1  17.9  14.2  18.8  28.0  40.1  22  blue   64.22     -4.6      True       8.0\n2  23.6  18.4  29.9  27.8  39.8  30  blue   74.48    -11.5      True       7.8\n3  23.6  36.2  22.1  14.5  28.2  24  blue   74.48     14.1     False       NaN\n\n\n\n\nAll values that do not meet the condition are hidden from the expression, leaving NaNs in the resulting column. Boolean masks come in quite handy in data analysis, as they allow you to extract certain rows from a DataFrame based on their values in one or more columns.\nFurthermore, in addition to simply adding columns, new columns can be inserted in a desired index position using df.insert() with arguments specifying the location, name, and values of the column:\n# Create list of seasons\nseasons = ['winter', 'spring', 'summer', 'fall']\n\n# Insert season as first column\ndf.insert(0, 'SEASON', seasons)\n\ndf\n\n\n\n\n\n   SEASON     A     B     C     D     E   F     G  A_degF  BC_diff  D_20plus  D_less20\n0  winter  25.8  28.1  16.2  11.0  13.0  18  blue   78.44     11.9     False       NaN\n1  spring  17.9  14.2  18.8  28.0  40.1  22  blue   64.22     -4.6      True       8.0\n2  summer  23.6  18.4  29.9  27.8  39.8  30  blue   74.48    -11.5      True       7.8\n3    fall  23.6  36.2  22.1  14.5  28.2  24  blue   74.48     14.1     False       NaN\n\n\n\n\n\n\nRemoving data\nUnlike adding new data columns, removing columns from a DataFrame should be done with caution. In fact, it‚Äôs not a bad idea to create a copy of your DataFrame before performing any operations. This will allow you to return to the original data as needed without having to re-import or re-initialize the DataFrame. If you do need to remove a column, you can use the del command:\n# Delete 'G' from df\ndel df['G']\n\ndf\n\n\n\n\n\n   SEASON     A     B     C     D     E   F  A_degF  BC_diff  D_20plus  D_less20\n0  winter  25.8  28.1  16.2  11.0  13.0  18   78.44     11.9     False       NaN\n1  spring  17.9  14.2  18.8  28.0  40.1  22   64.22     -4.6      True       8.0\n2  summer  23.6  18.4  29.9  27.8  39.8  30   74.48    -11.5      True       7.8\n3    fall  23.6  36.2  22.1  14.5  28.2  24   74.48     14.1     False       NaN\n\n\n\n\nNote that this is an in-place operation, meaning that the column is deleted from the original variable. Alternatively, you can use df.pop() to extract a column. This method allows a column values to be extracted (and deleted) from a DataFrame and assigned to a new variable:\n# Extract column 'F' from df as a new Series\ndf_F = df.pop('F')\n\ndf\n\n\n\n\n\n   SEASON     A     B     C     D     E  A_degF  BC_diff  D_20plus  D_less20\n0  winter  25.8  28.1  16.2  11.0  13.0   78.44     11.9     False       NaN\n1  spring  17.9  14.2  18.8  28.0  40.1   64.22     -4.6      True       8.0\n2  summer  23.6  18.4  29.9  27.8  39.8   74.48    -11.5      True       7.8\n3    fall  23.6  36.2  22.1  14.5  28.2   74.48     14.1     False       NaN\n\n\n\n\n\n\nApplying functions\nIn addition to manipulating individual columns, you can apply a function to an entire Series or DataFrame using the pandas function df.apply(). For example, consider our original DataFrame df, which consists of temperature values in ¬∞C:\ndf = pd.DataFrame([[25.8, 28.1, 16.2, 11.0],[17.9, 14.2, 18.8, 28.0],\n                   [23.6, 18.4, 29.9, 27.8],[23.6, 36.2, 22.1, 14.5]],\n                 columns=['A','B','C','D'])\ndf\n\n\n\n\n\n      A     B     C     D\n0  25.8  28.1  16.2  11.0\n1  17.9  14.2  18.8  28.0\n2  23.6  18.4  29.9  27.8\n3  23.6  36.2  22.1  14.5\n\n\n\n\nWe previously used arithmetic operators to convert column 'A' to ¬∞F, but we could also use a function. First, let‚Äôs define a function convert_CtoF to convert temperature values from Celsius to Fahrenheit:\ndef convert_CtoF(degC):\n    \"\"\" Converts a temperature to from Celsius to Fahrenheit\n    \n    Parameters\n    ----------\n        degC : float\n            Temperature value in ¬∞C\n       \n    Returns\n    -------\n        degF : float\n            Temperature value in ¬∞F\n    \"\"\"\n    \n    degF = (degC *(9./5)) + 32\n    \n    return degF\nUsing df.apply() we can use this function to convert values in column 'A' as follows:\ndf.A.apply(convert_CtoF)\n\n\n\n\n\n0    78.44\n1    64.22\n2    74.48\n3    74.48\nName: A, dtype: float64\n\n\n\n\nWhere this becomes especially useful is for operating on entire DataFrames. You have to be careful with this if your DataFrame contains multiple data types, but it works well when you need to perform an operation on an entire DataFrame. For example, we could convert all of the values in df by iterating through the columns, or, using df.apply(), we could acheive the same result in a single line of code:\ndf.apply(convert_CtoF)\n\n\n\n\n\n       A      B      C      D\n0  78.44  82.58  61.16  51.80\n1  64.22  57.56  65.84  82.40\n2  74.48  65.12  85.82  82.04\n3  74.48  97.16  71.78  58.10\n\n\n\n\ndf.apply(convert_CtoF)\n\n\n\n\n\n       A      B      C      D\n0  78.44  82.58  61.16  51.80\n1  64.22  57.56  65.84  82.40\n2  74.48  65.12  85.82  82.04\n3  74.48  97.16  71.78  58.10"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-5.",
    "href": "interactive_sessions/4-1_pandas.html#practice-5.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö  Practice 5. ",
    "text": "üìö  Practice 5. \n\n\nAdd a column ‚ÄòNET_SW‚Äô to bsrn with the net shortwave radiation.\n\n\nAdd a column ‚ÄòNET_LW‚Äô to bsrn with the net longwave radiation.\n\n\nAdd a column ‚ÄòNET_RAD‚Äô to bsrn with the net total radiation. Net radiation is given by the following equation:\n\nR^{}_{N} \\, = \\,  R^{\\, \\downarrow}_{SW} \\, - \\,  R^{\\, \\uparrow}_{SW} \\, + \\, R^{\\, \\downarrow}_{LW} \\, - \\,  R^{\\, \\uparrow}_{LW} where R^{\\, \\downarrow}_{SW} and R^{\\, \\uparrow}_{SW} are incoming and outgoing shortwave radiation, respectively, and R^{\\, \\downarrow}_{LW} and R^{\\, \\uparrow}_{LW} are incoming and outgoing longwave radiation, respectively.\n\nCreate a new DataFrame with the day of the month and daily mean values of shortwave incoming, shortwave outgoing, longwave incoming, longwave outgoing radiation, and net total radiation. (Hint: use masking!).\n\n\n\nCombining DataFrames\nThere are several ways to combine data from multiple Series or DataFrames into a single object in pandas. These functions include pd.append(), pd.join(), and pd.merge(). We will focus on the general pd.concat() function, which is the most versatile way to concatenate pandas objects. To learn more about these other functions, refer to the pandas documentation or see  Chapter 3 of the  Python Data Science Handbook.\nLet‚Äôs start by considering the simplest case of two DataFrames with identical columns:\ndf1 = pd.DataFrame([['Los Angeles', 34.0522, -118.2437],\n                    ['Bamako', 12.6392, 8.0029],\n                    ['Johannesburg', -26.2041, 28.0473],\n                    ['Cairo', 30.0444, 31.2357]],\n                  columns=['CITY', 'LAT', 'LONG'])\n\ndf2 = pd.DataFrame([['Cape Town', -33.9249, 18.4241],\n                    ['Kyoto', 35.0116, 135.7681],\n                    ['London', 51.5074, -0.1278],\n                    ['Cochabamba', -17.4140, -66.1653]],\n                  columns=['CITY', 'LAT', 'LONG'])\nUsing pd.concat([df1,df2]), we can combine the two DataFrames into one. Notice that we must pass the DataFrames as a list, because pd.concat() requires an iterable object as its input.\n# Concatenate df1 and df2\ncity_coords = pd.concat([df1,df2])\n\ncity_coords\n\n\n\n\n\n           CITY      LAT      LONG\n0   Los Angeles  34.0522 -118.2437\n1        Bamako  12.6392    8.0029\n2  Johannesburg -26.2041   28.0473\n3         Cairo  30.0444   31.2357\n0     Cape Town -33.9249   18.4241\n1         Kyoto  35.0116  135.7681\n2        London  51.5074   -0.1278\n3    Cochabamba -17.4140  -66.1653\n\n\n\n\nBy default, pandas concatenates along the row axis, appending the values in df2 to df1 as new rows. However, notice that the original index values have been retained. Since these index labels do not contain useful information, it would be best to reset the index before proceeding. This can be done in one of two ways. First, we could have passed ignore_index=True to the pd.concat() function, telling pandas to ignore the index labels. Since we have already created a new variable, however, let‚Äôs use a more general method: df.reset_index().\n# Reset index in-place and delete old index\ncity_coords.reset_index(inplace=True, drop=True)\n\ncity_coords\n\n\n\n\n\n           CITY      LAT      LONG\n0   Los Angeles  34.0522 -118.2437\n1        Bamako  12.6392    8.0029\n2  Johannesburg -26.2041   28.0473\n3         Cairo  30.0444   31.2357\n4     Cape Town -33.9249   18.4241\n5         Kyoto  35.0116  135.7681\n6        London  51.5074   -0.1278\n7    Cochabamba -17.4140  -66.1653\n\n\n\n\nBy passing the optional inplace and drop parameters, we ensured that pandas would reset the index in-place (the default is to return a new DataFrame) and drop the old index (the default behaviour is to add the former index as a column).\nNow let‚Äôs consider the case of concatenating two DataFrames whose columns do not match. In this case, pandas will keep source rows and columns separate in the concatenated DataFrame, filling empty cells with NaN values:\ndf3 = pd.DataFrame([['USA', 87],['Mali', 350],['South Africa', 1753],['Egypt', 23],\n                    ['South Africa', 25],['Japan', 47],['UK', 11],['Bolivia', 2558]],\n                  columns=['COUNTRY', 'ELEV'])\n\n# Concatenate cities1 and df3\npd.concat([city_coords,df3])\n\n\n\n\n\n           CITY      LAT      LONG       COUNTRY    ELEV\n0   Los Angeles  34.0522 -118.2437           NaN     NaN\n1        Bamako  12.6392    8.0029           NaN     NaN\n2  Johannesburg -26.2041   28.0473           NaN     NaN\n3         Cairo  30.0444   31.2357           NaN     NaN\n4     Cape Town -33.9249   18.4241           NaN     NaN\n5         Kyoto  35.0116  135.7681           NaN     NaN\n6        London  51.5074   -0.1278           NaN     NaN\n7    Cochabamba -17.4140  -66.1653           NaN     NaN\n0           NaN      NaN       NaN           USA    87.0\n1           NaN      NaN       NaN          Mali   350.0\n2           NaN      NaN       NaN  South Africa  1753.0\n3           NaN      NaN       NaN         Egypt    23.0\n4           NaN      NaN       NaN  South Africa    25.0\n5           NaN      NaN       NaN         Japan    47.0\n6           NaN      NaN       NaN            UK    11.0\n7           NaN      NaN       NaN       Bolivia  2558.0\n\n\n\n\nInstead, we must pass axis=1 to the function to specify that we want to add the data in df3 as columns to the new DataFrame:\n# Concatenate along column axis\ncities = pd.concat([city_coords,df3], axis=1)\n\ncities\n\n\n\n\n\n           CITY      LAT      LONG       COUNTRY  ELEV\n0   Los Angeles  34.0522 -118.2437           USA    87\n1        Bamako  12.6392    8.0029          Mali   350\n2  Johannesburg -26.2041   28.0473  South Africa  1753\n3         Cairo  30.0444   31.2357         Egypt    23\n4     Cape Town -33.9249   18.4241  South Africa    25\n5         Kyoto  35.0116  135.7681         Japan    47\n6        London  51.5074   -0.1278            UK    11\n7    Cochabamba -17.4140  -66.1653       Bolivia  2558"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-6.",
    "href": "interactive_sessions/4-1_pandas.html#practice-6.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö  Practice 6. ",
    "text": "üìö  Practice 6. \n\n\nConcatenate df1 and df2 into a new DataFrame with all 9 rivers.\n\n\nCreate a new DataFrame rivers with the discharge, mouth, source, and continent information and add this to your DataFrame from (a) to produce a DataFrame with all of the data in the table below.\n\n\n\n\n\n\nRiver\n\n\nLength (\\text{km})\n\n\nDrainage area (\\text{km}^2)\n\n\nDischarge (\\text{m}^3/\\text{s})\n\n\nMouth\n\n\nSource\n\n\nContinent\n\n\n\n\nAmazon\n\n\n6400\n\n\n7,050,000\n\n\n209,000\n\n\nAtlantic Ocean\n\n\nRio Mantaro\n\n\nSouth America\n\n\n\n\nCongo\n\n\n4371\n\n\n4,014,500\n\n\n41,200\n\n\nAtlantic Ocean\n\n\nLualaba River\n\n\nAfrica\n\n\n\n\nYangtze\n\n\n6418\n\n\n1,808,500\n\n\n30,166\n\n\nEast China Sea\n\n\nJianggendiru Glacier\n\n\nAsia\n\n\n\n\nMississippi\n\n\n3730\n\n\n3,202,230\n\n\n16,792\n\n\nGulf of Mexico\n\n\nLake Itasca\n\n\nNorth America\n\n\n\n\nZambezi\n\n\n2574\n\n\n1,331,000\n\n\n3,400\n\n\nIndian Ocean\n\n\nMiombo Woodlands\n\n\nAfrica\n\n\n\n\nMekong\n\n\n4023\n\n\n811,000\n\n\n16,000\n\n\nSouth China Sea\n\n\nLasagongma Spring\n\n\nAsia\n\n\n\n\nMurray\n\n\n2508\n\n\n1,0614,69\n\n\n767\n\n\nSouthern Ocean\n\n\nAustralian Alps\n\n\nOceania\n\n\n\n\nRh√¥ne\n\n\n813\n\n\n98,000\n\n\n1,710\n\n\nMediterranean Sea\n\n\nRh√¥ne Glacier\n\n\nEurope\n\n\n\n\nCubango\n\n\n1056\n\n\n530,000\n\n\n475\n\n\nOkavango Delta\n\n\nBi√© Plateau\n\n\nAfrica\n\n\n\n\n\nData export\n\n\nWhile you will most likely use pandas DataFrames to manipulate data, perform statistical analyses, and visualize results within Python, you may encounter scenarios where it is useful to ‚Äúsave‚Äù a DataFrame with which you‚Äôve been working. Exporting data from pandas is analogous to importing it.\nLet‚Äôs take the example of the cities DataFrame we created in the last example. Now that we‚Äôve compiled GPS coordinates of various cities, let‚Äôs say we wanted to load these data into a GIS software application. We could export this DataFrame using df.to_csv() specifying the file name with the full file path as follows:\ncities.to_csv('./exports/cities.csv')"
  },
  {
    "objectID": "interactive_sessions/4-1_pandas.html#practice-7.",
    "href": "interactive_sessions/4-1_pandas.html#practice-7.",
    "title": "Session 4-1: Pandas üêº",
    "section": "üìö  Practice 7. ",
    "text": "üìö  Practice 7. \nUsing the example above, export your rivers DataFrame to a CSV file in a local data folder. Make sure you have created a data folder in your local copy of the course repository first!\n\nCongratulations!\nYou made it to the end of your first journey with Pandas. You deserve a warm, fuzzy reward‚Ä¶\n\n\nCode\nfrom IPython.display import YouTubeVideo\nfrom random import choice\nids=['sGF6bOi1NfA','Z98ZxYFsIWo', 'l73rmrLTHQc', 'D7xWXk5T3-g']\nYouTubeVideo(id=choice(ids),width=600,height=300)\n\n\n\n        \n        \n\n\n\n\n\n\nCode\n# IGNORE THIS CELL\nfrom IPython.core.display import HTML\ndef css_styling():\n    styles = open(\"./styles/exercises.css\", \"r\").read()\n    return HTML(styles)\ncss_styling()"
  },
  {
    "objectID": "interactive_sessions/0-2_hello_data_science.html",
    "href": "interactive_sessions/0-2_hello_data_science.html",
    "title": "Interactive Session 0-2: ‚ÄúHello, Python Data Science‚Äù",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes | ‚û°Ô∏è Next Session|"
  },
  {
    "objectID": "interactive_sessions/0-2_hello_data_science.html#setup",
    "href": "interactive_sessions/0-2_hello_data_science.html#setup",
    "title": "Interactive Session 0-2: ‚ÄúHello, Python Data Science‚Äù",
    "section": "Setup",
    "text": "Setup\n\nFork and clone this repo\nCheck out the project structure & files"
  },
  {
    "objectID": "interactive_sessions/0-2_hello_data_science.html#data-science-101",
    "href": "interactive_sessions/0-2_hello_data_science.html#data-science-101",
    "title": "Interactive Session 0-2: ‚ÄúHello, Python Data Science‚Äù",
    "section": "Data Science 101",
    "text": "Data Science 101\n\nWe‚Äôll run through each line in the toolik_airtemp_summary.ipynb, which is translated from your first EDS221 assignment. This will allow us to understand where what it‚Äôs doing, and see for the first time, some of the most important tools in our python toolkit.\nSimilarly, we‚Äôll create a new notebook from scratch & work through one more example to read in a different dataset.\n\nOur second example will be to:\n\nRead in a different set of data from a long-term water quality study at Elkhorn Slough, CA.\nExplore the imported data\nClean up the dataset names\nCreate a plot of water quality variables at varying sites, do some customization\nExport the graph to /figs"
  },
  {
    "objectID": "interactive_sessions/0-2_hello_data_science.html#data-sources",
    "href": "interactive_sessions/0-2_hello_data_science.html#data-sources",
    "title": "Interactive Session 0-2: ‚ÄúHello, Python Data Science‚Äù",
    "section": "Data sources",
    "text": "Data sources\nAll datasets are collected and provided by scientists with the Toolik Station Long Term Ecological Research (LTER) site, Alaska.\nToolik Station Meteorological Data: toolik_weather.csv Shaver, G. 2019. A multi-year DAILY weather file for the Toolik Field Station at Toolik Lake, AK starting 1988 to present. ver 4. Environmental Data Initiative. https://doi.org/10.6073/pasta/ce0f300cdf87ec002909012abefd9c5c (Accessed 2021-08-08).\nToolik Lake Chlorophyll: toolik_chlorophyll.csv Miller, M. 2014. Chlorophyll A, and primary productivity of Toolik lake , Arctic LTER 1975 to 1988, Toolik Filed Station, Alaska. ver 5. Environmental Data Initiative. https://doi.org/10.6073/pasta/6738024bf0174f73b3f74486f43d1059 (Accessed 2021-08-08).\nToolik fish: toolik_fish.csv Budy, P., C. Luecke, and M. McDonald. 2020. Fish captures in lakes of the Arctic LTER region Toolik Field Station Alaska from 1986 to present. ver 6. Environmental Data Initiative. https://doi.org/10.6073/pasta/d0a9358f783339821b82510eb8c61b45 (Accessed 2021-08-08).\nElkhorn Slough Water Quality Data: elkhorn_slough_water_quality.csv Arora, B., Venkatesh, S., Dwivedi, D., Vezhapperambu, S., & Ramesh, M. (2022). Water Quality Parameters at the Elkhorn Slough National Estuarine Research Reserve (ESNERR). ESS-DIVE. doi:10.15485/1875297, version: ess-dive-941fcc36279c83f-20230407T151617854348.\nhttps://knb.ecoinformatics.org/view/doi%3A10.15485%2F1875297"
  },
  {
    "objectID": "interactive_sessions/enumerate_and_zip.html#first-lets-make-three-short-lists-to-use-in-our-example",
    "href": "interactive_sessions/enumerate_and_zip.html#first-lets-make-three-short-lists-to-use-in-our-example",
    "title": "Enumerate and Zip",
    "section": "1. First, let‚Äôs make three short lists to use in our example:",
    "text": "1. First, let‚Äôs make three short lists to use in our example:\n\n\nCode\nlist_1 = ['a', 'b', 'c', 'd']\nlist_2 = [1, 2, 3, 4]\nlist_3 = ['i', 'j', 'k', 'l']"
  },
  {
    "objectID": "interactive_sessions/enumerate_and_zip.html#now-lets-see-what-happens-when-we-put-the-first-list-into-a-for-loop-using-enumerate",
    "href": "interactive_sessions/enumerate_and_zip.html#now-lets-see-what-happens-when-we-put-the-first-list-into-a-for-loop-using-enumerate",
    "title": "Enumerate and Zip",
    "section": "2. Now, let‚Äôs see what happens when we put the first list into a for loop using enumerate",
    "text": "2. Now, let‚Äôs see what happens when we put the first list into a for loop using enumerate\n\n\nCode\nfor stuff in enumerate(list_1):\n    print(stuff)\n\n\n\nü§î stuff contained two items each time the loop ran. The first item is the index into list_1 (the current position of the loop in the list) and the second item is the value of list_1 at that position."
  },
  {
    "objectID": "interactive_sessions/enumerate_and_zip.html#lets-alter-our-code-to-assign-each-of-these-items-separately-in-the-for-loop",
    "href": "interactive_sessions/enumerate_and_zip.html#lets-alter-our-code-to-assign-each-of-these-items-separately-in-the-for-loop",
    "title": "Enumerate and Zip",
    "section": "3. Let‚Äôs alter our code to assign each of these items separately in the for loop:",
    "text": "3. Let‚Äôs alter our code to assign each of these items separately in the for loop:\n\n\nCode\nfor i,value in enumerate(list_1):\n    print(i,value)\n\n\n\nüß† : Now that we have an ‚Äúindex‚Äù variable (i), we could grab the value of any item in any other list at the same position!"
  },
  {
    "objectID": "interactive_sessions/enumerate_and_zip.html#lets-grab-the-values-of-list_1-and-list_2-as-well.",
    "href": "interactive_sessions/enumerate_and_zip.html#lets-grab-the-values-of-list_1-and-list_2-as-well.",
    "title": "Enumerate and Zip",
    "section": "4. Let‚Äôs grab the values of list_1 and list_2 as well.",
    "text": "4. Let‚Äôs grab the values of list_1 and list_2 as well.\n\n\nCode\nfor i,value in enumerate(list_1):\n    print(i,value,list_2[i],list_3[i])"
  },
  {
    "objectID": "interactive_sessions/enumerate_and_zip.html#finally-instead-of-using-the-index-to-grab-items-outside-the-loop-we-can-use-zip-to-loop-through-all-of-these-lists-at-the-same-time",
    "href": "interactive_sessions/enumerate_and_zip.html#finally-instead-of-using-the-index-to-grab-items-outside-the-loop-we-can-use-zip-to-loop-through-all-of-these-lists-at-the-same-time",
    "title": "Enumerate and Zip",
    "section": "üß† üß† Finally, instead of using the index to ‚Äúgrab‚Äù items outside the loop, we can use zip to loop through all of these lists at the same time!",
    "text": "üß† üß† Finally, instead of using the index to ‚Äúgrab‚Äù items outside the loop, we can use zip to loop through all of these lists at the same time!\n\n\nCode\nfor stuff in zip(list_1, list_2, list_3):\n    print(stuff)\n\n\n\n\nCode\ndef f(x):\n    return x + 'stuff'\n\n# new_list = []\n# for value in list_1:\n#     new_list.append(f(value))\n    \n\nnew_list = [f(value) for value in list_1]\nprint(new_list)\n\n\n\n\nCode\nfor v in zip(list_1): #, list_2, list_3):\n    print(v)\n\n\n\n\n\nth-4165028533.jpeg"
  },
  {
    "objectID": "interactive_sessions/5-1_matplotlib.html",
    "href": "interactive_sessions/5-1_matplotlib.html",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "",
    "text": "‚¨ÖÔ∏è Previous Session | üè† Course Home | üö¶ EDS217 Vibes |\nThere are extensive options for plotting in Python ‚Äì some favorites include statistical visualizations in Seaborn and interactive plots for web applications in Bokeh. The original and fundamental library for visualizations in Python, however, is matplotlib.\nMatplotlib was the first plotting library developed for Python and remains the most widely used library for data visualization in the Python community. Designed to resemble graphics in MATLAB, matplotlib is reminiscent of MATLAB in both appearance and functionality. As a result, it is not the easiest library to work with, and deviates from the object-oriented syntax we are familiar with in Python.\nThis session will serve as an introduction to plotting in Python using matplotlib. The nature of matplotlib ‚Äì and figure-making in general ‚Äì¬†is such that the easiest way to learn is by following examples. As such, this session is structured a bit differently than the others, so be sure to look carefully at the coded examples. Finally, the best way to learn advanced functions and find help with matplotlib is by exploring the examples in the gallery."
  },
  {
    "objectID": "interactive_sessions/5-1_matplotlib.html#introduction-to-matplotlib",
    "href": "interactive_sessions/5-1_matplotlib.html#introduction-to-matplotlib",
    "title": "Session 5-1: Matplotlib üìà",
    "section": "Introduction to matplotlib",
    "text": "Introduction to matplotlib\n\nAs always, we will begin by importing the required libraries and packages. For plotting, itself, we will use a module of the matplotlib library called  pyplot. The  pyplot module consists of a collection of functions to display and edit figures. As you advance with Python and with data analysis, you may want to explore additional features of  matplotlib, but  pyplot will suit the vast majority of your plotting needs at this stage.\nThe standard import statement for  matplotlib.pyplot  is:\nimport matplotlib.pyplot as plt\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\nAnatomy of a matplotlib plot\nThe core components of a matplotlib plot are the Figure and the Axes. The Figure is the overall window upon which all components are drawn. It serves as the blank container for plots, as well as other things, such as a legend, color bar, etc. You can (and will) create multiple independent figures, and each figure can hold multiple Axes. To the figure you will add Axes, the area where the data are actually plotted and where associated ticks, labels, etc. live.\nWhen working with a single plot, we will mostly deal with the Figure object and its routines, but we will see the Axes become important as we increase the complexity of our plots.\n\n\n\nBasic plotting\n\n\nWe will start with the most basic plotting routines: plt.plot() and plt.scatter(). The first, plt.plot(), is used to generate a connected line plot (with optional markers for individual data points). plt.scatter(), as the name suggests, is used to generate a scatter plot.\nEach time you want to create a new figure, it is wise to first initialize a new instance of the matplotlib.figure.Figure class on which to plot our data. While this is not required to display the plot, if you subsequently plot additional data without a new Figure instance, all data will be plotted on the same figure. For example, let‚Äôs generate a few functions, y_{\\sin} = \\sin{(x)} and y_{\\cos} = \\cos{(x)}:\n# Generate a 1D array with 300 points between -5 and 5\nx = np.linspace(-5,5,300)\n# Generate sine wave\nysin = np.sin(x)\n# Generate cosine wave\nycos = np.cos(x)\nWe can plot these on the same figure without instancing plt.figure() as follows:\n# Plot sine wave\nplt.plot(x,ysin)\n# Plot cosine wave\nplt.plot(x,ycos)\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Generate a 1D array with 100 points between -5 and 5\nx = np.linspace(-5,5,100)\n# Generate sine wave\nysin = np.sin(x)\n# Generate cosine wave\nycos = np.cos(x)\n\n# Plot sine wave\nplt.plot(x,ysin)\n# Plot cosine wave\nplt.plot(x,ycos)\n\n\n\n\n\nTo create multiple graphs in separate figure windows, however, you need to create new Figure instances as follows:\nfig = plt.figure()\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Plot sine wave\nfig1 = plt.figure()\nplt.plot(x,ysin)\n\n# Plot cosine wave\nfig2 = plt.figure()\nplt.plot(x,ycos)\n\n\n\n\n\n\n\n\nThis also allows you to access the Figure object later by refering to the variable fig. Thus, even when you want to plot all data on a single plot, it is best to always start by initializing a new Figure.\nTo generate a scatter plot instead of a line, we can use plt.scatter():\n# Generate new x and y with fewer points for legibility\nxscat = np.linspace(-5,5,25)\nyscat = np.sin(xscat)\n\n# Plot sine function as scatter plot\nplt.scatter(xscat,yscat)\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Generate new x and y with fewer points for legibility\nxscat = np.linspace(-5,5,25)\nyscat = np.sin(xscat)\n\n# Plot sine function as scatter plot\nplt.scatter(xscat,yscat)\n\n\n&lt;matplotlib.collections.PathCollection at 0x17a67dbd0&gt;\n\n\n\n\n\nYou can also create a scatter plot using plt.plot() with keyword arguments, which allow you to change things like the color, style, and size of the lines and markers. We will explore some of these keyword arguments in the next section.\n\n\nKeyword arguments\n\n\nIn addition to the required x and y parameters, there are a number of optional keyword arguments that can be passed to the matplotlib plotting functions. Here, we will consider a few of the most useful: color, marker, and linestyle.\n\nColors\nThe first thing you might wish to control is the color of your plot. Matplotlib accepts several different color definitions to the color keyword argument, which is a feature of most plotting functions.\nFirst, colors can be passed as strings according to their HTML/CSS names. For example:\nplt.plot(x, y, 'green')\nIn total, there are 140 colors allowed in HTML; their names are shown below.\n\n\n\ncolors\n\n\nAs you can see in the image above, the basic colors can also be defined by a single-letter shortcut. These are shown in the table below.\n\n\n\n\n\n\n\nLetter code\nColor name\n\n\n\n\n‚Äòr‚Äô\nred\n\n\n‚Äòg‚Äô\ngreen\n\n\n‚Äòb‚Äô\nblue\n\n\n‚Äòc‚Äô\ncyan\n\n\n‚Äòm‚Äô\nmagenta\n\n\n‚Äòy‚Äô\nyellow\n\n\n‚Äòk‚Äô\nblack\n\n\n‚Äòw‚Äô\nwhite\n\n\n\nAnother way of specifying colors is to use an RGB(A) tuple, where the brightness of each channel (R, G, or B, which correspond to red, green, and blue) is given as a float between 0 and 1. An optional fourth value, A or alpha, value can be passed to specify the opacity of the line or marker.\nplt.plot(x, y, color=(0.2,0.7,1.0))\nA grayscale value can be used by passing a number between 0 and 1 as a string. In this representation, '0.0' corresponds to black and '1.0' corresponds to white.\nplt.plot(x, y, color='0.25')\nMy personal favorite way to define colors is to use  color hex codes, which represent colors as hexadecimals ranging from 0 to FF. Color hex codes consist of a hash character # followed by six hex values (e.g.¬†#AFD645). Hex codes must be passed as strings (e.g.¬†'#AFD645') in matplotlib and are perhaps the most flexible way to select colors.\nplt.plot(x, y, color='#C6E2FF')\nIn the cell below, five functions are plotted in different colors, each specified by a different definition.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave with different colors\nplt.plot(x, np.sin(x - 0), color='darkblue')     # HTML name\nplt.plot(x, np.sin(x - 1), color='m')            # Short letter code\nplt.plot(x, np.sin(x - 2), color=(0.0,0.8,0.81)) # RGB tuple\nplt.plot(x, np.sin(x - 3), color='0.65')         # Grayscale between 0 and 1\nplt.plot(x, np.sin(x - 4), color='#B8D62E')      # Hex code\n\n\n\n\n\n\n\nLinestyles\nUsing the linestyle keyword argument, you can change the style of the line plotted using plt.plot(). These can be specified either by their name or a shortcut. A few of the style options (and their matplotlib shortcuts) are shown in the table below. To see a full list of linestyle options, see the docs.\n\n\n\n\n\n\n\nShort code\nLine style\n\n\n\n\n‚Äò-‚Äô\nsolid\n\n\n‚Äò‚Äì‚Äô\ndashed\n\n\n‚Äò:‚Äô\ndotted\n\n\n‚Äò-.‚Äô\ndashdot\n\n\n\nAs we‚Äôve already seen, the default linestyle is solid. The syntax for changing a line‚Äôs style is:\nplt.plot(x, y, linestyle='dashed')\nor, more commonly:\nplt.plot(x, y, linestyle='--')\nLet‚Äôs adjust the style of our waveform plot using the linestyle keyword argument.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave with different colors + linestyles\nplt.plot(x, np.sin(x - 0), color='darkblue', linestyle='-')\nplt.plot(x, np.sin(x - 1), color='m', linestyle='dashed')\nplt.plot(x, np.sin(x - 2), color=(0.0,0.8,0.81), linestyle=':') \nplt.plot(x, np.sin(x - 3), color='0.65', linestyle='solid')\nplt.plot(x, np.sin(x - 4), color='#B8D62E', linestyle='-.')\n\n\n\n\n\n\n\nMarkers\nMarkers can be used in plt.plot() and plt.scatter(). There are several available markers in matplotlib, and you can also define your own. A few of the most useful are shown in the table below.\n\n\n\nMarker code\nSymbol\nDescription\n\n\n\n\n‚Äòo‚Äô\n‚óè\ncircle\n\n\n‚Äò.‚Äô\n‚ãÖ\npoint\n\n\n**‚Äô*‚Äô**\n‚òÖ\nstar\n\n\n‚Äò+‚Äô\n+\nplus\n\n\n‚Äòx‚Äô\n\\times\nx\n\n\n‚Äò^‚Äô\n‚ñ≤\ntriangle\n\n\n‚Äòs‚Äô\n‚óº\nsquare\n\n\n\nNote that unlike color and linestyle, the marker keyword argument only accepts a code to specify the marker style.\nplt.scatter(x, y, marker='+')\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave as scatter plot with different colors + markers\nplt.scatter(xscat, yscat-0, color='darkblue', marker='o')\nplt.scatter(xscat, yscat-1, color='m', marker='.')\nplt.scatter(xscat, yscat-2, color=(0.0,0.8,0.81), marker='+')\nplt.scatter(xscat, yscat-3, color='0.65', marker='*')\nplt.scatter(xscat, yscat-4, color='#B8D62E', marker='s')\n\n\n&lt;matplotlib.collections.PathCollection at 0x17a827fd0&gt;\n\n\n\n\n\nUsing the marker keyword argument with the plt.plot() function creates a connected line plot, where the data points are designated by markers and connected by lines.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave with different colors + markers\nplt.plot(xscat, np.sin(xscat - 0), color='darkblue', marker='o')\nplt.plot(xscat, np.sin(xscat - 1), color='m', marker='.')\nplt.plot(xscat, np.sin(xscat - 2), color=(0.0,0.8,0.81), marker='+')\nplt.plot(xscat, np.sin(xscat - 3), color='0.65', marker='*')\nplt.plot(xscat, np.sin(xscat - 4), color='#B8D62E', marker='s')\n\n\n\n\n\n\n\nExplicit definitions vs.¬†shortcuts\nUp to now, we have used explicit definitions to specify keyword arguments. While this is generally preferable, matplotlib does allow color, linestyle, and marker codes to be combined into a single, non-keyword argument. For example:\n# Plot a dashed red line\nplt.plot(x, y, 'r--')\nSeveral examples are presented in the cell below.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave with different colors + markers\nplt.plot(xscat, yscat-0, 'b-o')    # Solid blue line with circle markers\nplt.plot(xscat, yscat-1, 'm--*')   # Dashed magenta line with star markers\nplt.plot(xscat, yscat-2, 'c+')     # Cyan plus markers\nplt.plot(xscat, yscat-3, 'k')      # Solid black line\nplt.plot(xscat, yscat-4, 'y-s')    # Solid yellow line with square markers\n\n\n\n\n\nAs you can see, the downside of this method is that you are limited to the eight colors that have a single-letter code. To use other colors, you must use explicitly defined keyword arguments.\nIn addition to those we explored in this section, other useful keyword arguments include linewidth and markersize, which do exactly what you‚Äôd expect them to do. For a full list of keyword arguments (you should know what‚Äôs coming by now), see the docs.\n\n\n\nAxes settings\n\n\nNext, we will explore how to scale and annotate a plot using axes routines that control what goes on around the edges of the plot.\n\nLimits, labels, + ticks\nBy default, matplotlib will attempt to determine x- and y-axis limits, which usually work pretty well. Sometimes, however, it is useful to have finer control. The simplest way to adjust the display limits is to use the plt.xlim() and plt.ylim() methods:\n# Set axis limits\nplt.xlim(xmin, xmax)\nplt.ylim(ymin, ymax)\nIn the example below, adjust the numbers (these can be int or float values) to see how the plot changes.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\n\n# Set axis limits\nplt.xlim(-5,5)\nplt.ylim(-2,2)\n\n\n(-2.0, 2.0)\n\n\n\n\n\nYou may also find it useful to adjust the ticks and/or tick labels that matplotlib  displays by default. The plt.xticks() and plt.yticks() methods allow you to control the locations of both the ticks and the labels on the x- and y-axes, respectively. Both methods accept two list or array-like arguments, as well as optional keyword arguments. The first corresponds to the ticks, while the second controls the tick labels.\n# Set x-axis ticks at 0, 0.25, 0.5, 0.75, 1.0 with all labeled\nplt.xticks([0,0.25,0.5,0.75,1.0])\n# Set y-axis ticks from 0 to 100 with ticks on 10s and labels on 20s\nplt.yticks(np.arange(0,101,10),['0','','20','','40','','60','','80','','100'])\nIf the labels are not specified, all ticks will be labeled accordingly. To only label certain ticks, you must pass a list with empty strings in the location of the ticks you wish to leave unlabeled (or the ticks will be labeled in order).\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n\n([&lt;matplotlib.axis.YTick at 0x17aa243a0&gt;,\n  &lt;matplotlib.axis.YTick at 0x17aa0fd00&gt;,\n  &lt;matplotlib.axis.YTick at 0x17a9f0ca0&gt;,\n  &lt;matplotlib.axis.YTick at 0x17a9cf6d0&gt;,\n  &lt;matplotlib.axis.YTick at 0x17a9f0400&gt;],\n [Text(0, -1.0, '‚àí1.0'),\n  Text(0, -0.5, '‚àí0.5'),\n  Text(0, 0.0, '0.0'),\n  Text(0, 0.5, '0.5'),\n  Text(0, 1.0, '1.0')])\n\n\n\n\n\nAs with any plot, it is imperative to include x- and y-axis labels. This can be done by passing strings to the plt.xlabel() and plt.ylabel() methods:\n# Set axis labels\nplt.xlabel('x-axis')\nplt.ylabel('y-axis')\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n# Set axis labels\nplt.xlabel('x-axis')\nplt.ylabel('y-axis')\n\n\nText(0, 0.5, 'y-axis')\n\n\n\n\n\nA nice feature about matplotlib is that it supports TeX formatting for mathematical expressions. This is quite useful for displaying equations, exponents, units, and other mathematical operators. The syntax for TeX expressions is 'r$TeX expression here$'. For example, we can display the axis labels as x and \\sin{(x)} as follows:\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n# Set axis labels\nplt.xlabel(r'$x$')\nplt.ylabel(r'$\\sin{(x)}$')\n\n\nText(0, 0.5, '$\\\\sin{(x)}$')\n\n\n\n\n\n\n\nLegends + titles\nAdding a title to your plot is analogous to labeling the x- and y-axes. The plt.title() method allows you to set the title of your plot by passing a string:\nplt.title('Title')\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\nplt.plot(x, ycos, color='#B8D62E')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n# Set axis labels\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\n\n# Set title\nplt.title('Sinusoidal functions')\n\n\nText(0.5, 1.0, 'Sinusoidal functions')\n\n\n\n\n\nWhen multiple datasets are plotted on the same axes it is often useful to include a legend that labels each line or set of points. Matplotlib has a quick way of displaying a legend using the plt.legend() method. There are multiple ways of specifying the label for each dataset; I prefer to pass a list of strings to plt.legend():\n# Plot data\nplt.plot(x1, y1)\nplt.plot(x2, y2)\n\n# Legend\nplt.legend(labels=['Data1', 'Data2'])\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, color='darkblue')\nplt.plot(x, ycos, color='#B8D62E')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n# Set axis labels\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\n\n# Set title\nplt.title('Sinusoidal functions')\n\n# Legend\nplt.legend(labels=['sin(x)','cos(x)'])\n\n\n&lt;matplotlib.legend.Legend at 0x17a7c0e50&gt;\n\n\n\n\n\nAnother way of setting the data labels is to use the label keyword argument in the plt.plot() (or plt.scatter()) function:\n# Plot data\nplt.plot(x1, y1, label='Data1')\nplt.plot(x2, y2, label='Data2')\n\n# Legend\nplt.legend()\nNote that you must still run plt.legend() to display the legend.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig1 = plt.figure()\n# Plot sine wave \nplt.plot(x, ysin, label='sin(x)', color='darkblue')\nplt.plot(x, ycos, label='cos(x)', color='#B8D62E')\n\n# Set x-axis limits\nplt.xlim(-5,5)\n\n# Set axis ticks\nplt.xticks([-4,-3,-2,-1,0,1,2,3,4],['-4','','-2','','0','','2','','4'])\nplt.yticks([-1,-0.5,0,0.5,1])\n\n# Set axis labels\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\n\n# Set title\nplt.title('Sinusoidal functions')\n\n# Legend\nplt.legend()\n\n\n&lt;matplotlib.legend.Legend at 0x17a5db520&gt;\n\n\n\n\n\n\n\n\nSubplots + multiple axes\n\n\nNow that we‚Äôve established the basics of plotting in matplotlib, let‚Äôs get a bit more complicated. Oftentimes, you may want to plot data on multiple axes within the same figure. The easiest way to do this in matplotlib is to use the plt.subplot() function, which takes three non-keyword arguments: nrows, ncols, and index. nrows and ncols correspond to the total number of rows and columns of the entire figure, while index refers to the index position of the current axes. Importantly (and annoyingly), the index for subplots starts in the upper left corner at 1 (not 0)!. The image below contains a few examples of how matplotlib arranges subplots.\n\nThe most explicit way of adding subplots is to use the fig.add_subplot() command to initialize new axes as variables:\n# Initialize empty figure\nfig = plt.figure()\n# Add four axes\nax1 = fig.add_subplot(2,2,1)\nax2 = fig.add_subplot(2,2,2)\nax3 = fig.add_subplot(2,2,3)\nax4 = fig.add_subplot(2,2,4)\nThis allows you to access each Axes object later to plot data and adjust the axes parameters.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig = plt.figure()\n# Add four axes\nax1 = fig.add_subplot(2,2,1)\nax2 = fig.add_subplot(2,2,2)\nax3 = fig.add_subplot(2,2,3)\nax4 = fig.add_subplot(2,2,4)\n\n\n\n\n\nTo plot data, we use ax.plot() or ax.scatter(). These methods are analogous to plt.plot() and plt.scatter() for acting on the Axes, rather than the Figure object.\n# Plot data\nax1.plot(x, y)\nax2.plot(x, y)\nax3.plot(x, y)\nax4.plot(x, y)\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig = plt.figure()\n# Add four axes\nax1 = fig.add_subplot(2,2,1)\nax2 = fig.add_subplot(2,2,2)\nax3 = fig.add_subplot(2,2,3)\nax4 = fig.add_subplot(2,2,4)\n\n# Plot data\n# Plot sine wave with different colors on different axes\nax1.plot(x, np.sin(x - 0), color='darkblue')\nax2.plot(x, np.sin(x - 1), color='m')\nax3.plot(x, np.sin(x - 2), color=(0.0,0.8,0.81))\nax4.plot(x, np.sin(x - 4), color='#B8D62E')\n\n\n\n\n\n\nFigure vs.¬†Axes methods\nPerhaps the trickiest part about subplots ‚Äì and Axes methods in general ‚Äì¬†is adjusting the axes settings. While most Figure functions translate directly Axes methods (e.g.¬†plt.plot() \\rightarrow ax.plot(), plt.legend() \\rightarrow ax.legend()), commands to set limits, ticks, labels, and titles are slightly modified. Some important Figure methods and their Axes counterparts are shown in the table below.\n\n\n\n\n\n\n\nFigure command\nAxes command\n\n\n\n\nplt.xlabel()\nax.set_xlabel()\n\n\nplt.ylabel()\nax.set_ylabel()\n\n\nplt.xlim()\nax.set_xlim()\n\n\nplt.ylim()\nax.set_ylim()\n\n\nplt.xticks()\nax.set_xticks()\n\n\nplt.yticks()\nax.set_yticks()\n\n\n\nThese are different primarily because the Figure functions are inherited from MATLAB, while the Axes functions are object-oriented. Generally, the arguments are similar ‚Äì if not identical ‚Äì¬†between the two.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig = plt.figure()\n# Add four axes\nax1 = fig.add_subplot(2,2,1)\nax2 = fig.add_subplot(2,2,2)\nax3 = fig.add_subplot(2,2,3)\nax4 = fig.add_subplot(2,2,4)\n\n# Plot data\n# Plot sine wave with different colors on different axes\nax1.plot(x, np.sin(x - 0), color='darkblue')\nax2.plot(x, np.sin(x - 1), color='m')\nax3.plot(x, np.sin(x - 2), color=(0.0,0.8,0.81))\nax4.plot(x, np.sin(x - 4), color='#B8D62E')\n\n# Set axes limits, labels, + ticks\nfor i,ax in enumerate([ax1,ax2,ax3,ax4]):\n    # Set x limits \n    ax.set_xlim(-5,5)\n    # Set title\n    ax.set_title(r'$\\sin{(x - %d)}$' % i)\n    # Only label x ticks and x-axis on bottom row\n    if i &lt; 2:\n        ax.set_xticklabels([])\n    else:\n        ax.set_xlabel('x')\n    # Only label y ticks and y-axis on left column\n    if i == 0 or i == 2:\n        ax.set_ylabel('y')\n    else:\n        ax.set_yticklabels([])\n\nplt.tight_layout()\n\n\n\n\n\nIn the last example, we included a command, plt.tight_layout(), which automatically formats the figure to fit the window. This is most useful when using an IDE with a separate plotting window, rather than with in-line plots like those in a notebook. To get a sense of what plt.tight_layout() does, try re-running the above cell with this command commented out.\nTo go beyond regularly gridded subplots and create subplots that span multiple rows and/or columns, check out GridSpec.\n\n\n\nWorking with real data\n\n\nAs we learned in the previous exercise, working with real-world data usually complicates things, and plotting is no exception. In particular, working with time series can get a bit messy. Let‚Äôs take a look at our BSRN data as an example.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Import data\nbsrn = pd.read_csv('../data/BSRN_GOB_2019-10.csv',index_col=0,parse_dates=True)\n\n\nNow that we‚Äôve imported our data, let‚Äôs make a quick plot of incoming shortwave radiation over time.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure\nfig = plt.figure()\n# Plot incoming SW radiation\nplt.plot(bsrn.index,bsrn.SWD_Wm2)\n# Label y-axis\nplt.ylabel(r'Incoming SW radiation (W m$^{-2}$)')\n\n\nText(0, 0.5, 'Incoming SW radiation (W m$^{-2}$)')\n\n\n\n\n\nThe x-axis looks rather messy because the tick labels are timestamps, which are, by nature, very long. Luckily, matplotlib has a module called dates for dealing with datetime objects.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\nimport matplotlib.dates as mdates\n\n\nWithout going into too much detail, we can use some of the more advanced Axes settings to format and rotate the tick labels such that they no longer overlap, and we can use matplotlib.dates to format the timestamps. In short, we will use the mdates.DateFormatter() function to format the timestamps according to C formatting codes.\nThe following example demonstrates this, and includes a good code chunk for formatting timestamps to add to your repertoire. It is important to note that the formatting methods employed here are Axes methods, which means that we must operate on an Axes object, rather than the Figure.\n\n‚ñ∂Ô∏è &lt;b&gt; Run the cell below. &lt;/b&gt;\n\n\n\nCode\n# Initialize empty figure and axes\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n# Plot incoming SW radiation\nax.plot(bsrn.index,bsrn.SWD_Wm2)\n# Label y-axis\nax.set_ylabel(r'Incoming SW radiation (W m$^{-2}$)')\n\n# Format timestamps\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%y'))\n# Format and rotate ticks\nplt.setp(ax.get_xticklabels(), rotation=45, fontsize=10, ha='right')\nax.get_xticklabels()\n\n\n[Text(18170.0, 0, '01-Oct-19'),\n Text(18174.0, 0, '05-Oct-19'),\n Text(18178.0, 0, '09-Oct-19'),\n Text(18182.0, 0, '13-Oct-19'),\n Text(18186.0, 0, '17-Oct-19'),\n Text(18190.0, 0, '21-Oct-19'),\n Text(18194.0, 0, '25-Oct-19'),\n Text(18198.0, 0, '29-Oct-19'),\n Text(18201.0, 0, '01-Nov-19')]"
  },
  {
    "objectID": "group_project/python_data_science_show_and_tell.html#python-library-show-and-tell",
    "href": "group_project/python_data_science_show_and_tell.html#python-library-show-and-tell",
    "title": "üì£ Data Science Library Show-and-Tell",
    "section": "Python Library Show-and-Tell",
    "text": "Python Library Show-and-Tell\n\nForm groups of 4-5 Students\nFind a Library\nWorking collaboratively use a github repo to create a notebook about the library\nPresent notebook to class (10-15 min)\n\n\nFind a Library\n\nPyPi pypi.org\nTowards Data Science towardsdatascience.com\nPodcasts: Talk Python to Me, Linear Digressions, Python Bytes\nDomain-specific searches ‚Äúpython oceanography‚Äù, ‚Äúpython climate science‚Äù, etc‚Ä¶\n\nGood candidates for a Show-and-Tell are libraries that are relevant and popular.\nPopularity can measured with GitHub stars, or PyPi downloads. Or if folks in the data science community are talking about it.\n\n\nCreate a github repo for your tutorial.\nThe repo should contain:\n\nan environment file including all necessary dependencies\na README.md file with a brief description of the library and a link to the library‚Äôs webpage or github repo.\nan example notebook (or notebooks) about the library.\nany other files necessary to run the example notebook(s)\n\n\n\nNotebook contents:\n\nBrief Description\n\nWhat is it?\nWhere is it? Link to project webpage, github\nWho developed?\nWhy was it created?\n\nPotential Use in Environmental Data Science\nQuick tutorial/example, using Env. Data Sci example if possible!\n\nOkay to incorporate examples found elsewhere (provide link and acknowledgement!)\n\n\n\n\nLibrary Show-and-Tell\n\nPresent your notebook to the class!\n10-15 minute presentation.\nQ&A.\nWe will have our presentations in the afternoon on the last day of class (Friday, Sept.¬†15)\nAll repos will be cloned to the environmentaldatascience github so everyone can learn from each other.\n\n\nBY LUNCH ON WEDNESDAY: SELECT YOUR LIBRARY, PLUS TWO ALTERNATES (IN CASE OF DUPLICATES)"
  },
  {
    "objectID": "lectures/lectures.html",
    "href": "lectures/lectures.html",
    "title": "EDS 217 Lectures",
    "section": "",
    "text": "Return to Course Home Page\n\n\n\n\nThis page contains links to lecture materials for EDS 217.\n\nIntroduction to Python Data Science\n\n\nThe Zen of Python\n\n\nGetting Help"
  },
  {
    "objectID": "lectures/99_dry_vs_wet.html#dry-vs.-wet",
    "href": "lectures/99_dry_vs_wet.html#dry-vs.-wet",
    "title": "EDS 217, Lecture 4: DRY üèú vs.¬†WET üåä",
    "section": "DRY vs.¬†WET",
    "text": "DRY vs.¬†WET\nIf DRY means ‚ÄúDon‚Äôt Repeat Yourself‚Äù‚Ä¶ then WET means ‚ÄúWrite Every Time‚Äù, or ‚ÄúWe Enjoy Typing‚Äù\nDon‚Äôt write WET code!\n\nHow to DRY out your code\nWe write DRY code - or we DRY out WET code - through a combination of abstraction and normalization."
  },
  {
    "objectID": "lectures/99_dry_vs_wet.html#abstraction",
    "href": "lectures/99_dry_vs_wet.html#abstraction",
    "title": "EDS 217, Lecture 4: DRY üèú vs.¬†WET üåä",
    "section": "Abstraction",
    "text": "Abstraction\nThe ‚Äúprinciple of abstraction‚Äù aims to reduce duplication of information (usually code) in a program whenever it is practical to do so:\n‚ÄúEach significant piece of functionality in a program should be implemented in just one place in the source code. Where similar functions are carried out by distinct pieces of code, it is generally beneficial to combine them into one by abstracting out the varying parts.‚Äù\nBenjamin C. Pierce - Types and Programming Languages\n\nAbstraction Example\nThe easiest way to understand abstraction is to see it in action. Here‚Äôs an example that you are already familiar with; determining the energy emitted by an object as a function of its temperature:\nQ = \\epsilon \\sigma T^4\nwhere \\epsilon is an object‚Äôs emmissivity, \\sigma is the Stefan-Boltzmann constant, and T is temperature in degrees Kelvin.\n\n\nAbstraction Example\nWe might write the following code to determine Q:\n\n\nCode\n# How much energy is emitted by an object at a certain temperature?\nŒµ = 1      # emissivity [-]\nœÉ = 5.67e-8  # stefan-boltzmann constant [W/T^4]\nT_C = 40         # temperature [deg-C]\n\nQ = Œµ * œÉ * (T_C+273.15)**4\nprint(Q)\n\n\n\n\nAbstraction Example\nBut this code is going to get very WET very fast.\n\n\nCode\n# How much energy is emitted by an object at a certain temperature?\nŒµ = 1      # emissivity [-]\nœÉ = 5.67e-8  # stefan-boltzmann constant [W/m^2/K^4]\nT_C = 40         # temperature [deg-C]\n\nQ = Œµ * œÉ * (T_C+273.15)**4\n\n# New T value? Different epsilon? What about a bunch of T values?\nT_2 = 30\n\nQ2 = Œµ * œÉ * (T_2+273.15)**4\n\n\n\n\n\nAbstraction Example\nHere‚Äôs a DRY version obtained using abstraction:\n\n\nCode\n# energy.py contains a function to calculate Q from T \nfrom energy import Q \n\nT = 40 # deg-C\nE = Q(T, unit='C')\n\n\n\n\nAbstraction Summary, Part 1\n\nWe keep our code DRY by using abstraction. In addition to functions, python also provides Classes as another important way to create abstractions.\nFunctions and Classes are the subject of this tomorrow‚Äôs exercise.\n\n\n\nAbstraction Summary, Part 2\n\nIn general, the process of keeping code DRY through successive layers of abstraction is known as re-factoring.\nThe ‚ÄúRule of Three‚Äù states that you should probably consider refactoring (i.e.¬†adding abstraction) whenever you find your code doing the same thing three times or more."
  },
  {
    "objectID": "lectures/99_dry_vs_wet.html#normalization",
    "href": "lectures/99_dry_vs_wet.html#normalization",
    "title": "EDS 217, Lecture 4: DRY üèú vs.¬†WET üåä",
    "section": "Normalization",
    "text": "Normalization\nNormalization is the process of structuring data in order to reduce redundancy and improve integrity."
  },
  {
    "objectID": "lectures/99_dry_vs_wet.html#normalization-1",
    "href": "lectures/99_dry_vs_wet.html#normalization-1",
    "title": "EDS 217, Lecture 4: DRY üèú vs.¬†WET üåä",
    "section": "Normalization",
    "text": "Normalization\nSome of the key principles of Normalization include:\n\nAll data have a Primary Key, which uniquely identifies a record. Usually, in python, this key is called an Index.\nAtomic columns, meaning entries contain a single value. This means no collections should appear as elements within a data table. (i.e.¬†‚Äúcells‚Äù in structured data should not contain lists!)\nNo transitive dependencies. This means that there should not be implicit associations between columns within data tables.\n\n\nPrimary Keys\nThis form of normalization is easy to obtain, as the idea of an Index is embedded in almost any Python data structure, and a core component of data structures witin pandas, which is the most popular data science library in python (coming next week!).\n\n\nPrimary Keys\n\n\nCode\n# All DataFrames in pandas are created with an index (i.e unique primary key)\nimport pandas as pd\naverage_high_temps = [18.3, 18.3, 18.9, 20.6, 21.1, 21.7,\n                      23.9, 24.4, 23.9, 22.8, 20.6, 18.3]\nsb_high_temp = pd.DataFrame(\n    average_high_temps, # This list will become a single column of values\n    columns=['Average_High_Temperature'] # This is the name of the column\n) # NOTE: use sb_high_temp.head() py-&gt;month_list\n#sb_high_temp.index = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nsb_high_temp.head()\n\n\n\n\nAtomic Columns\nThe idea of atomic columns is that each element in a data structure should contain a unique value. This requirement is harder to obtain and you will sometimes violate it.\n\n\nCode\n# import pandas as pd\naverage_high_temps = [18.3, 18.3, 18.9, 20.6, 21.1, 21.7, 23.9, 24.4, 23.9, 22.8, 20.6, 18.3]\naverage_rainfall = [110.7, 119.1, 74.2, 31.5, 8.4, 2.3, 0.5, 1.3, 3.6, 22.9, 45.5, 77.2]\n\n# THIS DATAFRAME IS NOT ATOMIC. EACH ELEMENT IN THE COLUMN IS A LIST.\nsb_climate = pd.DataFrame([\n    [average_high_temps, # The first column will contain a list.\n     average_rainfall]], # The second column will also contain a list.\n    columns=['Monthly Average Temp', 'Monthly Average Rainfall'] # Column names\n)\nsb_climate.head()\n\n\n\n\nAtomic Columns\nThe idea of atomic columns is that each element in a data structure should contain a unique value. This requirement is harder to obtain and you will sometimes violate it.\n\n\nCode\nimport pandas as pd\naverage_high_temps = [18.3, 18.3, 18.9, 20.6, 21.1, 21.7, 23.9, 24.4, 23.9, 22.8, 20.6, 18.3]\naverage_rainfall = [110.7, 119.1, 74.2, 31.5, 8.4, 2.3, 0.5, 1.3, 3.6, 22.9, 45.5, 77.2]\n\n# THIS DATAFRAME IS ATOMIC. EACH ELEMENT IN THE COLUMN IS A SINGLE VALUE.\nsb_climate = pd.DataFrame({ # Using a dict to create the data frame.\n    'Average_High_Temperature':average_high_temps, # This is the first column\n    'Average_Rainfall':average_rainfall # This is the second column\n})\nsb_climate.index = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nsb_climate.head()\n\n\n\n\nTransitive Dependencies\nThe idea of transitive dependencies is the inclusion of multiple associated attributes within the same data structure.\n\nTransitive dependencies make updating data very difficult, but they can be helpful in analyzying data.\nSo we should only introduce them in data that we will not be editing.\n\nUsually environmental data, and especially timeseries, are rarely modified after creation. So we don‚Äôt need to worry as much about these dependencies.\nFor example, contrast a data record of ‚Äútemperatures through time‚Äù to a data record of ‚Äúuser contacts in a social network‚Äù.\n\n\nTransitive Dependencies\nThe idea of transitive dependencies is the inclusion of multiple associated attributes within the same data structure.\n\n\nCode\nimport pandas as pd\naverage_high_temps = [18.3, 18.3, 18.9, 20.6, 21.1, 21.7, 23.9, 24.4, 23.9, 22.8, 20.6, 18.3]\naverage_rainfall = [110.7, 119.1, 74.2, 31.5, 8.4, 2.3, 0.5, 1.3, 3.6, 22.9, 45.5, 77.2]\n\n# TRANSITIVE ASSOCIATIONS EXIST BETWEEN MONTHS AND SEASONS IN THIS DATAFRAME:\nmonth = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nseason = ['Winter', 'Winter', 'Spring', 'Spring', 'Spring', 'Summer', 'Summer', 'Summer', 'Fall', 'Fall', 'Fall', 'Winter']\nsb_climate = pd.DataFrame({ # Using a dict to create the data frame.\n    'Month': month,         # Adding month as the first column of the data frame\n    'Season': season,       # Adding the season for each month (this is a transitive dependency)\n    'Avg_High_Temp':average_high_temps, # This is the third column\n    'Avg_Rain':average_rainfall         # This is the fourth column\n})\nsb_climate.head()\n\n\n\n\nNormalization Summary\nIn general, for data analysis, basic normalization is handled for you.\n\nFor read only data with fixed associations, a lack of normalization is manageable.\nHowever, many analyses are easier if you structure your data in ways that are as normalized as possible.\nIf you are collecting data then it is important to develop an organization structure that is normalized."
  },
  {
    "objectID": "lectures/99_dry_vs_wet.html#the-end",
    "href": "lectures/99_dry_vs_wet.html#the-end",
    "title": "EDS 217, Lecture 4: DRY üèú vs.¬†WET üåä",
    "section": "The End",
    "text": "The End"
  }
]